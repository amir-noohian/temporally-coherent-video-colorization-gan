{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_second.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNlIRTPzNbI"
      },
      "source": [
        "## In this code, we consider GAN loss, L1 loss, and Style loss. In addition, we just use the current lineart frame to input the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hif97tj5cj9o",
        "outputId": "0e598108-c4f0-49bf-a6b6-c84ff3123cfe"
      },
      "source": [
        "!pip uninstall scipy\r\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scipy-1.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy-1.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled scipy-1.1.0\n",
            "Collecting scipy==1.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQTf3rjcOnz"
      },
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from math import log10\r\n",
        "from os.path import join\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_WEhnDvOjF"
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgM5pqPIU9d9",
        "outputId": "23226f77-73a2-418d-8028-5e6883d7ce9c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EZsqYjVQoS"
      },
      "source": [
        "sys.path.append('/content/gdrive/MyDrive/src_second')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxJDA28aUJe9"
      },
      "source": [
        "from models import define_G, define_D, print_network\r\n",
        "from data import get_training_set, get_test_set, create_iterator\r\n",
        "from dataset import DatasetFromFolder\r\n",
        "from loss import AdversarialLoss, StyleLoss, PerceptualLoss\r\n",
        "from util import Progbar, stitch_images, postprocess, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T5HnCEwsgXS"
      },
      "source": [
        "root = '/content/gdrive/MyDrive'\r\n",
        "dataset = 'dataset'\r\n",
        "logfile = 'trainlogs.dat'\r\n",
        "checkpoint_path_G = False\r\n",
        "checkpoint_path_D = False\r\n",
        "batchSize = 16\r\n",
        "testBatchSize = 1\r\n",
        "nEpochs = 80\r\n",
        "input_nc = 1\r\n",
        "output_nc = 3\r\n",
        "lr = 0.0001\r\n",
        "beta1 = 0\r\n",
        "cuda = True\r\n",
        "threads = 0\r\n",
        "seed = 123\r\n",
        "L1lamb = 10\r\n",
        "Stylelamb = 1000\r\n",
        "Contentlamb = 0\r\n",
        "Adversariallamb = 0.1\r\n",
        "ngf = 2\r\n",
        "ndf = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af92GbOgPG2j"
      },
      "source": [
        "if cuda and not torch.cuda.is_available():\r\n",
        "    raise Exception(\"No GPU found, please run without --cuda\")\r\n",
        "\r\n",
        "cudnn.benchmark = True\r\n",
        "\r\n",
        "torch.manual_seed(seed)\r\n",
        "if cuda:\r\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGXUruQOvpvV",
        "outputId": "fa301e52-a4b0-4e19-c359-f9a3fb2b08e5"
      },
      "source": [
        "print('===> Loading datasets')\r\n",
        "root_path = root\r\n",
        "train_set = get_training_set(join(root_path , dataset))\r\n",
        "test_set = get_test_set(join(root_path , dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Loading datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUec3y0aPRZE"
      },
      "source": [
        "training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batchSize, shuffle=True)\r\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=threads, batch_size=testBatchSize, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv2Sg-JBPVPd"
      },
      "source": [
        "sample_iterator = create_iterator(4, test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9O_Y9qkPY9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de19414e-5165-42ef-d4b5-60d1b0b291c5"
      },
      "source": [
        "print('===> Building model')\r\n",
        "netG = define_G(input_nc, output_nc, ngf, False, [0])\r\n",
        "netD = define_D(input_nc + output_nc, ndf, False, [0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Building model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xi4LWxEPbul"
      },
      "source": [
        "if checkpoint_path_G and checkpoint_path_D:\r\n",
        "    load(checkpoint_path_G, checkpoint_path_D, netG, netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T5sTtucPfBj"
      },
      "source": [
        "criterionGAN = AdversarialLoss()\r\n",
        "criterionSTYLE = StyleLoss()\r\n",
        "criterionCONTENT = PerceptualLoss()\r\n",
        "criterionL1 = nn.L1Loss()\r\n",
        "criterionMSE = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP6Lr9sTPhSL"
      },
      "source": [
        "# setup optimizer\r\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\r\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr * 0.1, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TzXshGnPj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2329ec72-5d3e-4e76-c766-0250b426d4a6"
      },
      "source": [
        "print('---------- Networks initialized -------------')\r\n",
        "print_network(netG)\r\n",
        "print_network(netD)\r\n",
        "print('-----------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- Networks initialized -------------\n",
            "InpaintGenerator(\n",
            "  (encoder): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "  )\n",
            "  (middle): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (4): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (5): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (6): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (7): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 10765187\n",
            "Discriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 2764800\n",
            "-----------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHE6eEPIPmhx"
      },
      "source": [
        "real_a = torch.FloatTensor(batchSize, input_nc, 256, 256)\r\n",
        "real_b = torch.FloatTensor(batchSize, output_nc, 256, 256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cp-1DnRPrcM"
      },
      "source": [
        "if cuda:\r\n",
        "    netD = netD.cuda()\r\n",
        "    netG = netG.cuda()\r\n",
        "    criterionGAN = criterionGAN.cuda()\r\n",
        "    criterionL1 = criterionL1.cuda()\r\n",
        "    critertionSTYLE = criterionSTYLE.cuda()\r\n",
        "    criterionCONTENT = criterionCONTENT.cuda()\r\n",
        "    criterionMSE = criterionMSE.cuda()\r\n",
        "    real_a = real_a.cuda()\r\n",
        "    real_b = real_b.cuda()\r\n",
        "\r\n",
        "real_a = Variable(real_a)\r\n",
        "real_b = Variable(real_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jZpTDafPzv9"
      },
      "source": [
        "def train(epoch):\r\n",
        "\r\n",
        "    for iteration, batch in enumerate(training_data_loader, 1):\r\n",
        "        # forward\r\n",
        "        real_a_cpu, real_b_cpu = batch[0], batch[1]\r\n",
        "        with torch.no_grad():\r\n",
        "          real_a.resize_(real_a_cpu.size()).copy_(real_a_cpu)\r\n",
        "          real_b.resize_(real_b_cpu.size()).copy_(real_b_cpu)\r\n",
        "        \r\n",
        "        input_joined = real_a\r\n",
        "\r\n",
        "        fake_b = netG(input_joined)\r\n",
        "\r\n",
        "        ############################\r\n",
        "        # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))\r\n",
        "        ###########################\r\n",
        "\r\n",
        "        optimizerD.zero_grad()\r\n",
        "\r\n",
        "        # train with fake\r\n",
        "        fake_ab = torch.cat((real_a, fake_b), 1)\r\n",
        "        pred_fake = netD.forward(fake_ab.detach())\r\n",
        "        loss_d_fake = criterionGAN(pred_fake,False,True)\r\n",
        "\r\n",
        "        # train with real\r\n",
        "        real_ab = torch.cat((real_a, real_b), 1)\r\n",
        "        pred_real = netD.forward(real_ab)\r\n",
        "        loss_d_real = criterionGAN(pred_real, True, True) \r\n",
        "\r\n",
        "\r\n",
        "        # Combined loss\r\n",
        "        loss_d = (loss_d_fake + loss_d_real) * 0.5\r\n",
        "\r\n",
        "        loss_d.backward()\r\n",
        "\r\n",
        "        #Discriminator parameters update every 12 iterations \r\n",
        "        if (iteration == 1 or iteration % 12 == 0):\r\n",
        "            optimizerD.step()\r\n",
        "\r\n",
        "        ############################\r\n",
        "        # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))\r\n",
        "        ##########################\r\n",
        "        optimizerG.zero_grad()\r\n",
        "\r\n",
        "        # First, G(A) should fake the discriminator\r\n",
        "        fake_ab = torch.cat((real_a, fake_b), 1)\r\n",
        "        pred_fake = netD.forward(fake_ab)\r\n",
        "        loss_g_gan = criterionGAN(pred_fake, True, False)\r\n",
        "\r\n",
        "        # Second, G(A) = B\r\n",
        "        loss_g_l1 = criterionL1(fake_b, real_b) * L1lamb\r\n",
        "        loss_g = loss_g_gan + loss_g_l1\r\n",
        "\r\n",
        "        loss_g_style = criterionSTYLE(fake_b,real_b) * Stylelamb\r\n",
        "        loss_g = loss_g + loss_g_style\r\n",
        "\r\n",
        "        loss_g_content = criterionCONTENT(fake_b,real_b) * Contentlamb\r\n",
        "        loss_g = loss_g + loss_g_content\r\n",
        "\r\n",
        "        loss_g.backward()\r\n",
        "\r\n",
        "        optimizerG.step()\r\n",
        "\r\n",
        "        if (iteration % 7 == 0):\r\n",
        "            logs = [(\"epoc\", epoch),(\"iter\", iteration),(\"Loss_G\", loss_g.item()),(\"Loss_D\", loss_d.item()), (\"Loss_G_adv\",loss_g_gan.item()),(\"Loss_G_L1\",loss_g_l1.item()),(\"Loss_G_style\",loss_g_style.item()),(\"Loss_G_content\",loss_g_content.item()),(\"Loss_D_Real\",loss_d_real.item()),(\"Loss_D_Fake\",loss_d_fake.item())]\r\n",
        "            log_train_data(logs)\r\n",
        "\r\n",
        "        if (iteration % 7 == 0):\r\n",
        "            sample(iteration)\r\n",
        "\r\n",
        "\r\n",
        "        print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f} LossD_Fake: {:.4f} LossD_Real: {:.4f}  LossG_Adv: {:.4f} LossG_L1: {:.4f} LossG_Style {:.4f} LossG_Content {:.4f}\".format(\r\n",
        "           epoch, iteration, len(training_data_loader), loss_d, loss_g, loss_d_fake, loss_d_real, loss_g_gan, loss_g_l1, loss_g_style, loss_g_content))\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grV9tKdNQDer"
      },
      "source": [
        "def sample(iteration):\r\n",
        "    with torch.no_grad():\r\n",
        "\r\n",
        "        input,target,prev_frame = next(sample_iterator)\r\n",
        "        \r\n",
        "        if cuda:\r\n",
        "            input = input.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "\r\n",
        "        pred_input = input\r\n",
        "        prediction = netG(pred_input)\r\n",
        "        prediction = postprocess(prediction)\r\n",
        "        input = postprocess(input)\r\n",
        "        target = postprocess(target)\r\n",
        "\r\n",
        "    img = stitch_images(input, target, prediction)\r\n",
        "    samples_dir = root_path + \"/samples_second\"\r\n",
        "\r\n",
        "    if not os.path.exists(samples_dir):\r\n",
        "        os.makedirs(samples_dir)\r\n",
        "\r\n",
        "    sample = dataset + \"_\" + str(epoch) + \"_\" + str(iteration).zfill(2) + \".jpg\"\r\n",
        "    print('\\nsaving sample ' + sample + ' - learning rate: ' + str(lr))\r\n",
        "    img.save(os.path.join(samples_dir, sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc16nvL7QMGV"
      },
      "source": [
        "def log_train_data(loginfo):\r\n",
        "    log_dir = root_path + \"/logs_second\"\r\n",
        "    if not os.path.exists(log_dir):\r\n",
        "        os.makedirs(log_dir)\r\n",
        "    log_file = log_dir + \"/\" + logfile\r\n",
        "    with open(log_file, 'a') as f:\r\n",
        "        f.write('%s\\n' % ' '.join([str(item[1]) for item in loginfo]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y65ILFkOsSNF"
      },
      "source": [
        "def checkpoint(epoch):\r\n",
        "    checkpoint_dir = root_path + '/checkpoint_second'\r\n",
        "    if not os.path.exists(checkpoint_dir):\r\n",
        "        os.makedirs(checkpoint_dir)\r\n",
        "\r\n",
        "    net_g_model_out_path = checkpoint_dir + \"/netG_weights_epoch_{}.pth\".format(epoch)\r\n",
        "    net_d_model_out_path = checkpoint_dir + \"/netD_weights_epoch_{}.pth\".format(epoch)\r\n",
        "\r\n",
        "    torch.save({'generator': netG.state_dict()}, net_g_model_out_path)\r\n",
        "    torch.save({'discriminator': netD.state_dict()}, net_d_model_out_path)\r\n",
        "    \r\n",
        "    print(\"Checkpoint saved to {}\".format(\"checkpoint\" + dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUULk4yQYsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46cc844-49ff-4167-b6a4-8dcc3a5197cd"
      },
      "source": [
        "for epoch in range(1, nEpochs + 1):\r\n",
        "    train(epoch)\r\n",
        "    checkpoint(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Epoch[1](1/7): Loss_D: 0.6832 Loss_G: 10.0857 LossD_Fake: 0.6447 LossD_Real: 0.7217  LossG_Adv: 0.7350 LossG_L1: 3.6607 LossG_Style 5.6899 LossG_Content 0.0000\n",
            "===> Epoch[1](2/7): Loss_D: 0.6893 Loss_G: 9.2321 LossD_Fake: 0.6586 LossD_Real: 0.7200  LossG_Adv: 0.7250 LossG_L1: 3.5780 LossG_Style 4.9291 LossG_Content 0.0000\n",
            "===> Epoch[1](3/7): Loss_D: 0.6916 Loss_G: 9.9341 LossD_Fake: 0.6648 LossD_Real: 0.7183  LossG_Adv: 0.7210 LossG_L1: 3.6031 LossG_Style 5.6099 LossG_Content 0.0000\n",
            "===> Epoch[1](4/7): Loss_D: 0.6903 Loss_G: 9.4275 LossD_Fake: 0.6659 LossD_Real: 0.7146  LossG_Adv: 0.7206 LossG_L1: 3.6140 LossG_Style 5.0929 LossG_Content 0.0000\n",
            "===> Epoch[1](5/7): Loss_D: 0.6920 Loss_G: 9.3819 LossD_Fake: 0.6699 LossD_Real: 0.7142  LossG_Adv: 0.7166 LossG_L1: 3.4342 LossG_Style 5.2311 LossG_Content 0.0000\n",
            "===> Epoch[1](6/7): Loss_D: 0.6936 Loss_G: 9.5503 LossD_Fake: 0.6718 LossD_Real: 0.7154  LossG_Adv: 0.7148 LossG_L1: 3.5401 LossG_Style 5.2955 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_1_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[1](7/7): Loss_D: 0.6933 Loss_G: 9.2969 LossD_Fake: 0.6739 LossD_Real: 0.7127  LossG_Adv: 0.7126 LossG_L1: 3.1536 LossG_Style 5.4307 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[2](1/7): Loss_D: 0.6940 Loss_G: 9.1855 LossD_Fake: 0.6731 LossD_Real: 0.7149  LossG_Adv: 0.7120 LossG_L1: 3.3210 LossG_Style 5.1525 LossG_Content 0.0000\n",
            "===> Epoch[2](2/7): Loss_D: 0.6925 Loss_G: 7.9715 LossD_Fake: 0.6748 LossD_Real: 0.7102  LossG_Adv: 0.7117 LossG_L1: 2.9671 LossG_Style 4.2926 LossG_Content 0.0000\n",
            "===> Epoch[2](3/7): Loss_D: 0.6922 Loss_G: 8.6789 LossD_Fake: 0.6748 LossD_Real: 0.7096  LossG_Adv: 0.7118 LossG_L1: 2.9986 LossG_Style 4.9686 LossG_Content 0.0000\n",
            "===> Epoch[2](4/7): Loss_D: 0.6919 Loss_G: 8.8816 LossD_Fake: 0.6744 LossD_Real: 0.7095  LossG_Adv: 0.7122 LossG_L1: 3.3755 LossG_Style 4.7939 LossG_Content 0.0000\n",
            "===> Epoch[2](5/7): Loss_D: 0.6937 Loss_G: 8.3432 LossD_Fake: 0.6765 LossD_Real: 0.7108  LossG_Adv: 0.7100 LossG_L1: 3.2282 LossG_Style 4.4050 LossG_Content 0.0000\n",
            "===> Epoch[2](6/7): Loss_D: 0.6935 Loss_G: 8.5397 LossD_Fake: 0.6769 LossD_Real: 0.7100  LossG_Adv: 0.7096 LossG_L1: 3.1768 LossG_Style 4.6533 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_2_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[2](7/7): Loss_D: 0.6935 Loss_G: 8.7462 LossD_Fake: 0.6769 LossD_Real: 0.7101  LossG_Adv: 0.7097 LossG_L1: 3.4663 LossG_Style 4.5703 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[3](1/7): Loss_D: 0.6931 Loss_G: 8.8041 LossD_Fake: 0.6764 LossD_Real: 0.7099  LossG_Adv: 0.7095 LossG_L1: 3.0969 LossG_Style 4.9977 LossG_Content 0.0000\n",
            "===> Epoch[3](2/7): Loss_D: 0.6932 Loss_G: 7.7186 LossD_Fake: 0.6777 LossD_Real: 0.7086  LossG_Adv: 0.7089 LossG_L1: 3.0890 LossG_Style 3.9208 LossG_Content 0.0000\n",
            "===> Epoch[3](3/7): Loss_D: 0.6933 Loss_G: 8.3693 LossD_Fake: 0.6786 LossD_Real: 0.7080  LossG_Adv: 0.7079 LossG_L1: 2.9401 LossG_Style 4.7214 LossG_Content 0.0000\n",
            "===> Epoch[3](4/7): Loss_D: 0.6926 Loss_G: 8.0321 LossD_Fake: 0.6770 LossD_Real: 0.7081  LossG_Adv: 0.7096 LossG_L1: 3.0992 LossG_Style 4.2234 LossG_Content 0.0000\n",
            "===> Epoch[3](5/7): Loss_D: 0.6930 Loss_G: 7.7977 LossD_Fake: 0.6787 LossD_Real: 0.7074  LossG_Adv: 0.7079 LossG_L1: 2.9153 LossG_Style 4.1745 LossG_Content 0.0000\n",
            "===> Epoch[3](6/7): Loss_D: 0.6930 Loss_G: 7.8098 LossD_Fake: 0.6785 LossD_Real: 0.7075  LossG_Adv: 0.7081 LossG_L1: 2.8638 LossG_Style 4.2379 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_3_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[3](7/7): Loss_D: 0.6943 Loss_G: 9.2922 LossD_Fake: 0.6791 LossD_Real: 0.7095  LossG_Adv: 0.7074 LossG_L1: 3.2495 LossG_Style 5.3353 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[4](1/7): Loss_D: 0.6935 Loss_G: 8.2704 LossD_Fake: 0.6788 LossD_Real: 0.7082  LossG_Adv: 0.7074 LossG_L1: 3.0569 LossG_Style 4.5061 LossG_Content 0.0000\n",
            "===> Epoch[4](2/7): Loss_D: 0.6928 Loss_G: 7.8460 LossD_Fake: 0.6793 LossD_Real: 0.7063  LossG_Adv: 0.7072 LossG_L1: 2.7734 LossG_Style 4.3654 LossG_Content 0.0000\n",
            "===> Epoch[4](3/7): Loss_D: 0.6932 Loss_G: 7.7137 LossD_Fake: 0.6800 LossD_Real: 0.7064  LossG_Adv: 0.7065 LossG_L1: 2.7239 LossG_Style 4.2834 LossG_Content 0.0000\n",
            "===> Epoch[4](4/7): Loss_D: 0.6939 Loss_G: 8.3433 LossD_Fake: 0.6804 LossD_Real: 0.7074  LossG_Adv: 0.7060 LossG_L1: 2.9646 LossG_Style 4.6727 LossG_Content 0.0000\n",
            "===> Epoch[4](5/7): Loss_D: 0.6928 Loss_G: 8.3747 LossD_Fake: 0.6788 LossD_Real: 0.7067  LossG_Adv: 0.7077 LossG_L1: 3.0660 LossG_Style 4.6010 LossG_Content 0.0000\n",
            "===> Epoch[4](6/7): Loss_D: 0.6937 Loss_G: 8.3698 LossD_Fake: 0.6800 LossD_Real: 0.7074  LossG_Adv: 0.7065 LossG_L1: 3.0890 LossG_Style 4.5743 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_4_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[4](7/7): Loss_D: 0.6919 Loss_G: 7.3267 LossD_Fake: 0.6792 LossD_Real: 0.7045  LossG_Adv: 0.7073 LossG_L1: 2.9115 LossG_Style 3.7078 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[5](1/7): Loss_D: 0.6943 Loss_G: 8.0786 LossD_Fake: 0.6797 LossD_Real: 0.7089  LossG_Adv: 0.7075 LossG_L1: 3.0562 LossG_Style 4.3149 LossG_Content 0.0000\n",
            "===> Epoch[5](2/7): Loss_D: 0.6924 Loss_G: 7.7315 LossD_Fake: 0.6789 LossD_Real: 0.7059  LossG_Adv: 0.7077 LossG_L1: 3.0034 LossG_Style 4.0204 LossG_Content 0.0000\n",
            "===> Epoch[5](3/7): Loss_D: 0.6927 Loss_G: 8.0153 LossD_Fake: 0.6790 LossD_Real: 0.7063  LossG_Adv: 0.7075 LossG_L1: 2.9495 LossG_Style 4.3583 LossG_Content 0.0000\n",
            "===> Epoch[5](4/7): Loss_D: 0.6922 Loss_G: 7.8334 LossD_Fake: 0.6790 LossD_Real: 0.7054  LossG_Adv: 0.7075 LossG_L1: 2.6541 LossG_Style 4.4719 LossG_Content 0.0000\n",
            "===> Epoch[5](5/7): Loss_D: 0.6934 Loss_G: 7.2747 LossD_Fake: 0.6796 LossD_Real: 0.7072  LossG_Adv: 0.7069 LossG_L1: 2.7862 LossG_Style 3.7816 LossG_Content 0.0000\n",
            "===> Epoch[5](6/7): Loss_D: 0.6926 Loss_G: 8.1553 LossD_Fake: 0.6793 LossD_Real: 0.7060  LossG_Adv: 0.7073 LossG_L1: 2.8850 LossG_Style 4.5631 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_5_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[5](7/7): Loss_D: 0.6932 Loss_G: 7.6436 LossD_Fake: 0.6791 LossD_Real: 0.7072  LossG_Adv: 0.7074 LossG_L1: 2.7885 LossG_Style 4.1476 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[6](1/7): Loss_D: 0.6928 Loss_G: 7.5261 LossD_Fake: 0.6792 LossD_Real: 0.7063  LossG_Adv: 0.7065 LossG_L1: 2.7248 LossG_Style 4.0948 LossG_Content 0.0000\n",
            "===> Epoch[6](2/7): Loss_D: 0.6922 Loss_G: 7.8056 LossD_Fake: 0.6798 LossD_Real: 0.7047  LossG_Adv: 0.7067 LossG_L1: 2.7808 LossG_Style 4.3181 LossG_Content 0.0000\n",
            "===> Epoch[6](3/7): Loss_D: 0.6930 Loss_G: 7.5315 LossD_Fake: 0.6800 LossD_Real: 0.7060  LossG_Adv: 0.7065 LossG_L1: 3.0298 LossG_Style 3.7951 LossG_Content 0.0000\n",
            "===> Epoch[6](4/7): Loss_D: 0.6920 Loss_G: 7.6969 LossD_Fake: 0.6794 LossD_Real: 0.7045  LossG_Adv: 0.7071 LossG_L1: 2.8287 LossG_Style 4.1611 LossG_Content 0.0000\n",
            "===> Epoch[6](5/7): Loss_D: 0.6925 Loss_G: 7.4054 LossD_Fake: 0.6802 LossD_Real: 0.7049  LossG_Adv: 0.7063 LossG_L1: 2.7091 LossG_Style 3.9900 LossG_Content 0.0000\n",
            "===> Epoch[6](6/7): Loss_D: 0.6929 Loss_G: 7.1915 LossD_Fake: 0.6800 LossD_Real: 0.7058  LossG_Adv: 0.7065 LossG_L1: 2.7880 LossG_Style 3.6970 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_6_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[6](7/7): Loss_D: 0.6923 Loss_G: 7.8553 LossD_Fake: 0.6800 LossD_Real: 0.7046  LossG_Adv: 0.7066 LossG_L1: 3.1385 LossG_Style 4.0102 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[7](1/7): Loss_D: 0.6931 Loss_G: 7.4004 LossD_Fake: 0.6800 LossD_Real: 0.7062  LossG_Adv: 0.7054 LossG_L1: 2.8285 LossG_Style 3.8665 LossG_Content 0.0000\n",
            "===> Epoch[7](2/7): Loss_D: 0.6921 Loss_G: 6.8984 LossD_Fake: 0.6810 LossD_Real: 0.7033  LossG_Adv: 0.7055 LossG_L1: 2.5930 LossG_Style 3.5999 LossG_Content 0.0000\n",
            "===> Epoch[7](3/7): Loss_D: 0.6926 Loss_G: 7.3074 LossD_Fake: 0.6813 LossD_Real: 0.7039  LossG_Adv: 0.7051 LossG_L1: 2.9388 LossG_Style 3.6635 LossG_Content 0.0000\n",
            "===> Epoch[7](4/7): Loss_D: 0.6918 Loss_G: 7.3205 LossD_Fake: 0.6807 LossD_Real: 0.7029  LossG_Adv: 0.7057 LossG_L1: 2.6023 LossG_Style 4.0124 LossG_Content 0.0000\n",
            "===> Epoch[7](5/7): Loss_D: 0.6920 Loss_G: 7.4352 LossD_Fake: 0.6805 LossD_Real: 0.7035  LossG_Adv: 0.7060 LossG_L1: 2.7548 LossG_Style 3.9744 LossG_Content 0.0000\n",
            "===> Epoch[7](6/7): Loss_D: 0.6924 Loss_G: 8.2840 LossD_Fake: 0.6818 LossD_Real: 0.7030  LossG_Adv: 0.7046 LossG_L1: 3.0721 LossG_Style 4.5073 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_7_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[7](7/7): Loss_D: 0.6929 Loss_G: 7.8354 LossD_Fake: 0.6817 LossD_Real: 0.7040  LossG_Adv: 0.7047 LossG_L1: 2.8256 LossG_Style 4.3050 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[8](1/7): Loss_D: 0.6927 Loss_G: 7.5427 LossD_Fake: 0.6812 LossD_Real: 0.7042  LossG_Adv: 0.7040 LossG_L1: 2.9462 LossG_Style 3.8924 LossG_Content 0.0000\n",
            "===> Epoch[8](2/7): Loss_D: 0.6918 Loss_G: 7.0417 LossD_Fake: 0.6825 LossD_Real: 0.7011  LossG_Adv: 0.7039 LossG_L1: 2.6771 LossG_Style 3.6606 LossG_Content 0.0000\n",
            "===> Epoch[8](3/7): Loss_D: 0.6918 Loss_G: 7.3347 LossD_Fake: 0.6822 LossD_Real: 0.7014  LossG_Adv: 0.7042 LossG_L1: 2.8738 LossG_Style 3.7567 LossG_Content 0.0000\n",
            "===> Epoch[8](4/7): Loss_D: 0.6925 Loss_G: 7.3659 LossD_Fake: 0.6830 LossD_Real: 0.7020  LossG_Adv: 0.7035 LossG_L1: 2.7822 LossG_Style 3.8803 LossG_Content 0.0000\n",
            "===> Epoch[8](5/7): Loss_D: 0.6924 Loss_G: 6.9875 LossD_Fake: 0.6827 LossD_Real: 0.7020  LossG_Adv: 0.7037 LossG_L1: 2.6904 LossG_Style 3.5934 LossG_Content 0.0000\n",
            "===> Epoch[8](6/7): Loss_D: 0.6920 Loss_G: 7.3886 LossD_Fake: 0.6829 LossD_Real: 0.7011  LossG_Adv: 0.7035 LossG_L1: 2.7223 LossG_Style 3.9628 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_8_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[8](7/7): Loss_D: 0.6924 Loss_G: 7.2292 LossD_Fake: 0.6834 LossD_Real: 0.7013  LossG_Adv: 0.7030 LossG_L1: 2.9489 LossG_Style 3.5773 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[9](1/7): Loss_D: 0.6919 Loss_G: 7.5274 LossD_Fake: 0.6829 LossD_Real: 0.7009  LossG_Adv: 0.7027 LossG_L1: 2.7417 LossG_Style 4.0830 LossG_Content 0.0000\n",
            "===> Epoch[9](2/7): Loss_D: 0.6918 Loss_G: 7.0661 LossD_Fake: 0.6832 LossD_Real: 0.7005  LossG_Adv: 0.7033 LossG_L1: 2.8115 LossG_Style 3.5513 LossG_Content 0.0000\n",
            "===> Epoch[9](3/7): Loss_D: 0.6917 Loss_G: 7.5473 LossD_Fake: 0.6834 LossD_Real: 0.7001  LossG_Adv: 0.7031 LossG_L1: 2.8027 LossG_Style 4.0415 LossG_Content 0.0000\n",
            "===> Epoch[9](4/7): Loss_D: 0.6916 Loss_G: 6.9725 LossD_Fake: 0.6836 LossD_Real: 0.6996  LossG_Adv: 0.7029 LossG_L1: 2.7977 LossG_Style 3.4719 LossG_Content 0.0000\n",
            "===> Epoch[9](5/7): Loss_D: 0.6922 Loss_G: 6.2686 LossD_Fake: 0.6835 LossD_Real: 0.7009  LossG_Adv: 0.7029 LossG_L1: 2.5585 LossG_Style 3.0071 LossG_Content 0.0000\n",
            "===> Epoch[9](6/7): Loss_D: 0.6918 Loss_G: 7.0958 LossD_Fake: 0.6828 LossD_Real: 0.7008  LossG_Adv: 0.7037 LossG_L1: 2.7872 LossG_Style 3.6050 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_9_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[9](7/7): Loss_D: 0.6926 Loss_G: 6.1259 LossD_Fake: 0.6830 LossD_Real: 0.7022  LossG_Adv: 0.7035 LossG_L1: 2.5247 LossG_Style 2.8978 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[10](1/7): Loss_D: 0.6919 Loss_G: 6.6868 LossD_Fake: 0.6827 LossD_Real: 0.7010  LossG_Adv: 0.7030 LossG_L1: 2.6305 LossG_Style 3.3532 LossG_Content 0.0000\n",
            "===> Epoch[10](2/7): Loss_D: 0.6911 Loss_G: 6.9331 LossD_Fake: 0.6835 LossD_Real: 0.6987  LossG_Adv: 0.7030 LossG_L1: 2.6064 LossG_Style 3.6237 LossG_Content 0.0000\n",
            "===> Epoch[10](3/7): Loss_D: 0.6917 Loss_G: 6.4547 LossD_Fake: 0.6837 LossD_Real: 0.6996  LossG_Adv: 0.7027 LossG_L1: 2.6962 LossG_Style 3.0558 LossG_Content 0.0000\n",
            "===> Epoch[10](4/7): Loss_D: 0.6914 Loss_G: 6.8808 LossD_Fake: 0.6839 LossD_Real: 0.6990  LossG_Adv: 0.7025 LossG_L1: 2.7556 LossG_Style 3.4227 LossG_Content 0.0000\n",
            "===> Epoch[10](5/7): Loss_D: 0.6917 Loss_G: 7.1366 LossD_Fake: 0.6845 LossD_Real: 0.6990  LossG_Adv: 0.7019 LossG_L1: 2.7570 LossG_Style 3.6777 LossG_Content 0.0000\n",
            "===> Epoch[10](6/7): Loss_D: 0.6915 Loss_G: 7.2985 LossD_Fake: 0.6844 LossD_Real: 0.6987  LossG_Adv: 0.7020 LossG_L1: 2.8492 LossG_Style 3.7473 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_10_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[10](7/7): Loss_D: 0.6925 Loss_G: 6.7323 LossD_Fake: 0.6844 LossD_Real: 0.7006  LossG_Adv: 0.7020 LossG_L1: 2.6521 LossG_Style 3.3782 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[11](1/7): Loss_D: 0.6916 Loss_G: 7.0685 LossD_Fake: 0.6850 LossD_Real: 0.6982  LossG_Adv: 0.7005 LossG_L1: 2.8600 LossG_Style 3.5081 LossG_Content 0.0000\n",
            "===> Epoch[11](2/7): Loss_D: 0.6917 Loss_G: 6.7183 LossD_Fake: 0.6860 LossD_Real: 0.6974  LossG_Adv: 0.7004 LossG_L1: 2.5356 LossG_Style 3.4823 LossG_Content 0.0000\n",
            "===> Epoch[11](3/7): Loss_D: 0.6921 Loss_G: 6.7299 LossD_Fake: 0.6859 LossD_Real: 0.6983  LossG_Adv: 0.7004 LossG_L1: 2.6220 LossG_Style 3.4074 LossG_Content 0.0000\n",
            "===> Epoch[11](4/7): Loss_D: 0.6914 Loss_G: 6.5546 LossD_Fake: 0.6844 LossD_Real: 0.6984  LossG_Adv: 0.7021 LossG_L1: 2.7848 LossG_Style 3.0678 LossG_Content 0.0000\n",
            "===> Epoch[11](5/7): Loss_D: 0.6915 Loss_G: 6.5432 LossD_Fake: 0.6850 LossD_Real: 0.6979  LossG_Adv: 0.7014 LossG_L1: 2.6738 LossG_Style 3.1681 LossG_Content 0.0000\n",
            "===> Epoch[11](6/7): Loss_D: 0.6912 Loss_G: 6.5001 LossD_Fake: 0.6842 LossD_Real: 0.6982  LossG_Adv: 0.7022 LossG_L1: 2.7438 LossG_Style 3.0541 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_11_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[11](7/7): Loss_D: 0.6924 Loss_G: 5.9371 LossD_Fake: 0.6857 LossD_Real: 0.6991  LossG_Adv: 0.7006 LossG_L1: 2.4950 LossG_Style 2.7414 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[12](1/7): Loss_D: 0.6916 Loss_G: 6.2406 LossD_Fake: 0.6848 LossD_Real: 0.6985  LossG_Adv: 0.7031 LossG_L1: 2.5012 LossG_Style 3.0363 LossG_Content 0.0000\n",
            "===> Epoch[12](2/7): Loss_D: 0.6909 Loss_G: 6.9093 LossD_Fake: 0.6832 LossD_Real: 0.6985  LossG_Adv: 0.7032 LossG_L1: 2.7878 LossG_Style 3.4183 LossG_Content 0.0000\n",
            "===> Epoch[12](3/7): Loss_D: 0.6912 Loss_G: 6.5286 LossD_Fake: 0.6832 LossD_Real: 0.6991  LossG_Adv: 0.7032 LossG_L1: 2.6851 LossG_Style 3.1404 LossG_Content 0.0000\n",
            "===> Epoch[12](4/7): Loss_D: 0.6914 Loss_G: 6.8348 LossD_Fake: 0.6833 LossD_Real: 0.6994  LossG_Adv: 0.7031 LossG_L1: 2.6002 LossG_Style 3.5315 LossG_Content 0.0000\n",
            "===> Epoch[12](5/7): Loss_D: 0.6912 Loss_G: 6.9965 LossD_Fake: 0.6843 LossD_Real: 0.6982  LossG_Adv: 0.7021 LossG_L1: 2.7725 LossG_Style 3.5219 LossG_Content 0.0000\n",
            "===> Epoch[12](6/7): Loss_D: 0.6914 Loss_G: 6.4265 LossD_Fake: 0.6846 LossD_Real: 0.6982  LossG_Adv: 0.7019 LossG_L1: 2.6175 LossG_Style 3.1071 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_12_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[12](7/7): Loss_D: 0.6925 Loss_G: 5.9177 LossD_Fake: 0.6839 LossD_Real: 0.7010  LossG_Adv: 0.7025 LossG_L1: 2.7044 LossG_Style 2.5108 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[13](1/7): Loss_D: 0.6906 Loss_G: 6.7246 LossD_Fake: 0.6834 LossD_Real: 0.6979  LossG_Adv: 0.7007 LossG_L1: 2.7078 LossG_Style 3.3160 LossG_Content 0.0000\n",
            "===> Epoch[13](2/7): Loss_D: 0.6921 Loss_G: 6.3939 LossD_Fake: 0.6872 LossD_Real: 0.6969  LossG_Adv: 0.6992 LossG_L1: 2.7619 LossG_Style 2.9328 LossG_Content 0.0000\n",
            "===> Epoch[13](3/7): Loss_D: 0.6916 Loss_G: 6.5900 LossD_Fake: 0.6864 LossD_Real: 0.6969  LossG_Adv: 0.7000 LossG_L1: 2.7351 LossG_Style 3.1550 LossG_Content 0.0000\n",
            "===> Epoch[13](4/7): Loss_D: 0.6909 Loss_G: 6.4123 LossD_Fake: 0.6863 LossD_Real: 0.6954  LossG_Adv: 0.7000 LossG_L1: 2.7896 LossG_Style 2.9226 LossG_Content 0.0000\n",
            "===> Epoch[13](5/7): Loss_D: 0.6908 Loss_G: 6.4330 LossD_Fake: 0.6853 LossD_Real: 0.6963  LossG_Adv: 0.7011 LossG_L1: 2.6203 LossG_Style 3.1115 LossG_Content 0.0000\n",
            "===> Epoch[13](6/7): Loss_D: 0.6908 Loss_G: 6.2779 LossD_Fake: 0.6860 LossD_Real: 0.6956  LossG_Adv: 0.7004 LossG_L1: 2.6103 LossG_Style 2.9672 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_13_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[13](7/7): Loss_D: 0.6906 Loss_G: 6.4863 LossD_Fake: 0.6863 LossD_Real: 0.6950  LossG_Adv: 0.7001 LossG_L1: 2.3691 LossG_Style 3.4172 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[14](1/7): Loss_D: 0.6913 Loss_G: 5.9198 LossD_Fake: 0.6868 LossD_Real: 0.6958  LossG_Adv: 0.6985 LossG_L1: 2.5969 LossG_Style 2.6244 LossG_Content 0.0000\n",
            "===> Epoch[14](2/7): Loss_D: 0.6905 Loss_G: 6.1760 LossD_Fake: 0.6875 LossD_Real: 0.6935  LossG_Adv: 0.6989 LossG_L1: 2.6004 LossG_Style 2.8767 LossG_Content 0.0000\n",
            "===> Epoch[14](3/7): Loss_D: 0.6917 Loss_G: 6.1640 LossD_Fake: 0.6876 LossD_Real: 0.6958  LossG_Adv: 0.6987 LossG_L1: 2.6604 LossG_Style 2.8049 LossG_Content 0.0000\n",
            "===> Epoch[14](4/7): Loss_D: 0.6903 Loss_G: 6.6864 LossD_Fake: 0.6869 LossD_Real: 0.6936  LossG_Adv: 0.6995 LossG_L1: 2.7168 LossG_Style 3.2701 LossG_Content 0.0000\n",
            "===> Epoch[14](5/7): Loss_D: 0.6922 Loss_G: 6.7326 LossD_Fake: 0.6890 LossD_Real: 0.6954  LossG_Adv: 0.6974 LossG_L1: 2.6151 LossG_Style 3.4202 LossG_Content 0.0000\n",
            "===> Epoch[14](6/7): Loss_D: 0.6911 Loss_G: 6.6827 LossD_Fake: 0.6879 LossD_Real: 0.6943  LossG_Adv: 0.6985 LossG_L1: 2.5941 LossG_Style 3.3901 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_14_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[14](7/7): Loss_D: 0.6908 Loss_G: 5.9693 LossD_Fake: 0.6871 LossD_Real: 0.6946  LossG_Adv: 0.6993 LossG_L1: 2.5761 LossG_Style 2.6938 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[15](1/7): Loss_D: 0.6911 Loss_G: 6.2460 LossD_Fake: 0.6880 LossD_Real: 0.6941  LossG_Adv: 0.6969 LossG_L1: 2.4993 LossG_Style 3.0498 LossG_Content 0.0000\n",
            "===> Epoch[15](2/7): Loss_D: 0.6912 Loss_G: 6.5706 LossD_Fake: 0.6899 LossD_Real: 0.6924  LossG_Adv: 0.6964 LossG_L1: 2.4890 LossG_Style 3.3852 LossG_Content 0.0000\n",
            "===> Epoch[15](3/7): Loss_D: 0.6911 Loss_G: 5.7797 LossD_Fake: 0.6892 LossD_Real: 0.6931  LossG_Adv: 0.6972 LossG_L1: 2.4966 LossG_Style 2.5860 LossG_Content 0.0000\n",
            "===> Epoch[15](4/7): Loss_D: 0.6912 Loss_G: 6.6635 LossD_Fake: 0.6906 LossD_Real: 0.6918  LossG_Adv: 0.6957 LossG_L1: 2.6728 LossG_Style 3.2951 LossG_Content 0.0000\n",
            "===> Epoch[15](5/7): Loss_D: 0.6916 Loss_G: 5.9509 LossD_Fake: 0.6902 LossD_Real: 0.6930  LossG_Adv: 0.6961 LossG_L1: 2.6692 LossG_Style 2.5855 LossG_Content 0.0000\n",
            "===> Epoch[15](6/7): Loss_D: 0.6912 Loss_G: 6.3824 LossD_Fake: 0.6891 LossD_Real: 0.6933  LossG_Adv: 0.6972 LossG_L1: 2.6117 LossG_Style 3.0734 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_15_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[15](7/7): Loss_D: 0.6908 Loss_G: 6.7221 LossD_Fake: 0.6894 LossD_Real: 0.6922  LossG_Adv: 0.6969 LossG_L1: 3.0571 LossG_Style 2.9681 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[16](1/7): Loss_D: 0.6906 Loss_G: 6.4115 LossD_Fake: 0.6881 LossD_Real: 0.6931  LossG_Adv: 0.6971 LossG_L1: 2.8279 LossG_Style 2.8864 LossG_Content 0.0000\n",
            "===> Epoch[16](2/7): Loss_D: 0.6912 Loss_G: 6.5254 LossD_Fake: 0.6925 LossD_Real: 0.6899  LossG_Adv: 0.6938 LossG_L1: 2.8776 LossG_Style 2.9540 LossG_Content 0.0000\n",
            "===> Epoch[16](3/7): Loss_D: 0.6909 Loss_G: 6.1323 LossD_Fake: 0.6910 LossD_Real: 0.6909  LossG_Adv: 0.6953 LossG_L1: 2.7017 LossG_Style 2.7353 LossG_Content 0.0000\n",
            "===> Epoch[16](4/7): Loss_D: 0.6911 Loss_G: 6.0191 LossD_Fake: 0.6905 LossD_Real: 0.6917  LossG_Adv: 0.6958 LossG_L1: 2.5427 LossG_Style 2.7806 LossG_Content 0.0000\n",
            "===> Epoch[16](5/7): Loss_D: 0.6907 Loss_G: 6.2292 LossD_Fake: 0.6900 LossD_Real: 0.6914  LossG_Adv: 0.6964 LossG_L1: 2.6116 LossG_Style 2.9212 LossG_Content 0.0000\n",
            "===> Epoch[16](6/7): Loss_D: 0.6903 Loss_G: 6.1836 LossD_Fake: 0.6909 LossD_Real: 0.6897  LossG_Adv: 0.6955 LossG_L1: 2.6626 LossG_Style 2.8255 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_16_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[16](7/7): Loss_D: 0.6918 Loss_G: 7.4388 LossD_Fake: 0.6927 LossD_Real: 0.6909  LossG_Adv: 0.6936 LossG_L1: 2.5242 LossG_Style 4.2210 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[17](1/7): Loss_D: 0.6911 Loss_G: 6.1348 LossD_Fake: 0.6900 LossD_Real: 0.6921  LossG_Adv: 0.6984 LossG_L1: 2.6791 LossG_Style 2.7574 LossG_Content 0.0000\n",
            "===> Epoch[17](2/7): Loss_D: 0.6903 Loss_G: 6.7436 LossD_Fake: 0.6884 LossD_Real: 0.6922  LossG_Adv: 0.6979 LossG_L1: 2.6232 LossG_Style 3.4224 LossG_Content 0.0000\n",
            "===> Epoch[17](3/7): Loss_D: 0.6907 Loss_G: 5.7713 LossD_Fake: 0.6893 LossD_Real: 0.6921  LossG_Adv: 0.6971 LossG_L1: 2.4611 LossG_Style 2.6131 LossG_Content 0.0000\n",
            "===> Epoch[17](4/7): Loss_D: 0.6899 Loss_G: 6.7543 LossD_Fake: 0.6892 LossD_Real: 0.6906  LossG_Adv: 0.6971 LossG_L1: 2.6182 LossG_Style 3.4389 LossG_Content 0.0000\n",
            "===> Epoch[17](5/7): Loss_D: 0.6915 Loss_G: 6.3186 LossD_Fake: 0.6906 LossD_Real: 0.6924  LossG_Adv: 0.6957 LossG_L1: 2.5879 LossG_Style 3.0350 LossG_Content 0.0000\n",
            "===> Epoch[17](6/7): Loss_D: 0.6904 Loss_G: 6.0005 LossD_Fake: 0.6897 LossD_Real: 0.6912  LossG_Adv: 0.6967 LossG_L1: 2.4686 LossG_Style 2.8352 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_17_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[17](7/7): Loss_D: 0.6927 Loss_G: 5.7200 LossD_Fake: 0.6900 LossD_Real: 0.6954  LossG_Adv: 0.6964 LossG_L1: 2.8000 LossG_Style 2.2236 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[18](1/7): Loss_D: 0.6899 Loss_G: 6.4575 LossD_Fake: 0.6885 LossD_Real: 0.6913  LossG_Adv: 0.6960 LossG_L1: 2.4922 LossG_Style 3.2693 LossG_Content 0.0000\n",
            "===> Epoch[18](2/7): Loss_D: 0.6920 Loss_G: 6.2686 LossD_Fake: 0.6933 LossD_Real: 0.6908  LossG_Adv: 0.6931 LossG_L1: 2.8131 LossG_Style 2.7625 LossG_Content 0.0000\n",
            "===> Epoch[18](3/7): Loss_D: 0.6910 Loss_G: 5.6709 LossD_Fake: 0.6916 LossD_Real: 0.6904  LossG_Adv: 0.6947 LossG_L1: 2.4689 LossG_Style 2.5073 LossG_Content 0.0000\n",
            "===> Epoch[18](4/7): Loss_D: 0.6906 Loss_G: 5.9710 LossD_Fake: 0.6917 LossD_Real: 0.6895  LossG_Adv: 0.6947 LossG_L1: 2.4421 LossG_Style 2.8343 LossG_Content 0.0000\n",
            "===> Epoch[18](5/7): Loss_D: 0.6903 Loss_G: 5.9010 LossD_Fake: 0.6915 LossD_Real: 0.6892  LossG_Adv: 0.6949 LossG_L1: 2.5226 LossG_Style 2.6836 LossG_Content 0.0000\n",
            "===> Epoch[18](6/7): Loss_D: 0.6897 Loss_G: 6.0338 LossD_Fake: 0.6909 LossD_Real: 0.6885  LossG_Adv: 0.6955 LossG_L1: 2.6382 LossG_Style 2.7001 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_18_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[18](7/7): Loss_D: 0.6913 Loss_G: 5.9360 LossD_Fake: 0.6932 LossD_Real: 0.6894  LossG_Adv: 0.6931 LossG_L1: 2.7174 LossG_Style 2.5254 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[19](1/7): Loss_D: 0.6893 Loss_G: 6.1242 LossD_Fake: 0.6909 LossD_Real: 0.6877  LossG_Adv: 0.6937 LossG_L1: 2.5391 LossG_Style 2.8915 LossG_Content 0.0000\n",
            "===> Epoch[19](2/7): Loss_D: 0.6917 Loss_G: 6.1272 LossD_Fake: 0.6961 LossD_Real: 0.6873  LossG_Adv: 0.6903 LossG_L1: 2.6756 LossG_Style 2.7614 LossG_Content 0.0000\n",
            "===> Epoch[19](3/7): Loss_D: 0.6908 Loss_G: 5.7537 LossD_Fake: 0.6944 LossD_Real: 0.6872  LossG_Adv: 0.6920 LossG_L1: 2.4805 LossG_Style 2.5812 LossG_Content 0.0000\n",
            "===> Epoch[19](4/7): Loss_D: 0.6909 Loss_G: 5.9662 LossD_Fake: 0.6940 LossD_Real: 0.6877  LossG_Adv: 0.6924 LossG_L1: 2.4811 LossG_Style 2.7927 LossG_Content 0.0000\n",
            "===> Epoch[19](5/7): Loss_D: 0.6905 Loss_G: 5.7981 LossD_Fake: 0.6930 LossD_Real: 0.6880  LossG_Adv: 0.6934 LossG_L1: 2.4545 LossG_Style 2.6502 LossG_Content 0.0000\n",
            "===> Epoch[19](6/7): Loss_D: 0.6903 Loss_G: 5.7238 LossD_Fake: 0.6938 LossD_Real: 0.6868  LossG_Adv: 0.6926 LossG_L1: 2.4610 LossG_Style 2.5703 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_19_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[19](7/7): Loss_D: 0.6890 Loss_G: 6.0888 LossD_Fake: 0.6941 LossD_Real: 0.6838  LossG_Adv: 0.6923 LossG_L1: 2.6765 LossG_Style 2.7200 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[20](1/7): Loss_D: 0.6900 Loss_G: 5.8744 LossD_Fake: 0.6936 LossD_Real: 0.6864  LossG_Adv: 0.6934 LossG_L1: 2.4341 LossG_Style 2.7469 LossG_Content 0.0000\n",
            "===> Epoch[20](2/7): Loss_D: 0.6912 Loss_G: 6.2341 LossD_Fake: 0.6951 LossD_Real: 0.6872  LossG_Adv: 0.6913 LossG_L1: 2.6852 LossG_Style 2.8576 LossG_Content 0.0000\n",
            "===> Epoch[20](3/7): Loss_D: 0.6906 Loss_G: 5.7802 LossD_Fake: 0.6944 LossD_Real: 0.6869  LossG_Adv: 0.6920 LossG_L1: 2.5933 LossG_Style 2.4950 LossG_Content 0.0000\n",
            "===> Epoch[20](4/7): Loss_D: 0.6894 Loss_G: 6.1672 LossD_Fake: 0.6931 LossD_Real: 0.6857  LossG_Adv: 0.6932 LossG_L1: 2.6814 LossG_Style 2.7926 LossG_Content 0.0000\n",
            "===> Epoch[20](5/7): Loss_D: 0.6911 Loss_G: 5.3152 LossD_Fake: 0.6941 LossD_Real: 0.6882  LossG_Adv: 0.6923 LossG_L1: 2.2995 LossG_Style 2.3235 LossG_Content 0.0000\n",
            "===> Epoch[20](6/7): Loss_D: 0.6891 Loss_G: 6.4426 LossD_Fake: 0.6932 LossD_Real: 0.6851  LossG_Adv: 0.6931 LossG_L1: 2.5419 LossG_Style 3.2076 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_20_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[20](7/7): Loss_D: 0.6953 Loss_G: 5.3938 LossD_Fake: 0.6945 LossD_Real: 0.6962  LossG_Adv: 0.6919 LossG_L1: 2.4405 LossG_Style 2.2614 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[21](1/7): Loss_D: 0.6892 Loss_G: 6.1605 LossD_Fake: 0.6921 LossD_Real: 0.6862  LossG_Adv: 0.6931 LossG_L1: 2.6041 LossG_Style 2.8632 LossG_Content 0.0000\n",
            "===> Epoch[21](2/7): Loss_D: 0.6894 Loss_G: 5.4898 LossD_Fake: 0.6928 LossD_Real: 0.6859  LossG_Adv: 0.6936 LossG_L1: 2.2574 LossG_Style 2.5388 LossG_Content 0.0000\n",
            "===> Epoch[21](3/7): Loss_D: 0.6902 Loss_G: 6.2996 LossD_Fake: 0.6952 LossD_Real: 0.6852  LossG_Adv: 0.6912 LossG_L1: 2.6781 LossG_Style 2.9303 LossG_Content 0.0000\n",
            "===> Epoch[21](4/7): Loss_D: 0.6903 Loss_G: 5.9446 LossD_Fake: 0.6940 LossD_Real: 0.6867  LossG_Adv: 0.6924 LossG_L1: 2.4568 LossG_Style 2.7953 LossG_Content 0.0000\n",
            "===> Epoch[21](5/7): Loss_D: 0.6909 Loss_G: 5.9614 LossD_Fake: 0.6973 LossD_Real: 0.6846  LossG_Adv: 0.6891 LossG_L1: 2.6121 LossG_Style 2.6602 LossG_Content 0.0000\n",
            "===> Epoch[21](6/7): Loss_D: 0.6900 Loss_G: 5.7474 LossD_Fake: 0.6954 LossD_Real: 0.6845  LossG_Adv: 0.6910 LossG_L1: 2.3885 LossG_Style 2.6679 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_21_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[21](7/7): Loss_D: 0.6880 Loss_G: 5.6457 LossD_Fake: 0.6947 LossD_Real: 0.6813  LossG_Adv: 0.6917 LossG_L1: 2.6097 LossG_Style 2.3443 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[22](1/7): Loss_D: 0.6907 Loss_G: 5.6778 LossD_Fake: 0.6955 LossD_Real: 0.6859  LossG_Adv: 0.6922 LossG_L1: 2.5753 LossG_Style 2.4103 LossG_Content 0.0000\n",
            "===> Epoch[22](2/7): Loss_D: 0.6906 Loss_G: 5.9948 LossD_Fake: 0.6941 LossD_Real: 0.6871  LossG_Adv: 0.6923 LossG_L1: 2.5691 LossG_Style 2.7334 LossG_Content 0.0000\n",
            "===> Epoch[22](3/7): Loss_D: 0.6899 Loss_G: 5.4897 LossD_Fake: 0.6934 LossD_Real: 0.6864  LossG_Adv: 0.6930 LossG_L1: 2.4116 LossG_Style 2.3851 LossG_Content 0.0000\n",
            "===> Epoch[22](4/7): Loss_D: 0.6900 Loss_G: 6.2818 LossD_Fake: 0.6949 LossD_Real: 0.6850  LossG_Adv: 0.6915 LossG_L1: 2.5356 LossG_Style 3.0548 LossG_Content 0.0000\n",
            "===> Epoch[22](5/7): Loss_D: 0.6902 Loss_G: 5.5555 LossD_Fake: 0.6936 LossD_Real: 0.6868  LossG_Adv: 0.6927 LossG_L1: 2.4299 LossG_Style 2.4328 LossG_Content 0.0000\n",
            "===> Epoch[22](6/7): Loss_D: 0.6892 Loss_G: 5.7392 LossD_Fake: 0.6944 LossD_Real: 0.6841  LossG_Adv: 0.6920 LossG_L1: 2.5208 LossG_Style 2.5264 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_22_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[22](7/7): Loss_D: 0.6896 Loss_G: 6.3926 LossD_Fake: 0.6954 LossD_Real: 0.6838  LossG_Adv: 0.6910 LossG_L1: 2.3814 LossG_Style 3.3202 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[23](1/7): Loss_D: 0.6903 Loss_G: 6.0027 LossD_Fake: 0.6935 LossD_Real: 0.6871  LossG_Adv: 0.6932 LossG_L1: 2.5904 LossG_Style 2.7192 LossG_Content 0.0000\n",
            "===> Epoch[23](2/7): Loss_D: 0.6896 Loss_G: 5.9497 LossD_Fake: 0.6948 LossD_Real: 0.6844  LossG_Adv: 0.6916 LossG_L1: 2.5538 LossG_Style 2.7043 LossG_Content 0.0000\n",
            "===> Epoch[23](3/7): Loss_D: 0.6914 Loss_G: 5.6552 LossD_Fake: 0.6965 LossD_Real: 0.6863  LossG_Adv: 0.6899 LossG_L1: 2.4075 LossG_Style 2.5577 LossG_Content 0.0000\n",
            "===> Epoch[23](4/7): Loss_D: 0.6891 Loss_G: 5.7299 LossD_Fake: 0.6937 LossD_Real: 0.6844  LossG_Adv: 0.6927 LossG_L1: 2.3825 LossG_Style 2.6546 LossG_Content 0.0000\n",
            "===> Epoch[23](5/7): Loss_D: 0.6904 Loss_G: 5.9284 LossD_Fake: 0.6956 LossD_Real: 0.6851  LossG_Adv: 0.6908 LossG_L1: 2.6219 LossG_Style 2.6157 LossG_Content 0.0000\n",
            "===> Epoch[23](6/7): Loss_D: 0.6904 Loss_G: 5.4972 LossD_Fake: 0.6940 LossD_Real: 0.6867  LossG_Adv: 0.6924 LossG_L1: 2.4109 LossG_Style 2.3939 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_23_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[23](7/7): Loss_D: 0.6893 Loss_G: 5.5647 LossD_Fake: 0.6946 LossD_Real: 0.6840  LossG_Adv: 0.6918 LossG_L1: 2.3691 LossG_Style 2.5038 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[24](1/7): Loss_D: 0.6908 Loss_G: 5.5358 LossD_Fake: 0.6960 LossD_Real: 0.6856  LossG_Adv: 0.6933 LossG_L1: 2.4196 LossG_Style 2.4230 LossG_Content 0.0000\n",
            "===> Epoch[24](2/7): Loss_D: 0.6908 Loss_G: 5.5850 LossD_Fake: 0.6921 LossD_Real: 0.6896  LossG_Adv: 0.6943 LossG_L1: 2.3840 LossG_Style 2.5067 LossG_Content 0.0000\n",
            "===> Epoch[24](3/7): Loss_D: 0.6902 Loss_G: 5.7380 LossD_Fake: 0.6921 LossD_Real: 0.6883  LossG_Adv: 0.6943 LossG_L1: 2.4068 LossG_Style 2.6369 LossG_Content 0.0000\n",
            "===> Epoch[24](4/7): Loss_D: 0.6901 Loss_G: 5.5183 LossD_Fake: 0.6926 LossD_Real: 0.6875  LossG_Adv: 0.6937 LossG_L1: 2.4092 LossG_Style 2.4154 LossG_Content 0.0000\n",
            "===> Epoch[24](5/7): Loss_D: 0.6884 Loss_G: 5.9437 LossD_Fake: 0.6900 LossD_Real: 0.6868  LossG_Adv: 0.6964 LossG_L1: 2.6757 LossG_Style 2.5716 LossG_Content 0.0000\n",
            "===> Epoch[24](6/7): Loss_D: 0.6907 Loss_G: 5.8776 LossD_Fake: 0.6951 LossD_Real: 0.6863  LossG_Adv: 0.6913 LossG_L1: 2.4870 LossG_Style 2.6994 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_24_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[24](7/7): Loss_D: 0.6921 Loss_G: 5.9356 LossD_Fake: 0.6943 LossD_Real: 0.6899  LossG_Adv: 0.6921 LossG_L1: 2.3174 LossG_Style 2.9260 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[25](1/7): Loss_D: 0.6892 Loss_G: 5.6648 LossD_Fake: 0.6906 LossD_Real: 0.6878  LossG_Adv: 0.6929 LossG_L1: 2.3554 LossG_Style 2.6165 LossG_Content 0.0000\n",
            "===> Epoch[25](2/7): Loss_D: 0.6898 Loss_G: 5.7116 LossD_Fake: 0.6955 LossD_Real: 0.6841  LossG_Adv: 0.6909 LossG_L1: 2.3951 LossG_Style 2.6256 LossG_Content 0.0000\n",
            "===> Epoch[25](3/7): Loss_D: 0.6897 Loss_G: 5.5542 LossD_Fake: 0.6955 LossD_Real: 0.6839  LossG_Adv: 0.6909 LossG_L1: 2.2651 LossG_Style 2.5982 LossG_Content 0.0000\n",
            "===> Epoch[25](4/7): Loss_D: 0.6897 Loss_G: 5.3989 LossD_Fake: 0.6955 LossD_Real: 0.6840  LossG_Adv: 0.6909 LossG_L1: 2.3530 LossG_Style 2.3550 LossG_Content 0.0000\n",
            "===> Epoch[25](5/7): Loss_D: 0.6892 Loss_G: 5.5187 LossD_Fake: 0.6957 LossD_Real: 0.6828  LossG_Adv: 0.6907 LossG_L1: 2.4696 LossG_Style 2.3584 LossG_Content 0.0000\n",
            "===> Epoch[25](6/7): Loss_D: 0.6895 Loss_G: 5.6169 LossD_Fake: 0.6952 LossD_Real: 0.6839  LossG_Adv: 0.6913 LossG_L1: 2.5467 LossG_Style 2.3789 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_25_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[25](7/7): Loss_D: 0.6901 Loss_G: 6.5113 LossD_Fake: 0.6986 LossD_Real: 0.6815  LossG_Adv: 0.6878 LossG_L1: 2.5399 LossG_Style 3.2836 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[26](1/7): Loss_D: 0.6916 Loss_G: 5.8513 LossD_Fake: 0.6982 LossD_Real: 0.6850  LossG_Adv: 0.6921 LossG_L1: 2.4351 LossG_Style 2.7240 LossG_Content 0.0000\n",
            "===> Epoch[26](2/7): Loss_D: 0.6886 Loss_G: 6.2200 LossD_Fake: 0.6919 LossD_Real: 0.6852  LossG_Adv: 0.6944 LossG_L1: 2.6365 LossG_Style 2.8891 LossG_Content 0.0000\n",
            "===> Epoch[26](3/7): Loss_D: 0.6899 Loss_G: 5.4119 LossD_Fake: 0.6927 LossD_Real: 0.6870  LossG_Adv: 0.6936 LossG_L1: 2.3333 LossG_Style 2.3849 LossG_Content 0.0000\n",
            "===> Epoch[26](4/7): Loss_D: 0.6899 Loss_G: 5.3436 LossD_Fake: 0.6918 LossD_Real: 0.6880  LossG_Adv: 0.6945 LossG_L1: 2.3259 LossG_Style 2.3232 LossG_Content 0.0000\n",
            "===> Epoch[26](5/7): Loss_D: 0.6903 Loss_G: 5.5412 LossD_Fake: 0.6926 LossD_Real: 0.6880  LossG_Adv: 0.6938 LossG_L1: 2.4088 LossG_Style 2.4386 LossG_Content 0.0000\n",
            "===> Epoch[26](6/7): Loss_D: 0.6887 Loss_G: 5.8613 LossD_Fake: 0.6924 LossD_Real: 0.6850  LossG_Adv: 0.6940 LossG_L1: 2.4393 LossG_Style 2.7280 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_26_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[26](7/7): Loss_D: 0.6921 Loss_G: 5.4655 LossD_Fake: 0.6944 LossD_Real: 0.6897  LossG_Adv: 0.6919 LossG_L1: 2.3600 LossG_Style 2.4136 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[27](1/7): Loss_D: 0.6889 Loss_G: 5.7914 LossD_Fake: 0.6895 LossD_Real: 0.6883  LossG_Adv: 0.6966 LossG_L1: 2.3958 LossG_Style 2.6990 LossG_Content 0.0000\n",
            "===> Epoch[27](2/7): Loss_D: 0.6896 Loss_G: 5.6395 LossD_Fake: 0.6939 LossD_Real: 0.6852  LossG_Adv: 0.6924 LossG_L1: 2.4111 LossG_Style 2.5359 LossG_Content 0.0000\n",
            "===> Epoch[27](3/7): Loss_D: 0.6887 Loss_G: 5.6075 LossD_Fake: 0.6919 LossD_Real: 0.6855  LossG_Adv: 0.6945 LossG_L1: 2.5939 LossG_Style 2.3190 LossG_Content 0.0000\n",
            "===> Epoch[27](4/7): Loss_D: 0.6897 Loss_G: 5.6423 LossD_Fake: 0.6939 LossD_Real: 0.6855  LossG_Adv: 0.6925 LossG_L1: 2.3682 LossG_Style 2.5816 LossG_Content 0.0000\n",
            "===> Epoch[27](5/7): Loss_D: 0.6899 Loss_G: 5.8192 LossD_Fake: 0.6943 LossD_Real: 0.6856  LossG_Adv: 0.6921 LossG_L1: 2.4836 LossG_Style 2.6434 LossG_Content 0.0000\n",
            "===> Epoch[27](6/7): Loss_D: 0.6916 Loss_G: 5.7187 LossD_Fake: 0.6960 LossD_Real: 0.6871  LossG_Adv: 0.6904 LossG_L1: 2.6249 LossG_Style 2.4034 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_27_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[27](7/7): Loss_D: 0.6885 Loss_G: 6.0584 LossD_Fake: 0.6928 LossD_Real: 0.6841  LossG_Adv: 0.6936 LossG_L1: 2.7959 LossG_Style 2.5690 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[28](1/7): Loss_D: 0.6893 Loss_G: 6.1302 LossD_Fake: 0.6945 LossD_Real: 0.6841  LossG_Adv: 0.6934 LossG_L1: 2.5244 LossG_Style 2.9123 LossG_Content 0.0000\n",
            "===> Epoch[28](2/7): Loss_D: 0.6896 Loss_G: 5.5602 LossD_Fake: 0.6914 LossD_Real: 0.6878  LossG_Adv: 0.6950 LossG_L1: 2.5089 LossG_Style 2.3564 LossG_Content 0.0000\n",
            "===> Epoch[28](3/7): Loss_D: 0.6898 Loss_G: 5.5532 LossD_Fake: 0.6921 LossD_Real: 0.6874  LossG_Adv: 0.6943 LossG_L1: 2.4588 LossG_Style 2.4001 LossG_Content 0.0000\n",
            "===> Epoch[28](4/7): Loss_D: 0.6881 Loss_G: 5.7827 LossD_Fake: 0.6904 LossD_Real: 0.6857  LossG_Adv: 0.6960 LossG_L1: 2.4426 LossG_Style 2.6441 LossG_Content 0.0000\n",
            "===> Epoch[28](5/7): Loss_D: 0.6913 Loss_G: 5.1105 LossD_Fake: 0.6938 LossD_Real: 0.6888  LossG_Adv: 0.6926 LossG_L1: 2.1685 LossG_Style 2.2494 LossG_Content 0.0000\n",
            "===> Epoch[28](6/7): Loss_D: 0.6907 Loss_G: 5.5512 LossD_Fake: 0.6941 LossD_Real: 0.6873  LossG_Adv: 0.6923 LossG_L1: 2.3512 LossG_Style 2.5077 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_28_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[28](7/7): Loss_D: 0.6884 Loss_G: 5.5503 LossD_Fake: 0.6917 LossD_Real: 0.6851  LossG_Adv: 0.6947 LossG_L1: 2.4658 LossG_Style 2.3898 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[29](1/7): Loss_D: 0.6896 Loss_G: 5.6754 LossD_Fake: 0.6934 LossD_Real: 0.6858  LossG_Adv: 0.6957 LossG_L1: 2.5023 LossG_Style 2.4774 LossG_Content 0.0000\n",
            "===> Epoch[29](2/7): Loss_D: 0.6886 Loss_G: 5.4858 LossD_Fake: 0.6899 LossD_Real: 0.6874  LossG_Adv: 0.6965 LossG_L1: 2.3876 LossG_Style 2.4016 LossG_Content 0.0000\n",
            "===> Epoch[29](3/7): Loss_D: 0.6897 Loss_G: 5.5754 LossD_Fake: 0.6913 LossD_Real: 0.6880  LossG_Adv: 0.6951 LossG_L1: 2.4163 LossG_Style 2.4641 LossG_Content 0.0000\n",
            "===> Epoch[29](4/7): Loss_D: 0.6907 Loss_G: 5.2322 LossD_Fake: 0.6912 LossD_Real: 0.6902  LossG_Adv: 0.6952 LossG_L1: 2.2001 LossG_Style 2.3369 LossG_Content 0.0000\n",
            "===> Epoch[29](5/7): Loss_D: 0.6894 Loss_G: 5.4890 LossD_Fake: 0.6882 LossD_Real: 0.6906  LossG_Adv: 0.6982 LossG_L1: 2.4214 LossG_Style 2.3694 LossG_Content 0.0000\n",
            "===> Epoch[29](6/7): Loss_D: 0.6911 Loss_G: 5.7128 LossD_Fake: 0.6912 LossD_Real: 0.6910  LossG_Adv: 0.6952 LossG_L1: 2.3396 LossG_Style 2.6779 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_29_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[29](7/7): Loss_D: 0.6884 Loss_G: 5.9714 LossD_Fake: 0.6907 LossD_Real: 0.6862  LossG_Adv: 0.6957 LossG_L1: 2.3964 LossG_Style 2.8793 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[30](1/7): Loss_D: 0.6902 Loss_G: 5.7925 LossD_Fake: 0.6895 LossD_Real: 0.6908  LossG_Adv: 0.6950 LossG_L1: 2.4457 LossG_Style 2.6518 LossG_Content 0.0000\n",
            "===> Epoch[30](2/7): Loss_D: 0.6901 Loss_G: 5.4847 LossD_Fake: 0.6935 LossD_Real: 0.6868  LossG_Adv: 0.6929 LossG_L1: 2.4198 LossG_Style 2.3719 LossG_Content 0.0000\n",
            "===> Epoch[30](3/7): Loss_D: 0.6881 Loss_G: 5.5735 LossD_Fake: 0.6909 LossD_Real: 0.6854  LossG_Adv: 0.6955 LossG_L1: 2.3898 LossG_Style 2.4881 LossG_Content 0.0000\n",
            "===> Epoch[30](4/7): Loss_D: 0.6895 Loss_G: 5.5007 LossD_Fake: 0.6927 LossD_Real: 0.6863  LossG_Adv: 0.6937 LossG_L1: 2.3234 LossG_Style 2.4837 LossG_Content 0.0000\n",
            "===> Epoch[30](5/7): Loss_D: 0.6890 Loss_G: 5.2552 LossD_Fake: 0.6921 LossD_Real: 0.6858  LossG_Adv: 0.6943 LossG_L1: 2.2970 LossG_Style 2.2639 LossG_Content 0.0000\n",
            "===> Epoch[30](6/7): Loss_D: 0.6894 Loss_G: 5.0106 LossD_Fake: 0.6916 LossD_Real: 0.6873  LossG_Adv: 0.6949 LossG_L1: 2.2410 LossG_Style 2.0747 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_30_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[30](7/7): Loss_D: 0.6899 Loss_G: 5.4805 LossD_Fake: 0.6927 LossD_Real: 0.6871  LossG_Adv: 0.6937 LossG_L1: 2.2085 LossG_Style 2.5783 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[31](1/7): Loss_D: 0.6893 Loss_G: 5.5157 LossD_Fake: 0.6917 LossD_Real: 0.6869  LossG_Adv: 0.6976 LossG_L1: 2.4214 LossG_Style 2.3967 LossG_Content 0.0000\n",
            "===> Epoch[31](2/7): Loss_D: 0.6885 Loss_G: 5.9071 LossD_Fake: 0.6887 LossD_Real: 0.6884  LossG_Adv: 0.6978 LossG_L1: 2.3754 LossG_Style 2.8339 LossG_Content 0.0000\n",
            "===> Epoch[31](3/7): Loss_D: 0.6888 Loss_G: 5.3843 LossD_Fake: 0.6895 LossD_Real: 0.6882  LossG_Adv: 0.6969 LossG_L1: 2.3147 LossG_Style 2.3726 LossG_Content 0.0000\n",
            "===> Epoch[31](4/7): Loss_D: 0.6888 Loss_G: 5.8587 LossD_Fake: 0.6903 LossD_Real: 0.6873  LossG_Adv: 0.6961 LossG_L1: 2.4492 LossG_Style 2.7134 LossG_Content 0.0000\n",
            "===> Epoch[31](5/7): Loss_D: 0.6915 Loss_G: 5.3931 LossD_Fake: 0.6939 LossD_Real: 0.6891  LossG_Adv: 0.6925 LossG_L1: 2.2051 LossG_Style 2.4955 LossG_Content 0.0000\n",
            "===> Epoch[31](6/7): Loss_D: 0.6887 Loss_G: 5.2019 LossD_Fake: 0.6861 LossD_Real: 0.6912  LossG_Adv: 0.7003 LossG_L1: 2.3205 LossG_Style 2.1811 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_31_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[31](7/7): Loss_D: 0.6926 Loss_G: 5.7137 LossD_Fake: 0.6934 LossD_Real: 0.6919  LossG_Adv: 0.6930 LossG_L1: 2.5558 LossG_Style 2.4649 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[32](1/7): Loss_D: 0.6876 Loss_G: 5.7287 LossD_Fake: 0.6866 LossD_Real: 0.6886  LossG_Adv: 0.6958 LossG_L1: 2.5310 LossG_Style 2.5019 LossG_Content 0.0000\n",
            "===> Epoch[32](2/7): Loss_D: 0.6880 Loss_G: 5.5150 LossD_Fake: 0.6930 LossD_Real: 0.6830  LossG_Adv: 0.6935 LossG_L1: 2.5204 LossG_Style 2.3011 LossG_Content 0.0000\n",
            "===> Epoch[32](3/7): Loss_D: 0.6889 Loss_G: 5.1461 LossD_Fake: 0.6924 LossD_Real: 0.6854  LossG_Adv: 0.6941 LossG_L1: 2.2348 LossG_Style 2.2173 LossG_Content 0.0000\n",
            "===> Epoch[32](4/7): Loss_D: 0.6881 Loss_G: 5.3996 LossD_Fake: 0.6937 LossD_Real: 0.6824  LossG_Adv: 0.6928 LossG_L1: 2.4114 LossG_Style 2.2954 LossG_Content 0.0000\n",
            "===> Epoch[32](5/7): Loss_D: 0.6888 Loss_G: 5.1202 LossD_Fake: 0.6933 LossD_Real: 0.6842  LossG_Adv: 0.6931 LossG_L1: 2.1650 LossG_Style 2.2621 LossG_Content 0.0000\n",
            "===> Epoch[32](6/7): Loss_D: 0.6891 Loss_G: 5.5712 LossD_Fake: 0.6945 LossD_Real: 0.6838  LossG_Adv: 0.6920 LossG_L1: 2.4266 LossG_Style 2.4526 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_32_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[32](7/7): Loss_D: 0.6879 Loss_G: 6.0930 LossD_Fake: 0.6944 LossD_Real: 0.6815  LossG_Adv: 0.6921 LossG_L1: 2.3021 LossG_Style 3.0989 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[33](1/7): Loss_D: 0.6898 Loss_G: 5.7231 LossD_Fake: 0.6954 LossD_Real: 0.6843  LossG_Adv: 0.6957 LossG_L1: 2.4738 LossG_Style 2.5535 LossG_Content 0.0000\n",
            "===> Epoch[33](2/7): Loss_D: 0.6889 Loss_G: 5.4787 LossD_Fake: 0.6884 LossD_Real: 0.6895  LossG_Adv: 0.6980 LossG_L1: 2.3650 LossG_Style 2.4156 LossG_Content 0.0000\n",
            "===> Epoch[33](3/7): Loss_D: 0.6872 Loss_G: 5.2750 LossD_Fake: 0.6878 LossD_Real: 0.6866  LossG_Adv: 0.6987 LossG_L1: 2.1841 LossG_Style 2.3923 LossG_Content 0.0000\n",
            "===> Epoch[33](4/7): Loss_D: 0.6905 Loss_G: 5.2119 LossD_Fake: 0.6923 LossD_Real: 0.6887  LossG_Adv: 0.6941 LossG_L1: 2.2924 LossG_Style 2.2253 LossG_Content 0.0000\n",
            "===> Epoch[33](5/7): Loss_D: 0.6872 Loss_G: 5.6562 LossD_Fake: 0.6899 LossD_Real: 0.6845  LossG_Adv: 0.6966 LossG_L1: 2.3783 LossG_Style 2.5814 LossG_Content 0.0000\n",
            "===> Epoch[33](6/7): Loss_D: 0.6901 Loss_G: 5.1115 LossD_Fake: 0.6915 LossD_Real: 0.6887  LossG_Adv: 0.6950 LossG_L1: 2.2024 LossG_Style 2.2141 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_33_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[33](7/7): Loss_D: 0.6861 Loss_G: 6.1300 LossD_Fake: 0.6884 LossD_Real: 0.6837  LossG_Adv: 0.6980 LossG_L1: 2.7476 LossG_Style 2.6844 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[34](1/7): Loss_D: 0.6890 Loss_G: 5.4065 LossD_Fake: 0.6881 LossD_Real: 0.6898  LossG_Adv: 0.7017 LossG_L1: 2.4012 LossG_Style 2.3036 LossG_Content 0.0000\n",
            "===> Epoch[34](2/7): Loss_D: 0.6868 Loss_G: 5.9941 LossD_Fake: 0.6855 LossD_Real: 0.6880  LossG_Adv: 0.7009 LossG_L1: 2.3400 LossG_Style 2.9532 LossG_Content 0.0000\n",
            "===> Epoch[34](3/7): Loss_D: 0.6910 Loss_G: 5.4416 LossD_Fake: 0.6897 LossD_Real: 0.6923  LossG_Adv: 0.6968 LossG_L1: 2.2467 LossG_Style 2.4981 LossG_Content 0.0000\n",
            "===> Epoch[34](4/7): Loss_D: 0.6882 Loss_G: 5.1700 LossD_Fake: 0.6871 LossD_Real: 0.6894  LossG_Adv: 0.6994 LossG_L1: 2.2545 LossG_Style 2.2161 LossG_Content 0.0000\n",
            "===> Epoch[34](5/7): Loss_D: 0.6896 Loss_G: 5.4168 LossD_Fake: 0.6903 LossD_Real: 0.6889  LossG_Adv: 0.6961 LossG_L1: 2.2937 LossG_Style 2.4270 LossG_Content 0.0000\n",
            "===> Epoch[34](6/7): Loss_D: 0.6892 Loss_G: 4.9732 LossD_Fake: 0.6880 LossD_Real: 0.6904  LossG_Adv: 0.6984 LossG_L1: 2.1449 LossG_Style 2.1299 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_34_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[34](7/7): Loss_D: 0.6894 Loss_G: 4.7159 LossD_Fake: 0.6858 LossD_Real: 0.6930  LossG_Adv: 0.7007 LossG_L1: 2.1223 LossG_Style 1.8929 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[35](1/7): Loss_D: 0.6888 Loss_G: 4.8670 LossD_Fake: 0.6861 LossD_Real: 0.6916  LossG_Adv: 0.7046 LossG_L1: 2.0924 LossG_Style 2.0700 LossG_Content 0.0000\n",
            "===> Epoch[35](2/7): Loss_D: 0.6885 Loss_G: 5.7123 LossD_Fake: 0.6847 LossD_Real: 0.6922  LossG_Adv: 0.7017 LossG_L1: 2.3460 LossG_Style 2.6646 LossG_Content 0.0000\n",
            "===> Epoch[35](3/7): Loss_D: 0.6908 Loss_G: 5.1580 LossD_Fake: 0.6852 LossD_Real: 0.6965  LossG_Adv: 0.7013 LossG_L1: 2.2115 LossG_Style 2.2452 LossG_Content 0.0000\n",
            "===> Epoch[35](4/7): Loss_D: 0.6861 Loss_G: 5.3206 LossD_Fake: 0.6815 LossD_Real: 0.6907  LossG_Adv: 0.7050 LossG_L1: 2.3405 LossG_Style 2.2752 LossG_Content 0.0000\n",
            "===> Epoch[35](5/7): Loss_D: 0.6902 Loss_G: 5.5971 LossD_Fake: 0.6854 LossD_Real: 0.6950  LossG_Adv: 0.7011 LossG_L1: 2.4895 LossG_Style 2.4065 LossG_Content 0.0000\n",
            "===> Epoch[35](6/7): Loss_D: 0.6900 Loss_G: 4.9638 LossD_Fake: 0.6830 LossD_Real: 0.6970  LossG_Adv: 0.7035 LossG_L1: 2.1919 LossG_Style 2.0683 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_35_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[35](7/7): Loss_D: 0.6845 Loss_G: 5.0888 LossD_Fake: 0.6817 LossD_Real: 0.6873  LossG_Adv: 0.7049 LossG_L1: 2.2484 LossG_Style 2.1355 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[36](1/7): Loss_D: 0.6907 Loss_G: 5.7150 LossD_Fake: 0.6854 LossD_Real: 0.6961  LossG_Adv: 0.7073 LossG_L1: 2.7285 LossG_Style 2.2791 LossG_Content 0.0000\n",
            "===> Epoch[36](2/7): Loss_D: 0.6895 Loss_G: 5.6962 LossD_Fake: 0.6788 LossD_Real: 0.7001  LossG_Adv: 0.7078 LossG_L1: 2.6232 LossG_Style 2.3652 LossG_Content 0.0000\n",
            "===> Epoch[36](3/7): Loss_D: 0.6877 Loss_G: 5.6735 LossD_Fake: 0.6757 LossD_Real: 0.6996  LossG_Adv: 0.7110 LossG_L1: 2.4517 LossG_Style 2.5108 LossG_Content 0.0000\n",
            "===> Epoch[36](4/7): Loss_D: 0.6891 Loss_G: 5.9178 LossD_Fake: 0.6784 LossD_Real: 0.6998  LossG_Adv: 0.7082 LossG_L1: 2.3787 LossG_Style 2.8309 LossG_Content 0.0000\n",
            "===> Epoch[36](5/7): Loss_D: 0.6877 Loss_G: 5.5878 LossD_Fake: 0.6765 LossD_Real: 0.6989  LossG_Adv: 0.7101 LossG_L1: 2.4787 LossG_Style 2.3990 LossG_Content 0.0000\n",
            "===> Epoch[36](6/7): Loss_D: 0.6864 Loss_G: 5.7755 LossD_Fake: 0.6760 LossD_Real: 0.6968  LossG_Adv: 0.7107 LossG_L1: 2.4689 LossG_Style 2.5958 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_36_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[36](7/7): Loss_D: 0.6880 Loss_G: 6.2443 LossD_Fake: 0.6796 LossD_Real: 0.6963  LossG_Adv: 0.7069 LossG_L1: 2.8168 LossG_Style 2.7205 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[37](1/7): Loss_D: 0.6907 Loss_G: 5.7639 LossD_Fake: 0.6774 LossD_Real: 0.7039  LossG_Adv: 0.7019 LossG_L1: 2.5023 LossG_Style 2.5597 LossG_Content 0.0000\n",
            "===> Epoch[37](2/7): Loss_D: 0.6880 Loss_G: 5.7367 LossD_Fake: 0.6859 LossD_Real: 0.6901  LossG_Adv: 0.7006 LossG_L1: 2.4085 LossG_Style 2.6276 LossG_Content 0.0000\n",
            "===> Epoch[37](3/7): Loss_D: 0.6861 Loss_G: 5.6410 LossD_Fake: 0.6831 LossD_Real: 0.6891  LossG_Adv: 0.7034 LossG_L1: 2.5942 LossG_Style 2.3434 LossG_Content 0.0000\n",
            "===> Epoch[37](4/7): Loss_D: 0.6894 Loss_G: 5.5408 LossD_Fake: 0.6888 LossD_Real: 0.6901  LossG_Adv: 0.6977 LossG_L1: 2.4637 LossG_Style 2.3794 LossG_Content 0.0000\n",
            "===> Epoch[37](5/7): Loss_D: 0.6870 Loss_G: 5.2120 LossD_Fake: 0.6858 LossD_Real: 0.6882  LossG_Adv: 0.7007 LossG_L1: 2.4123 LossG_Style 2.0990 LossG_Content 0.0000\n",
            "===> Epoch[37](6/7): Loss_D: 0.6890 Loss_G: 5.5667 LossD_Fake: 0.6867 LossD_Real: 0.6914  LossG_Adv: 0.6997 LossG_L1: 2.3472 LossG_Style 2.5198 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_37_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[37](7/7): Loss_D: 0.6893 Loss_G: 5.0628 LossD_Fake: 0.6852 LossD_Real: 0.6933  LossG_Adv: 0.7012 LossG_L1: 2.1305 LossG_Style 2.2310 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[38](1/7): Loss_D: 0.6886 Loss_G: 5.2728 LossD_Fake: 0.6843 LossD_Real: 0.6929  LossG_Adv: 0.7002 LossG_L1: 2.4111 LossG_Style 2.1615 LossG_Content 0.0000\n",
            "===> Epoch[38](2/7): Loss_D: 0.6870 Loss_G: 5.2904 LossD_Fake: 0.6867 LossD_Real: 0.6872  LossG_Adv: 0.6997 LossG_L1: 2.2593 LossG_Style 2.3313 LossG_Content 0.0000\n",
            "===> Epoch[38](3/7): Loss_D: 0.6872 Loss_G: 4.9077 LossD_Fake: 0.6872 LossD_Real: 0.6873  LossG_Adv: 0.6992 LossG_L1: 2.1228 LossG_Style 2.0858 LossG_Content 0.0000\n",
            "===> Epoch[38](4/7): Loss_D: 0.6879 Loss_G: 5.1833 LossD_Fake: 0.6878 LossD_Real: 0.6880  LossG_Adv: 0.6986 LossG_L1: 2.2561 LossG_Style 2.2286 LossG_Content 0.0000\n",
            "===> Epoch[38](5/7): Loss_D: 0.6885 Loss_G: 5.3081 LossD_Fake: 0.6901 LossD_Real: 0.6869  LossG_Adv: 0.6962 LossG_L1: 2.2763 LossG_Style 2.3356 LossG_Content 0.0000\n",
            "===> Epoch[38](6/7): Loss_D: 0.6873 Loss_G: 5.5666 LossD_Fake: 0.6883 LossD_Real: 0.6863  LossG_Adv: 0.6982 LossG_L1: 2.4891 LossG_Style 2.3794 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_38_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[38](7/7): Loss_D: 0.6910 Loss_G: 5.5482 LossD_Fake: 0.6825 LossD_Real: 0.6996  LossG_Adv: 0.7041 LossG_L1: 2.5172 LossG_Style 2.3269 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[39](1/7): Loss_D: 0.6861 Loss_G: 5.5021 LossD_Fake: 0.6823 LossD_Real: 0.6899  LossG_Adv: 0.7031 LossG_L1: 2.3902 LossG_Style 2.4088 LossG_Content 0.0000\n",
            "===> Epoch[39](2/7): Loss_D: 0.6886 Loss_G: 5.6085 LossD_Fake: 0.6921 LossD_Real: 0.6851  LossG_Adv: 0.6943 LossG_L1: 2.4107 LossG_Style 2.5035 LossG_Content 0.0000\n",
            "===> Epoch[39](3/7): Loss_D: 0.6863 Loss_G: 5.1623 LossD_Fake: 0.6893 LossD_Real: 0.6833  LossG_Adv: 0.6971 LossG_L1: 2.2606 LossG_Style 2.2047 LossG_Content 0.0000\n",
            "===> Epoch[39](4/7): Loss_D: 0.6882 Loss_G: 5.4485 LossD_Fake: 0.6913 LossD_Real: 0.6851  LossG_Adv: 0.6951 LossG_L1: 2.3775 LossG_Style 2.3759 LossG_Content 0.0000\n",
            "===> Epoch[39](5/7): Loss_D: 0.6876 Loss_G: 5.3195 LossD_Fake: 0.6904 LossD_Real: 0.6848  LossG_Adv: 0.6960 LossG_L1: 2.2053 LossG_Style 2.4181 LossG_Content 0.0000\n",
            "===> Epoch[39](6/7): Loss_D: 0.6878 Loss_G: 5.4112 LossD_Fake: 0.6899 LossD_Real: 0.6856  LossG_Adv: 0.6965 LossG_L1: 2.4790 LossG_Style 2.2357 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_39_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[39](7/7): Loss_D: 0.6886 Loss_G: 5.1744 LossD_Fake: 0.6901 LossD_Real: 0.6870  LossG_Adv: 0.6963 LossG_L1: 2.2603 LossG_Style 2.2177 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[40](1/7): Loss_D: 0.6887 Loss_G: 5.2695 LossD_Fake: 0.6902 LossD_Real: 0.6871  LossG_Adv: 0.7012 LossG_L1: 2.2441 LossG_Style 2.3242 LossG_Content 0.0000\n",
            "===> Epoch[40](2/7): Loss_D: 0.6861 Loss_G: 4.8957 LossD_Fake: 0.6827 LossD_Real: 0.6895  LossG_Adv: 0.7038 LossG_L1: 2.1538 LossG_Style 2.0381 LossG_Content 0.0000\n",
            "===> Epoch[40](3/7): Loss_D: 0.6895 Loss_G: 5.1205 LossD_Fake: 0.6862 LossD_Real: 0.6927  LossG_Adv: 0.7002 LossG_L1: 2.2970 LossG_Style 2.1233 LossG_Content 0.0000\n",
            "===> Epoch[40](4/7): Loss_D: 0.6874 Loss_G: 5.2382 LossD_Fake: 0.6863 LossD_Real: 0.6885  LossG_Adv: 0.7002 LossG_L1: 2.0387 LossG_Style 2.4993 LossG_Content 0.0000\n",
            "===> Epoch[40](5/7): Loss_D: 0.6877 Loss_G: 5.2605 LossD_Fake: 0.6868 LossD_Real: 0.6887  LossG_Adv: 0.6997 LossG_L1: 2.3165 LossG_Style 2.2443 LossG_Content 0.0000\n",
            "===> Epoch[40](6/7): Loss_D: 0.6860 Loss_G: 5.3042 LossD_Fake: 0.6857 LossD_Real: 0.6864  LossG_Adv: 0.7008 LossG_L1: 2.2558 LossG_Style 2.3475 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_40_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[40](7/7): Loss_D: 0.6897 Loss_G: 5.0446 LossD_Fake: 0.6875 LossD_Real: 0.6919  LossG_Adv: 0.6989 LossG_L1: 2.1318 LossG_Style 2.2139 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[41](1/7): Loss_D: 0.6882 Loss_G: 5.0055 LossD_Fake: 0.6853 LossD_Real: 0.6911  LossG_Adv: 0.7038 LossG_L1: 2.1111 LossG_Style 2.1906 LossG_Content 0.0000\n",
            "===> Epoch[41](2/7): Loss_D: 0.6867 Loss_G: 5.7577 LossD_Fake: 0.6835 LossD_Real: 0.6899  LossG_Adv: 0.7030 LossG_L1: 2.4250 LossG_Style 2.6297 LossG_Content 0.0000\n",
            "===> Epoch[41](3/7): Loss_D: 0.6868 Loss_G: 5.0949 LossD_Fake: 0.6824 LossD_Real: 0.6911  LossG_Adv: 0.7041 LossG_L1: 2.1389 LossG_Style 2.2519 LossG_Content 0.0000\n",
            "===> Epoch[41](4/7): Loss_D: 0.6875 Loss_G: 4.7769 LossD_Fake: 0.6840 LossD_Real: 0.6910  LossG_Adv: 0.7025 LossG_L1: 1.9500 LossG_Style 2.1244 LossG_Content 0.0000\n",
            "===> Epoch[41](5/7): Loss_D: 0.6873 Loss_G: 5.1054 LossD_Fake: 0.6840 LossD_Real: 0.6905  LossG_Adv: 0.7024 LossG_L1: 2.2881 LossG_Style 2.1149 LossG_Content 0.0000\n",
            "===> Epoch[41](6/7): Loss_D: 0.6890 Loss_G: 5.0148 LossD_Fake: 0.6841 LossD_Real: 0.6939  LossG_Adv: 0.7024 LossG_L1: 2.2025 LossG_Style 2.1099 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_41_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[41](7/7): Loss_D: 0.6879 Loss_G: 4.8971 LossD_Fake: 0.6837 LossD_Real: 0.6921  LossG_Adv: 0.7027 LossG_L1: 2.1507 LossG_Style 2.0436 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[42](1/7): Loss_D: 0.6874 Loss_G: 5.4317 LossD_Fake: 0.6844 LossD_Real: 0.6905  LossG_Adv: 0.6963 LossG_L1: 2.1792 LossG_Style 2.5563 LossG_Content 0.0000\n",
            "===> Epoch[42](2/7): Loss_D: 0.6875 Loss_G: 5.0494 LossD_Fake: 0.6913 LossD_Real: 0.6838  LossG_Adv: 0.6952 LossG_L1: 2.1270 LossG_Style 2.2273 LossG_Content 0.0000\n",
            "===> Epoch[42](3/7): Loss_D: 0.6875 Loss_G: 5.1689 LossD_Fake: 0.6889 LossD_Real: 0.6861  LossG_Adv: 0.6975 LossG_L1: 2.1793 LossG_Style 2.2921 LossG_Content 0.0000\n",
            "===> Epoch[42](4/7): Loss_D: 0.6855 Loss_G: 4.8334 LossD_Fake: 0.6885 LossD_Real: 0.6824  LossG_Adv: 0.6979 LossG_L1: 2.1103 LossG_Style 2.0251 LossG_Content 0.0000\n",
            "===> Epoch[42](5/7): Loss_D: 0.6889 Loss_G: 4.7394 LossD_Fake: 0.6901 LossD_Real: 0.6876  LossG_Adv: 0.6963 LossG_L1: 2.0888 LossG_Style 1.9543 LossG_Content 0.0000\n",
            "===> Epoch[42](6/7): Loss_D: 0.6879 Loss_G: 5.2284 LossD_Fake: 0.6902 LossD_Real: 0.6857  LossG_Adv: 0.6963 LossG_L1: 2.1265 LossG_Style 2.4056 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_42_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[42](7/7): Loss_D: 0.6910 Loss_G: 4.2741 LossD_Fake: 0.6926 LossD_Real: 0.6893  LossG_Adv: 0.6938 LossG_L1: 1.8110 LossG_Style 1.7693 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[43](1/7): Loss_D: 0.6879 Loss_G: 5.0596 LossD_Fake: 0.6910 LossD_Real: 0.6849  LossG_Adv: 0.6933 LossG_L1: 2.1680 LossG_Style 2.1982 LossG_Content 0.0000\n",
            "===> Epoch[43](2/7): Loss_D: 0.6866 Loss_G: 5.0386 LossD_Fake: 0.6903 LossD_Real: 0.6830  LossG_Adv: 0.6961 LossG_L1: 2.1181 LossG_Style 2.2244 LossG_Content 0.0000\n",
            "===> Epoch[43](3/7): Loss_D: 0.6873 Loss_G: 4.9352 LossD_Fake: 0.6915 LossD_Real: 0.6832  LossG_Adv: 0.6950 LossG_L1: 2.0701 LossG_Style 2.1701 LossG_Content 0.0000\n",
            "===> Epoch[43](4/7): Loss_D: 0.6860 Loss_G: 5.2266 LossD_Fake: 0.6919 LossD_Real: 0.6800  LossG_Adv: 0.6945 LossG_L1: 2.1810 LossG_Style 2.3510 LossG_Content 0.0000\n",
            "===> Epoch[43](5/7): Loss_D: 0.6884 Loss_G: 5.1980 LossD_Fake: 0.6927 LossD_Real: 0.6840  LossG_Adv: 0.6937 LossG_L1: 2.1829 LossG_Style 2.3214 LossG_Content 0.0000\n",
            "===> Epoch[43](6/7): Loss_D: 0.6860 Loss_G: 5.0394 LossD_Fake: 0.6906 LossD_Real: 0.6815  LossG_Adv: 0.6959 LossG_L1: 2.2705 LossG_Style 2.0730 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_43_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[43](7/7): Loss_D: 0.6852 Loss_G: 4.7587 LossD_Fake: 0.6918 LossD_Real: 0.6786  LossG_Adv: 0.6946 LossG_L1: 2.1425 LossG_Style 1.9216 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[44](1/7): Loss_D: 0.6868 Loss_G: 4.9938 LossD_Fake: 0.6929 LossD_Real: 0.6807  LossG_Adv: 0.6959 LossG_L1: 2.0184 LossG_Style 2.2795 LossG_Content 0.0000\n",
            "===> Epoch[44](2/7): Loss_D: 0.6878 Loss_G: 4.7509 LossD_Fake: 0.6918 LossD_Real: 0.6838  LossG_Adv: 0.6946 LossG_L1: 2.0608 LossG_Style 1.9955 LossG_Content 0.0000\n",
            "===> Epoch[44](3/7): Loss_D: 0.6879 Loss_G: 4.8564 LossD_Fake: 0.6907 LossD_Real: 0.6852  LossG_Adv: 0.6958 LossG_L1: 1.9203 LossG_Style 2.2403 LossG_Content 0.0000\n",
            "===> Epoch[44](4/7): Loss_D: 0.6873 Loss_G: 5.3911 LossD_Fake: 0.6888 LossD_Real: 0.6858  LossG_Adv: 0.6976 LossG_L1: 2.2563 LossG_Style 2.4372 LossG_Content 0.0000\n",
            "===> Epoch[44](5/7): Loss_D: 0.6845 Loss_G: 5.3049 LossD_Fake: 0.6878 LossD_Real: 0.6812  LossG_Adv: 0.6987 LossG_L1: 2.2663 LossG_Style 2.3399 LossG_Content 0.0000\n",
            "===> Epoch[44](6/7): Loss_D: 0.6880 Loss_G: 5.2203 LossD_Fake: 0.6931 LossD_Real: 0.6829  LossG_Adv: 0.6933 LossG_L1: 2.4517 LossG_Style 2.0752 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_44_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[44](7/7): Loss_D: 0.6867 Loss_G: 4.5072 LossD_Fake: 0.6871 LossD_Real: 0.6863  LossG_Adv: 0.6994 LossG_L1: 1.9906 LossG_Style 1.8172 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[45](1/7): Loss_D: 0.6866 Loss_G: 5.0640 LossD_Fake: 0.6903 LossD_Real: 0.6828  LossG_Adv: 0.7037 LossG_L1: 2.1980 LossG_Style 2.1623 LossG_Content 0.0000\n",
            "===> Epoch[45](2/7): Loss_D: 0.6866 Loss_G: 4.9849 LossD_Fake: 0.6810 LossD_Real: 0.6922  LossG_Adv: 0.7055 LossG_L1: 2.0686 LossG_Style 2.2108 LossG_Content 0.0000\n",
            "===> Epoch[45](3/7): Loss_D: 0.6890 Loss_G: 5.0084 LossD_Fake: 0.6863 LossD_Real: 0.6916  LossG_Adv: 0.7002 LossG_L1: 2.1548 LossG_Style 2.1535 LossG_Content 0.0000\n",
            "===> Epoch[45](4/7): Loss_D: 0.6864 Loss_G: 4.9405 LossD_Fake: 0.6818 LossD_Real: 0.6911  LossG_Adv: 0.7047 LossG_L1: 2.1873 LossG_Style 2.0485 LossG_Content 0.0000\n",
            "===> Epoch[45](5/7): Loss_D: 0.6851 Loss_G: 4.9500 LossD_Fake: 0.6824 LossD_Real: 0.6878  LossG_Adv: 0.7041 LossG_L1: 2.0897 LossG_Style 2.1563 LossG_Content 0.0000\n",
            "===> Epoch[45](6/7): Loss_D: 0.6863 Loss_G: 4.9123 LossD_Fake: 0.6828 LossD_Real: 0.6898  LossG_Adv: 0.7038 LossG_L1: 2.0815 LossG_Style 2.1270 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_45_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[45](7/7): Loss_D: 0.6851 Loss_G: 5.4838 LossD_Fake: 0.6860 LossD_Real: 0.6842  LossG_Adv: 0.7005 LossG_L1: 2.0664 LossG_Style 2.7170 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[46](1/7): Loss_D: 0.6877 Loss_G: 5.0167 LossD_Fake: 0.6830 LossD_Real: 0.6924  LossG_Adv: 0.7033 LossG_L1: 2.2163 LossG_Style 2.0972 LossG_Content 0.0000\n",
            "===> Epoch[46](2/7): Loss_D: 0.6854 Loss_G: 5.5108 LossD_Fake: 0.6856 LossD_Real: 0.6851  LossG_Adv: 0.7009 LossG_L1: 2.2144 LossG_Style 2.5955 LossG_Content 0.0000\n",
            "===> Epoch[46](3/7): Loss_D: 0.6848 Loss_G: 5.6205 LossD_Fake: 0.6847 LossD_Real: 0.6850  LossG_Adv: 0.7018 LossG_L1: 2.2734 LossG_Style 2.6452 LossG_Content 0.0000\n",
            "===> Epoch[46](4/7): Loss_D: 0.6877 Loss_G: 4.8738 LossD_Fake: 0.6864 LossD_Real: 0.6890  LossG_Adv: 0.7001 LossG_L1: 2.1430 LossG_Style 2.0307 LossG_Content 0.0000\n",
            "===> Epoch[46](5/7): Loss_D: 0.6870 Loss_G: 5.0213 LossD_Fake: 0.6862 LossD_Real: 0.6878  LossG_Adv: 0.7003 LossG_L1: 2.1257 LossG_Style 2.1953 LossG_Content 0.0000\n",
            "===> Epoch[46](6/7): Loss_D: 0.6891 Loss_G: 4.6445 LossD_Fake: 0.6839 LossD_Real: 0.6943  LossG_Adv: 0.7026 LossG_L1: 1.9798 LossG_Style 1.9621 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_46_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[46](7/7): Loss_D: 0.6839 Loss_G: 4.2671 LossD_Fake: 0.6793 LossD_Real: 0.6886  LossG_Adv: 0.7074 LossG_L1: 1.8882 LossG_Style 1.6715 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[47](1/7): Loss_D: 0.6850 Loss_G: 5.0542 LossD_Fake: 0.6852 LossD_Real: 0.6848  LossG_Adv: 0.7005 LossG_L1: 2.1645 LossG_Style 2.1893 LossG_Content 0.0000\n",
            "===> Epoch[47](2/7): Loss_D: 0.6852 Loss_G: 4.7319 LossD_Fake: 0.6819 LossD_Real: 0.6886  LossG_Adv: 0.7047 LossG_L1: 2.0476 LossG_Style 1.9795 LossG_Content 0.0000\n",
            "===> Epoch[47](3/7): Loss_D: 0.6877 Loss_G: 4.7924 LossD_Fake: 0.6880 LossD_Real: 0.6873  LossG_Adv: 0.6984 LossG_L1: 2.0991 LossG_Style 1.9950 LossG_Content 0.0000\n",
            "===> Epoch[47](4/7): Loss_D: 0.6863 Loss_G: 5.1172 LossD_Fake: 0.6851 LossD_Real: 0.6875  LossG_Adv: 0.7014 LossG_L1: 2.2001 LossG_Style 2.2157 LossG_Content 0.0000\n",
            "===> Epoch[47](5/7): Loss_D: 0.6868 Loss_G: 4.7008 LossD_Fake: 0.6868 LossD_Real: 0.6869  LossG_Adv: 0.6997 LossG_L1: 1.9367 LossG_Style 2.0644 LossG_Content 0.0000\n",
            "===> Epoch[47](6/7): Loss_D: 0.6868 Loss_G: 4.6266 LossD_Fake: 0.6850 LossD_Real: 0.6887  LossG_Adv: 0.7015 LossG_L1: 1.9401 LossG_Style 1.9850 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_47_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[47](7/7): Loss_D: 0.6857 Loss_G: 4.9435 LossD_Fake: 0.6838 LossD_Real: 0.6877  LossG_Adv: 0.7027 LossG_L1: 2.1145 LossG_Style 2.1263 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[48](1/7): Loss_D: 0.6858 Loss_G: 4.7560 LossD_Fake: 0.6827 LossD_Real: 0.6889  LossG_Adv: 0.7011 LossG_L1: 1.9958 LossG_Style 2.0591 LossG_Content 0.0000\n",
            "===> Epoch[48](2/7): Loss_D: 0.6875 Loss_G: 4.5408 LossD_Fake: 0.6895 LossD_Real: 0.6856  LossG_Adv: 0.6969 LossG_L1: 1.8798 LossG_Style 1.9641 LossG_Content 0.0000\n",
            "===> Epoch[48](3/7): Loss_D: 0.6825 Loss_G: 5.0147 LossD_Fake: 0.6859 LossD_Real: 0.6791  LossG_Adv: 0.7006 LossG_L1: 2.1633 LossG_Style 2.1508 LossG_Content 0.0000\n",
            "===> Epoch[48](4/7): Loss_D: 0.6895 Loss_G: 4.4194 LossD_Fake: 0.6891 LossD_Real: 0.6899  LossG_Adv: 0.6974 LossG_L1: 1.8735 LossG_Style 1.8486 LossG_Content 0.0000\n",
            "===> Epoch[48](5/7): Loss_D: 0.6829 Loss_G: 5.2186 LossD_Fake: 0.6849 LossD_Real: 0.6809  LossG_Adv: 0.7016 LossG_L1: 2.2417 LossG_Style 2.2753 LossG_Content 0.0000\n",
            "===> Epoch[48](6/7): Loss_D: 0.6847 Loss_G: 4.8576 LossD_Fake: 0.6907 LossD_Real: 0.6787  LossG_Adv: 0.6958 LossG_L1: 1.9922 LossG_Style 2.1696 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_48_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[48](7/7): Loss_D: 0.6839 Loss_G: 4.7473 LossD_Fake: 0.6869 LossD_Real: 0.6809  LossG_Adv: 0.6997 LossG_L1: 2.1953 LossG_Style 1.8523 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[49](1/7): Loss_D: 0.6863 Loss_G: 5.1025 LossD_Fake: 0.6919 LossD_Real: 0.6807  LossG_Adv: 0.7029 LossG_L1: 2.2558 LossG_Style 2.1437 LossG_Content 0.0000\n",
            "===> Epoch[49](2/7): Loss_D: 0.6860 Loss_G: 4.9673 LossD_Fake: 0.6827 LossD_Real: 0.6894  LossG_Adv: 0.7039 LossG_L1: 2.1922 LossG_Style 2.0711 LossG_Content 0.0000\n",
            "===> Epoch[49](3/7): Loss_D: 0.6853 Loss_G: 5.3359 LossD_Fake: 0.6823 LossD_Real: 0.6883  LossG_Adv: 0.7042 LossG_L1: 1.9867 LossG_Style 2.6450 LossG_Content 0.0000\n",
            "===> Epoch[49](4/7): Loss_D: 0.6858 Loss_G: 4.9591 LossD_Fake: 0.6839 LossD_Real: 0.6878  LossG_Adv: 0.7026 LossG_L1: 2.0196 LossG_Style 2.2369 LossG_Content 0.0000\n",
            "===> Epoch[49](5/7): Loss_D: 0.6865 Loss_G: 5.1349 LossD_Fake: 0.6829 LossD_Real: 0.6900  LossG_Adv: 0.7036 LossG_L1: 2.1711 LossG_Style 2.2602 LossG_Content 0.0000\n",
            "===> Epoch[49](6/7): Loss_D: 0.6861 Loss_G: 4.7171 LossD_Fake: 0.6810 LossD_Real: 0.6911  LossG_Adv: 0.7056 LossG_L1: 2.0573 LossG_Style 1.9542 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_49_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[49](7/7): Loss_D: 0.6909 Loss_G: 4.1464 LossD_Fake: 0.6831 LossD_Real: 0.6986  LossG_Adv: 0.7034 LossG_L1: 1.6568 LossG_Style 1.7862 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[50](1/7): Loss_D: 0.6863 Loss_G: 4.6490 LossD_Fake: 0.6777 LossD_Real: 0.6950  LossG_Adv: 0.7003 LossG_L1: 2.0594 LossG_Style 1.8893 LossG_Content 0.0000\n",
            "===> Epoch[50](2/7): Loss_D: 0.6875 Loss_G: 5.3657 LossD_Fake: 0.6968 LossD_Real: 0.6782  LossG_Adv: 0.6898 LossG_L1: 2.1183 LossG_Style 2.5577 LossG_Content 0.0000\n",
            "===> Epoch[50](3/7): Loss_D: 0.6833 Loss_G: 4.8364 LossD_Fake: 0.6872 LossD_Real: 0.6794  LossG_Adv: 0.6993 LossG_L1: 2.1329 LossG_Style 2.0041 LossG_Content 0.0000\n",
            "===> Epoch[50](4/7): Loss_D: 0.6849 Loss_G: 4.4833 LossD_Fake: 0.6896 LossD_Real: 0.6801  LossG_Adv: 0.6969 LossG_L1: 1.9983 LossG_Style 1.7882 LossG_Content 0.0000\n",
            "===> Epoch[50](5/7): Loss_D: 0.6849 Loss_G: 5.0946 LossD_Fake: 0.6912 LossD_Real: 0.6786  LossG_Adv: 0.6953 LossG_L1: 2.0290 LossG_Style 2.3702 LossG_Content 0.0000\n",
            "===> Epoch[50](6/7): Loss_D: 0.6823 Loss_G: 4.8214 LossD_Fake: 0.6911 LossD_Real: 0.6734  LossG_Adv: 0.6953 LossG_L1: 2.0712 LossG_Style 2.0550 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_50_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[50](7/7): Loss_D: 0.6882 Loss_G: 4.6192 LossD_Fake: 0.6958 LossD_Real: 0.6807  LossG_Adv: 0.6907 LossG_L1: 1.9816 LossG_Style 1.9469 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[51](1/7): Loss_D: 0.6871 Loss_G: 4.8283 LossD_Fake: 0.6947 LossD_Real: 0.6794  LossG_Adv: 0.6998 LossG_L1: 2.0464 LossG_Style 2.0821 LossG_Content 0.0000\n",
            "===> Epoch[51](2/7): Loss_D: 0.6835 Loss_G: 4.9278 LossD_Fake: 0.6837 LossD_Real: 0.6834  LossG_Adv: 0.7029 LossG_L1: 2.1227 LossG_Style 2.1022 LossG_Content 0.0000\n",
            "===> Epoch[51](3/7): Loss_D: 0.6853 Loss_G: 4.8104 LossD_Fake: 0.6858 LossD_Real: 0.6848  LossG_Adv: 0.7007 LossG_L1: 2.1185 LossG_Style 1.9912 LossG_Content 0.0000\n",
            "===> Epoch[51](4/7): Loss_D: 0.6874 Loss_G: 4.4886 LossD_Fake: 0.6840 LossD_Real: 0.6908  LossG_Adv: 0.7025 LossG_L1: 1.8239 LossG_Style 1.9622 LossG_Content 0.0000\n",
            "===> Epoch[51](5/7): Loss_D: 0.6835 Loss_G: 4.7554 LossD_Fake: 0.6836 LossD_Real: 0.6834  LossG_Adv: 0.7029 LossG_L1: 2.0179 LossG_Style 2.0346 LossG_Content 0.0000\n",
            "===> Epoch[51](6/7): Loss_D: 0.6840 Loss_G: 4.8470 LossD_Fake: 0.6854 LossD_Real: 0.6826  LossG_Adv: 0.7012 LossG_L1: 2.0762 LossG_Style 2.0696 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_51_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[51](7/7): Loss_D: 0.6853 Loss_G: 4.7741 LossD_Fake: 0.6796 LossD_Real: 0.6910  LossG_Adv: 0.7070 LossG_L1: 2.1423 LossG_Style 1.9249 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[52](1/7): Loss_D: 0.6887 Loss_G: 5.0139 LossD_Fake: 0.6865 LossD_Real: 0.6909  LossG_Adv: 0.7013 LossG_L1: 2.1420 LossG_Style 2.1705 LossG_Content 0.0000\n",
            "===> Epoch[52](2/7): Loss_D: 0.6849 Loss_G: 4.4878 LossD_Fake: 0.6803 LossD_Real: 0.6896  LossG_Adv: 0.7063 LossG_L1: 1.8983 LossG_Style 1.8832 LossG_Content 0.0000\n",
            "===> Epoch[52](3/7): Loss_D: 0.6827 Loss_G: 4.6796 LossD_Fake: 0.6819 LossD_Real: 0.6834  LossG_Adv: 0.7046 LossG_L1: 1.9309 LossG_Style 2.0441 LossG_Content 0.0000\n",
            "===> Epoch[52](4/7): Loss_D: 0.6844 Loss_G: 5.0528 LossD_Fake: 0.6861 LossD_Real: 0.6827  LossG_Adv: 0.7004 LossG_L1: 2.1424 LossG_Style 2.2099 LossG_Content 0.0000\n",
            "===> Epoch[52](5/7): Loss_D: 0.6854 Loss_G: 4.5949 LossD_Fake: 0.6825 LossD_Real: 0.6882  LossG_Adv: 0.7041 LossG_L1: 1.9200 LossG_Style 1.9709 LossG_Content 0.0000\n",
            "===> Epoch[52](6/7): Loss_D: 0.6836 Loss_G: 4.9066 LossD_Fake: 0.6863 LossD_Real: 0.6809  LossG_Adv: 0.7003 LossG_L1: 2.1054 LossG_Style 2.1010 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_52_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[52](7/7): Loss_D: 0.6829 Loss_G: 5.1309 LossD_Fake: 0.6848 LossD_Real: 0.6811  LossG_Adv: 0.7017 LossG_L1: 2.2564 LossG_Style 2.1728 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[53](1/7): Loss_D: 0.6858 Loss_G: 5.1182 LossD_Fake: 0.6870 LossD_Real: 0.6845  LossG_Adv: 0.7074 LossG_L1: 2.1192 LossG_Style 2.2917 LossG_Content 0.0000\n",
            "===> Epoch[53](2/7): Loss_D: 0.6835 Loss_G: 5.2391 LossD_Fake: 0.6770 LossD_Real: 0.6901  LossG_Adv: 0.7097 LossG_L1: 2.0849 LossG_Style 2.4445 LossG_Content 0.0000\n",
            "===> Epoch[53](3/7): Loss_D: 0.6875 Loss_G: 4.7699 LossD_Fake: 0.6792 LossD_Real: 0.6958  LossG_Adv: 0.7075 LossG_L1: 1.8672 LossG_Style 2.1953 LossG_Content 0.0000\n",
            "===> Epoch[53](4/7): Loss_D: 0.6834 Loss_G: 4.8813 LossD_Fake: 0.6787 LossD_Real: 0.6882  LossG_Adv: 0.7080 LossG_L1: 2.0654 LossG_Style 2.1079 LossG_Content 0.0000\n",
            "===> Epoch[53](5/7): Loss_D: 0.6867 Loss_G: 4.6285 LossD_Fake: 0.6784 LossD_Real: 0.6951  LossG_Adv: 0.7083 LossG_L1: 2.0402 LossG_Style 1.8800 LossG_Content 0.0000\n",
            "===> Epoch[53](6/7): Loss_D: 0.6847 Loss_G: 4.4455 LossD_Fake: 0.6760 LossD_Real: 0.6934  LossG_Adv: 0.7107 LossG_L1: 1.9639 LossG_Style 1.7709 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_53_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[53](7/7): Loss_D: 0.6849 Loss_G: 4.8609 LossD_Fake: 0.6781 LossD_Real: 0.6916  LossG_Adv: 0.7085 LossG_L1: 1.8150 LossG_Style 2.3373 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[54](1/7): Loss_D: 0.6836 Loss_G: 4.7170 LossD_Fake: 0.6767 LossD_Real: 0.6906  LossG_Adv: 0.7137 LossG_L1: 2.0333 LossG_Style 1.9700 LossG_Content 0.0000\n",
            "===> Epoch[54](2/7): Loss_D: 0.6852 Loss_G: 4.5528 LossD_Fake: 0.6715 LossD_Real: 0.6989  LossG_Adv: 0.7155 LossG_L1: 1.8988 LossG_Style 1.9385 LossG_Content 0.0000\n",
            "===> Epoch[54](3/7): Loss_D: 0.6839 Loss_G: 4.7146 LossD_Fake: 0.6746 LossD_Real: 0.6932  LossG_Adv: 0.7122 LossG_L1: 1.9855 LossG_Style 2.0170 LossG_Content 0.0000\n",
            "===> Epoch[54](4/7): Loss_D: 0.6837 Loss_G: 4.5911 LossD_Fake: 0.6750 LossD_Real: 0.6924  LossG_Adv: 0.7117 LossG_L1: 1.8621 LossG_Style 2.0173 LossG_Content 0.0000\n",
            "===> Epoch[54](5/7): Loss_D: 0.6852 Loss_G: 4.7813 LossD_Fake: 0.6761 LossD_Real: 0.6943  LossG_Adv: 0.7107 LossG_L1: 1.9696 LossG_Style 2.1010 LossG_Content 0.0000\n",
            "===> Epoch[54](6/7): Loss_D: 0.6849 Loss_G: 4.7007 LossD_Fake: 0.6771 LossD_Real: 0.6928  LossG_Adv: 0.7097 LossG_L1: 1.9368 LossG_Style 2.0542 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_54_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[54](7/7): Loss_D: 0.6856 Loss_G: 4.9081 LossD_Fake: 0.6764 LossD_Real: 0.6948  LossG_Adv: 0.7105 LossG_L1: 1.8143 LossG_Style 2.3833 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[55](1/7): Loss_D: 0.6873 Loss_G: 4.9028 LossD_Fake: 0.6777 LossD_Real: 0.6969  LossG_Adv: 0.7076 LossG_L1: 1.9140 LossG_Style 2.2812 LossG_Content 0.0000\n",
            "===> Epoch[55](2/7): Loss_D: 0.6850 Loss_G: 4.5305 LossD_Fake: 0.6792 LossD_Real: 0.6908  LossG_Adv: 0.7075 LossG_L1: 1.9512 LossG_Style 1.8718 LossG_Content 0.0000\n",
            "===> Epoch[55](3/7): Loss_D: 0.6829 Loss_G: 4.5956 LossD_Fake: 0.6756 LossD_Real: 0.6903  LossG_Adv: 0.7112 LossG_L1: 1.8902 LossG_Style 1.9941 LossG_Content 0.0000\n",
            "===> Epoch[55](4/7): Loss_D: 0.6851 Loss_G: 4.7438 LossD_Fake: 0.6783 LossD_Real: 0.6919  LossG_Adv: 0.7085 LossG_L1: 1.9127 LossG_Style 2.1227 LossG_Content 0.0000\n",
            "===> Epoch[55](5/7): Loss_D: 0.6820 Loss_G: 4.7793 LossD_Fake: 0.6783 LossD_Real: 0.6858  LossG_Adv: 0.7085 LossG_L1: 1.8980 LossG_Style 2.1729 LossG_Content 0.0000\n",
            "===> Epoch[55](6/7): Loss_D: 0.6848 Loss_G: 4.7617 LossD_Fake: 0.6771 LossD_Real: 0.6925  LossG_Adv: 0.7096 LossG_L1: 2.0881 LossG_Style 1.9640 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_55_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[55](7/7): Loss_D: 0.6847 Loss_G: 4.4693 LossD_Fake: 0.6758 LossD_Real: 0.6936  LossG_Adv: 0.7110 LossG_L1: 1.8575 LossG_Style 1.9008 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[56](1/7): Loss_D: 0.6850 Loss_G: 4.6963 LossD_Fake: 0.6763 LossD_Real: 0.6936  LossG_Adv: 0.7142 LossG_L1: 2.0642 LossG_Style 1.9179 LossG_Content 0.0000\n",
            "===> Epoch[56](2/7): Loss_D: 0.6827 Loss_G: 4.9818 LossD_Fake: 0.6750 LossD_Real: 0.6905  LossG_Adv: 0.7118 LossG_L1: 1.9886 LossG_Style 2.2813 LossG_Content 0.0000\n",
            "===> Epoch[56](3/7): Loss_D: 0.6828 Loss_G: 4.5910 LossD_Fake: 0.6741 LossD_Real: 0.6914  LossG_Adv: 0.7128 LossG_L1: 1.9529 LossG_Style 1.9254 LossG_Content 0.0000\n",
            "===> Epoch[56](4/7): Loss_D: 0.6839 Loss_G: 4.4535 LossD_Fake: 0.6741 LossD_Real: 0.6937  LossG_Adv: 0.7127 LossG_L1: 1.8699 LossG_Style 1.8709 LossG_Content 0.0000\n",
            "===> Epoch[56](5/7): Loss_D: 0.6868 Loss_G: 4.5577 LossD_Fake: 0.6768 LossD_Real: 0.6969  LossG_Adv: 0.7100 LossG_L1: 1.8066 LossG_Style 2.0411 LossG_Content 0.0000\n",
            "===> Epoch[56](6/7): Loss_D: 0.6844 Loss_G: 4.7602 LossD_Fake: 0.6758 LossD_Real: 0.6930  LossG_Adv: 0.7111 LossG_L1: 1.9488 LossG_Style 2.1003 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_56_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[56](7/7): Loss_D: 0.6828 Loss_G: 4.3467 LossD_Fake: 0.6748 LossD_Real: 0.6907  LossG_Adv: 0.7120 LossG_L1: 1.8568 LossG_Style 1.7780 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[57](1/7): Loss_D: 0.6822 Loss_G: 4.4582 LossD_Fake: 0.6738 LossD_Real: 0.6906  LossG_Adv: 0.7093 LossG_L1: 1.8177 LossG_Style 1.9313 LossG_Content 0.0000\n",
            "===> Epoch[57](2/7): Loss_D: 0.6838 Loss_G: 4.7353 LossD_Fake: 0.6788 LossD_Real: 0.6889  LossG_Adv: 0.7079 LossG_L1: 1.9886 LossG_Style 2.0388 LossG_Content 0.0000\n",
            "===> Epoch[57](3/7): Loss_D: 0.6836 Loss_G: 4.6851 LossD_Fake: 0.6793 LossD_Real: 0.6880  LossG_Adv: 0.7075 LossG_L1: 1.9437 LossG_Style 2.0339 LossG_Content 0.0000\n",
            "===> Epoch[57](4/7): Loss_D: 0.6810 Loss_G: 4.7428 LossD_Fake: 0.6803 LossD_Real: 0.6818  LossG_Adv: 0.7064 LossG_L1: 1.9784 LossG_Style 2.0581 LossG_Content 0.0000\n",
            "===> Epoch[57](5/7): Loss_D: 0.6855 Loss_G: 4.4465 LossD_Fake: 0.6801 LossD_Real: 0.6910  LossG_Adv: 0.7066 LossG_L1: 1.9698 LossG_Style 1.7700 LossG_Content 0.0000\n",
            "===> Epoch[57](6/7): Loss_D: 0.6875 Loss_G: 4.6235 LossD_Fake: 0.6805 LossD_Real: 0.6945  LossG_Adv: 0.7062 LossG_L1: 1.8748 LossG_Style 2.0425 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_57_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[57](7/7): Loss_D: 0.6824 Loss_G: 4.1972 LossD_Fake: 0.6768 LossD_Real: 0.6879  LossG_Adv: 0.7099 LossG_L1: 1.7500 LossG_Style 1.7373 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[58](1/7): Loss_D: 0.6826 Loss_G: 4.9006 LossD_Fake: 0.6797 LossD_Real: 0.6855  LossG_Adv: 0.7031 LossG_L1: 1.9874 LossG_Style 2.2101 LossG_Content 0.0000\n",
            "===> Epoch[58](2/7): Loss_D: 0.6834 Loss_G: 4.5767 LossD_Fake: 0.6823 LossD_Real: 0.6845  LossG_Adv: 0.7044 LossG_L1: 1.9626 LossG_Style 1.9098 LossG_Content 0.0000\n",
            "===> Epoch[58](3/7): Loss_D: 0.6855 Loss_G: 4.4156 LossD_Fake: 0.6828 LossD_Real: 0.6882  LossG_Adv: 0.7038 LossG_L1: 1.7717 LossG_Style 1.9400 LossG_Content 0.0000\n",
            "===> Epoch[58](4/7): Loss_D: 0.6821 Loss_G: 4.5423 LossD_Fake: 0.6832 LossD_Real: 0.6810  LossG_Adv: 0.7035 LossG_L1: 1.8790 LossG_Style 1.9598 LossG_Content 0.0000\n",
            "===> Epoch[58](5/7): Loss_D: 0.6864 Loss_G: 4.2505 LossD_Fake: 0.6839 LossD_Real: 0.6889  LossG_Adv: 0.7027 LossG_L1: 1.7341 LossG_Style 1.8137 LossG_Content 0.0000\n",
            "===> Epoch[58](6/7): Loss_D: 0.6807 Loss_G: 4.4413 LossD_Fake: 0.6798 LossD_Real: 0.6816  LossG_Adv: 0.7069 LossG_L1: 1.8412 LossG_Style 1.8931 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_58_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[58](7/7): Loss_D: 0.6702 Loss_G: 4.8464 LossD_Fake: 0.6805 LossD_Real: 0.6600  LossG_Adv: 0.7062 LossG_L1: 2.1473 LossG_Style 1.9929 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[59](1/7): Loss_D: 0.6887 Loss_G: 5.2526 LossD_Fake: 0.6895 LossD_Real: 0.6880  LossG_Adv: 0.6892 LossG_L1: 2.1796 LossG_Style 2.3839 LossG_Content 0.0000\n",
            "===> Epoch[59](2/7): Loss_D: 0.6824 Loss_G: 4.8324 LossD_Fake: 0.6947 LossD_Real: 0.6701  LossG_Adv: 0.6918 LossG_L1: 2.0826 LossG_Style 2.0580 LossG_Content 0.0000\n",
            "===> Epoch[59](3/7): Loss_D: 0.6814 Loss_G: 4.3919 LossD_Fake: 0.6916 LossD_Real: 0.6713  LossG_Adv: 0.6949 LossG_L1: 1.8176 LossG_Style 1.8794 LossG_Content 0.0000\n",
            "===> Epoch[59](4/7): Loss_D: 0.6808 Loss_G: 4.6412 LossD_Fake: 0.6918 LossD_Real: 0.6697  LossG_Adv: 0.6947 LossG_L1: 2.0227 LossG_Style 1.9238 LossG_Content 0.0000\n",
            "===> Epoch[59](5/7): Loss_D: 0.6843 Loss_G: 4.3076 LossD_Fake: 0.6929 LossD_Real: 0.6758  LossG_Adv: 0.6936 LossG_L1: 1.8258 LossG_Style 1.7882 LossG_Content 0.0000\n",
            "===> Epoch[59](6/7): Loss_D: 0.6828 Loss_G: 4.5015 LossD_Fake: 0.6935 LossD_Real: 0.6722  LossG_Adv: 0.6930 LossG_L1: 1.8712 LossG_Style 1.9373 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_59_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[59](7/7): Loss_D: 0.6886 Loss_G: 4.1538 LossD_Fake: 0.6953 LossD_Real: 0.6819  LossG_Adv: 0.6912 LossG_L1: 1.7034 LossG_Style 1.7592 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[60](1/7): Loss_D: 0.6835 Loss_G: 4.7528 LossD_Fake: 0.6922 LossD_Real: 0.6748  LossG_Adv: 0.6886 LossG_L1: 2.0063 LossG_Style 2.0579 LossG_Content 0.0000\n",
            "===> Epoch[60](2/7): Loss_D: 0.6839 Loss_G: 4.4604 LossD_Fake: 0.7058 LossD_Real: 0.6619  LossG_Adv: 0.6809 LossG_L1: 1.9270 LossG_Style 1.8525 LossG_Content 0.0000\n",
            "===> Epoch[60](3/7): Loss_D: 0.6822 Loss_G: 4.6238 LossD_Fake: 0.7007 LossD_Real: 0.6637  LossG_Adv: 0.6860 LossG_L1: 1.8670 LossG_Style 2.0708 LossG_Content 0.0000\n",
            "===> Epoch[60](4/7): Loss_D: 0.6823 Loss_G: 4.5299 LossD_Fake: 0.7017 LossD_Real: 0.6630  LossG_Adv: 0.6849 LossG_L1: 1.8545 LossG_Style 1.9905 LossG_Content 0.0000\n",
            "===> Epoch[60](5/7): Loss_D: 0.6858 Loss_G: 4.7791 LossD_Fake: 0.7002 LossD_Real: 0.6713  LossG_Adv: 0.6864 LossG_L1: 2.0042 LossG_Style 2.0885 LossG_Content 0.0000\n",
            "===> Epoch[60](6/7): Loss_D: 0.6794 Loss_G: 4.4250 LossD_Fake: 0.6973 LossD_Real: 0.6615  LossG_Adv: 0.6892 LossG_L1: 1.8417 LossG_Style 1.8941 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_60_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[60](7/7): Loss_D: 0.6822 Loss_G: 4.2834 LossD_Fake: 0.7040 LossD_Real: 0.6605  LossG_Adv: 0.6828 LossG_L1: 1.8393 LossG_Style 1.7614 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[61](1/7): Loss_D: 0.6816 Loss_G: 4.4493 LossD_Fake: 0.6959 LossD_Real: 0.6673  LossG_Adv: 0.7007 LossG_L1: 1.9147 LossG_Style 1.8339 LossG_Content 0.0000\n",
            "===> Epoch[61](2/7): Loss_D: 0.6796 Loss_G: 4.4916 LossD_Fake: 0.6881 LossD_Real: 0.6712  LossG_Adv: 0.6985 LossG_L1: 1.9114 LossG_Style 1.8817 LossG_Content 0.0000\n",
            "===> Epoch[61](3/7): Loss_D: 0.6837 Loss_G: 4.3670 LossD_Fake: 0.6941 LossD_Real: 0.6733  LossG_Adv: 0.6925 LossG_L1: 1.7580 LossG_Style 1.9165 LossG_Content 0.0000\n",
            "===> Epoch[61](4/7): Loss_D: 0.6849 Loss_G: 4.2605 LossD_Fake: 0.6959 LossD_Real: 0.6739  LossG_Adv: 0.6907 LossG_L1: 1.7543 LossG_Style 1.8155 LossG_Content 0.0000\n",
            "===> Epoch[61](5/7): Loss_D: 0.6822 Loss_G: 4.6502 LossD_Fake: 0.6938 LossD_Real: 0.6705  LossG_Adv: 0.6927 LossG_L1: 1.9034 LossG_Style 2.0541 LossG_Content 0.0000\n",
            "===> Epoch[61](6/7): Loss_D: 0.6839 Loss_G: 4.8818 LossD_Fake: 0.6928 LossD_Real: 0.6750  LossG_Adv: 0.6937 LossG_L1: 2.1398 LossG_Style 2.0483 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_61_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[61](7/7): Loss_D: 0.6824 Loss_G: 4.3473 LossD_Fake: 0.6924 LossD_Real: 0.6723  LossG_Adv: 0.6940 LossG_L1: 1.6675 LossG_Style 1.9858 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[62](1/7): Loss_D: 0.6862 Loss_G: 4.4397 LossD_Fake: 0.6933 LossD_Real: 0.6791  LossG_Adv: 0.7027 LossG_L1: 1.9136 LossG_Style 1.8235 LossG_Content 0.0000\n",
            "===> Epoch[62](2/7): Loss_D: 0.6795 Loss_G: 4.7944 LossD_Fake: 0.6844 LossD_Real: 0.6746  LossG_Adv: 0.7023 LossG_L1: 1.8935 LossG_Style 2.1987 LossG_Content 0.0000\n",
            "===> Epoch[62](3/7): Loss_D: 0.6831 Loss_G: 4.3315 LossD_Fake: 0.6836 LossD_Real: 0.6826  LossG_Adv: 0.7029 LossG_L1: 1.8229 LossG_Style 1.8057 LossG_Content 0.0000\n",
            "===> Epoch[62](4/7): Loss_D: 0.6785 Loss_G: 4.6682 LossD_Fake: 0.6828 LossD_Real: 0.6742  LossG_Adv: 0.7038 LossG_L1: 1.8617 LossG_Style 2.1026 LossG_Content 0.0000\n",
            "===> Epoch[62](5/7): Loss_D: 0.6844 Loss_G: 4.3622 LossD_Fake: 0.6881 LossD_Real: 0.6808  LossG_Adv: 0.6986 LossG_L1: 1.6546 LossG_Style 2.0090 LossG_Content 0.0000\n",
            "===> Epoch[62](6/7): Loss_D: 0.6820 Loss_G: 4.2426 LossD_Fake: 0.6828 LossD_Real: 0.6811  LossG_Adv: 0.7038 LossG_L1: 1.7115 LossG_Style 1.8274 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_62_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[62](7/7): Loss_D: 0.6849 Loss_G: 4.0226 LossD_Fake: 0.6843 LossD_Real: 0.6854  LossG_Adv: 0.7023 LossG_L1: 1.6208 LossG_Style 1.6995 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[63](1/7): Loss_D: 0.6848 Loss_G: 4.8474 LossD_Fake: 0.6900 LossD_Real: 0.6797  LossG_Adv: 0.7043 LossG_L1: 1.8913 LossG_Style 2.2518 LossG_Content 0.0000\n",
            "===> Epoch[63](2/7): Loss_D: 0.6791 Loss_G: 4.5683 LossD_Fake: 0.6748 LossD_Real: 0.6833  LossG_Adv: 0.7120 LossG_L1: 1.9618 LossG_Style 1.8945 LossG_Content 0.0000\n",
            "===> Epoch[63](3/7): Loss_D: 0.6843 Loss_G: 4.4036 LossD_Fake: 0.6762 LossD_Real: 0.6924  LossG_Adv: 0.7106 LossG_L1: 1.7438 LossG_Style 1.9491 LossG_Content 0.0000\n",
            "===> Epoch[63](4/7): Loss_D: 0.6790 Loss_G: 4.6678 LossD_Fake: 0.6769 LossD_Real: 0.6812  LossG_Adv: 0.7101 LossG_L1: 1.8720 LossG_Style 2.0857 LossG_Content 0.0000\n",
            "===> Epoch[63](5/7): Loss_D: 0.6847 Loss_G: 4.3571 LossD_Fake: 0.6778 LossD_Real: 0.6916  LossG_Adv: 0.7089 LossG_L1: 1.8175 LossG_Style 1.8307 LossG_Content 0.0000\n",
            "===> Epoch[63](6/7): Loss_D: 0.6805 Loss_G: 4.2538 LossD_Fake: 0.6759 LossD_Real: 0.6852  LossG_Adv: 0.7109 LossG_L1: 1.7863 LossG_Style 1.7566 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_63_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[63](7/7): Loss_D: 0.6820 Loss_G: 4.0655 LossD_Fake: 0.6774 LossD_Real: 0.6865  LossG_Adv: 0.7093 LossG_L1: 1.5689 LossG_Style 1.7873 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[64](1/7): Loss_D: 0.6814 Loss_G: 4.2655 LossD_Fake: 0.6773 LossD_Real: 0.6855  LossG_Adv: 0.7033 LossG_L1: 1.7215 LossG_Style 1.8408 LossG_Content 0.0000\n",
            "===> Epoch[64](2/7): Loss_D: 0.6832 Loss_G: 4.3635 LossD_Fake: 0.6866 LossD_Real: 0.6797  LossG_Adv: 0.7000 LossG_L1: 1.6960 LossG_Style 1.9675 LossG_Content 0.0000\n",
            "===> Epoch[64](3/7): Loss_D: 0.6804 Loss_G: 4.2651 LossD_Fake: 0.6819 LossD_Real: 0.6789  LossG_Adv: 0.7047 LossG_L1: 1.7474 LossG_Style 1.8130 LossG_Content 0.0000\n",
            "===> Epoch[64](4/7): Loss_D: 0.6833 Loss_G: 4.4348 LossD_Fake: 0.6884 LossD_Real: 0.6783  LossG_Adv: 0.6983 LossG_L1: 1.6337 LossG_Style 2.1028 LossG_Content 0.0000\n",
            "===> Epoch[64](5/7): Loss_D: 0.6838 Loss_G: 4.6337 LossD_Fake: 0.6881 LossD_Real: 0.6796  LossG_Adv: 0.6988 LossG_L1: 1.9443 LossG_Style 1.9906 LossG_Content 0.0000\n",
            "===> Epoch[64](6/7): Loss_D: 0.6795 Loss_G: 4.3626 LossD_Fake: 0.6777 LossD_Real: 0.6814  LossG_Adv: 0.7090 LossG_L1: 1.7962 LossG_Style 1.8573 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_64_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[64](7/7): Loss_D: 0.6788 Loss_G: 4.5647 LossD_Fake: 0.6837 LossD_Real: 0.6739  LossG_Adv: 0.7028 LossG_L1: 1.9191 LossG_Style 1.9427 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[65](1/7): Loss_D: 0.6817 Loss_G: 4.2416 LossD_Fake: 0.6851 LossD_Real: 0.6784  LossG_Adv: 0.7030 LossG_L1: 1.6897 LossG_Style 1.8488 LossG_Content 0.0000\n",
            "===> Epoch[65](2/7): Loss_D: 0.6818 Loss_G: 4.2861 LossD_Fake: 0.6858 LossD_Real: 0.6778  LossG_Adv: 0.7012 LossG_L1: 1.8476 LossG_Style 1.7373 LossG_Content 0.0000\n",
            "===> Epoch[65](3/7): Loss_D: 0.6835 Loss_G: 4.4783 LossD_Fake: 0.6822 LossD_Real: 0.6849  LossG_Adv: 0.7046 LossG_L1: 1.7691 LossG_Style 2.0046 LossG_Content 0.0000\n",
            "===> Epoch[65](4/7): Loss_D: 0.6838 Loss_G: 4.1827 LossD_Fake: 0.6834 LossD_Real: 0.6841  LossG_Adv: 0.7032 LossG_L1: 1.6820 LossG_Style 1.7976 LossG_Content 0.0000\n",
            "===> Epoch[65](5/7): Loss_D: 0.6821 Loss_G: 4.3998 LossD_Fake: 0.6858 LossD_Real: 0.6784  LossG_Adv: 0.7009 LossG_L1: 1.6573 LossG_Style 2.0417 LossG_Content 0.0000\n",
            "===> Epoch[65](6/7): Loss_D: 0.6768 Loss_G: 4.5230 LossD_Fake: 0.6848 LossD_Real: 0.6687  LossG_Adv: 0.7019 LossG_L1: 1.8642 LossG_Style 1.9569 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_65_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[65](7/7): Loss_D: 0.6837 Loss_G: 4.0692 LossD_Fake: 0.6811 LossD_Real: 0.6862  LossG_Adv: 0.7056 LossG_L1: 1.7806 LossG_Style 1.5831 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[66](1/7): Loss_D: 0.6746 Loss_G: 4.5695 LossD_Fake: 0.6802 LossD_Real: 0.6691  LossG_Adv: 0.7002 LossG_L1: 1.8584 LossG_Style 2.0109 LossG_Content 0.0000\n",
            "===> Epoch[66](2/7): Loss_D: 0.6836 Loss_G: 4.1567 LossD_Fake: 0.6926 LossD_Real: 0.6747  LossG_Adv: 0.6941 LossG_L1: 1.7304 LossG_Style 1.7321 LossG_Content 0.0000\n",
            "===> Epoch[66](3/7): Loss_D: 0.6782 Loss_G: 4.8197 LossD_Fake: 0.6900 LossD_Real: 0.6664  LossG_Adv: 0.6967 LossG_L1: 2.0689 LossG_Style 2.0541 LossG_Content 0.0000\n",
            "===> Epoch[66](4/7): Loss_D: 0.6791 Loss_G: 4.2543 LossD_Fake: 0.6960 LossD_Real: 0.6622  LossG_Adv: 0.6909 LossG_L1: 1.8190 LossG_Style 1.7444 LossG_Content 0.0000\n",
            "===> Epoch[66](5/7): Loss_D: 0.6881 Loss_G: 4.1947 LossD_Fake: 0.6938 LossD_Real: 0.6825  LossG_Adv: 0.6931 LossG_L1: 1.6797 LossG_Style 1.8218 LossG_Content 0.0000\n",
            "===> Epoch[66](6/7): Loss_D: 0.6801 Loss_G: 4.6183 LossD_Fake: 0.6905 LossD_Real: 0.6697  LossG_Adv: 0.6964 LossG_L1: 1.8154 LossG_Style 2.1066 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_66_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[66](7/7): Loss_D: 0.6824 Loss_G: 4.0040 LossD_Fake: 0.6915 LossD_Real: 0.6732  LossG_Adv: 0.6952 LossG_L1: 1.8433 LossG_Style 1.4655 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[67](1/7): Loss_D: 0.6780 Loss_G: 4.3746 LossD_Fake: 0.6918 LossD_Real: 0.6642  LossG_Adv: 0.7052 LossG_L1: 1.8429 LossG_Style 1.8265 LossG_Content 0.0000\n",
            "===> Epoch[67](2/7): Loss_D: 0.6875 Loss_G: 4.2218 LossD_Fake: 0.6865 LossD_Real: 0.6884  LossG_Adv: 0.7005 LossG_L1: 1.7013 LossG_Style 1.8201 LossG_Content 0.0000\n",
            "===> Epoch[67](3/7): Loss_D: 0.6772 Loss_G: 4.2580 LossD_Fake: 0.6794 LossD_Real: 0.6751  LossG_Adv: 0.7077 LossG_L1: 1.7557 LossG_Style 1.7946 LossG_Content 0.0000\n",
            "===> Epoch[67](4/7): Loss_D: 0.6837 Loss_G: 4.5012 LossD_Fake: 0.6905 LossD_Real: 0.6769  LossG_Adv: 0.6964 LossG_L1: 1.7724 LossG_Style 2.0324 LossG_Content 0.0000\n",
            "===> Epoch[67](5/7): Loss_D: 0.6800 Loss_G: 4.3955 LossD_Fake: 0.6790 LossD_Real: 0.6809  LossG_Adv: 0.7079 LossG_L1: 1.8115 LossG_Style 1.8761 LossG_Content 0.0000\n",
            "===> Epoch[67](6/7): Loss_D: 0.6782 Loss_G: 4.5431 LossD_Fake: 0.6821 LossD_Real: 0.6743  LossG_Adv: 0.7049 LossG_L1: 1.9532 LossG_Style 1.8851 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_67_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[67](7/7): Loss_D: 0.6748 Loss_G: 4.5079 LossD_Fake: 0.6851 LossD_Real: 0.6644  LossG_Adv: 0.7016 LossG_L1: 1.8909 LossG_Style 1.9153 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[68](1/7): Loss_D: 0.6821 Loss_G: 4.5553 LossD_Fake: 0.6829 LossD_Real: 0.6813  LossG_Adv: 0.7098 LossG_L1: 1.8942 LossG_Style 1.9513 LossG_Content 0.0000\n",
            "===> Epoch[68](2/7): Loss_D: 0.6770 Loss_G: 4.3829 LossD_Fake: 0.6785 LossD_Real: 0.6755  LossG_Adv: 0.7084 LossG_L1: 1.8793 LossG_Style 1.7952 LossG_Content 0.0000\n",
            "===> Epoch[68](3/7): Loss_D: 0.6801 Loss_G: 4.5753 LossD_Fake: 0.6806 LossD_Real: 0.6797  LossG_Adv: 0.7065 LossG_L1: 1.7693 LossG_Style 2.0995 LossG_Content 0.0000\n",
            "===> Epoch[68](4/7): Loss_D: 0.6826 Loss_G: 4.1194 LossD_Fake: 0.6805 LossD_Real: 0.6848  LossG_Adv: 0.7064 LossG_L1: 1.5992 LossG_Style 1.8138 LossG_Content 0.0000\n",
            "===> Epoch[68](5/7): Loss_D: 0.6802 Loss_G: 4.3089 LossD_Fake: 0.6790 LossD_Real: 0.6814  LossG_Adv: 0.7080 LossG_L1: 1.7006 LossG_Style 1.9003 LossG_Content 0.0000\n",
            "===> Epoch[68](6/7): Loss_D: 0.6799 Loss_G: 4.1608 LossD_Fake: 0.6767 LossD_Real: 0.6831  LossG_Adv: 0.7103 LossG_L1: 1.6791 LossG_Style 1.7714 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_68_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[68](7/7): Loss_D: 0.6702 Loss_G: 4.1101 LossD_Fake: 0.6773 LossD_Real: 0.6632  LossG_Adv: 0.7095 LossG_L1: 1.7842 LossG_Style 1.6164 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[69](1/7): Loss_D: 0.6863 Loss_G: 4.2453 LossD_Fake: 0.6812 LossD_Real: 0.6914  LossG_Adv: 0.6894 LossG_L1: 1.7857 LossG_Style 1.7702 LossG_Content 0.0000\n",
            "===> Epoch[69](2/7): Loss_D: 0.6816 Loss_G: 4.3452 LossD_Fake: 0.7032 LossD_Real: 0.6601  LossG_Adv: 0.6837 LossG_L1: 1.7447 LossG_Style 1.9168 LossG_Content 0.0000\n",
            "===> Epoch[69](3/7): Loss_D: 0.6832 Loss_G: 3.9959 LossD_Fake: 0.6953 LossD_Real: 0.6711  LossG_Adv: 0.6915 LossG_L1: 1.6053 LossG_Style 1.6991 LossG_Content 0.0000\n",
            "===> Epoch[69](4/7): Loss_D: 0.6738 Loss_G: 4.5109 LossD_Fake: 0.6967 LossD_Real: 0.6509  LossG_Adv: 0.6901 LossG_L1: 1.8846 LossG_Style 1.9362 LossG_Content 0.0000\n",
            "===> Epoch[69](5/7): Loss_D: 0.6827 Loss_G: 4.3459 LossD_Fake: 0.7034 LossD_Real: 0.6620  LossG_Adv: 0.6837 LossG_L1: 1.7873 LossG_Style 1.8749 LossG_Content 0.0000\n",
            "===> Epoch[69](6/7): Loss_D: 0.6775 Loss_G: 4.1627 LossD_Fake: 0.6990 LossD_Real: 0.6559  LossG_Adv: 0.6879 LossG_L1: 1.7376 LossG_Style 1.7372 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_69_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[69](7/7): Loss_D: 0.6766 Loss_G: 4.6611 LossD_Fake: 0.7023 LossD_Real: 0.6509  LossG_Adv: 0.6849 LossG_L1: 1.7343 LossG_Style 2.2420 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[70](1/7): Loss_D: 0.6871 Loss_G: 3.8884 LossD_Fake: 0.6987 LossD_Real: 0.6755  LossG_Adv: 0.6944 LossG_L1: 1.5974 LossG_Style 1.5966 LossG_Content 0.0000\n",
            "===> Epoch[70](2/7): Loss_D: 0.6779 Loss_G: 4.0273 LossD_Fake: 0.6864 LossD_Real: 0.6693  LossG_Adv: 0.7003 LossG_L1: 1.6748 LossG_Style 1.6521 LossG_Content 0.0000\n",
            "===> Epoch[70](3/7): Loss_D: 0.6780 Loss_G: 4.2817 LossD_Fake: 0.6940 LossD_Real: 0.6620  LossG_Adv: 0.6928 LossG_L1: 1.7525 LossG_Style 1.8364 LossG_Content 0.0000\n",
            "===> Epoch[70](4/7): Loss_D: 0.6802 Loss_G: 4.0243 LossD_Fake: 0.6926 LossD_Real: 0.6678  LossG_Adv: 0.6943 LossG_L1: 1.5555 LossG_Style 1.7745 LossG_Content 0.0000\n",
            "===> Epoch[70](5/7): Loss_D: 0.6805 Loss_G: 4.3337 LossD_Fake: 0.6983 LossD_Real: 0.6626  LossG_Adv: 0.6886 LossG_L1: 1.7286 LossG_Style 1.9165 LossG_Content 0.0000\n",
            "===> Epoch[70](6/7): Loss_D: 0.6768 Loss_G: 4.3504 LossD_Fake: 0.6923 LossD_Real: 0.6613  LossG_Adv: 0.6946 LossG_L1: 1.7881 LossG_Style 1.8677 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_70_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[70](7/7): Loss_D: 0.6791 Loss_G: 4.9188 LossD_Fake: 0.6983 LossD_Real: 0.6599  LossG_Adv: 0.6885 LossG_L1: 2.0039 LossG_Style 2.2264 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[71](1/7): Loss_D: 0.6815 Loss_G: 4.6855 LossD_Fake: 0.6997 LossD_Real: 0.6634  LossG_Adv: 0.7074 LossG_L1: 2.0081 LossG_Style 1.9700 LossG_Content 0.0000\n",
            "===> Epoch[71](2/7): Loss_D: 0.6765 Loss_G: 4.3395 LossD_Fake: 0.6734 LossD_Real: 0.6796  LossG_Adv: 0.7139 LossG_L1: 1.7751 LossG_Style 1.8505 LossG_Content 0.0000\n",
            "===> Epoch[71](3/7): Loss_D: 0.6808 Loss_G: 3.8745 LossD_Fake: 0.6703 LossD_Real: 0.6913  LossG_Adv: 0.7170 LossG_L1: 1.4855 LossG_Style 1.6720 LossG_Content 0.0000\n",
            "===> Epoch[71](4/7): Loss_D: 0.6811 Loss_G: 4.1014 LossD_Fake: 0.6832 LossD_Real: 0.6789  LossG_Adv: 0.7040 LossG_L1: 1.6172 LossG_Style 1.7802 LossG_Content 0.0000\n",
            "===> Epoch[71](5/7): Loss_D: 0.6781 Loss_G: 4.2836 LossD_Fake: 0.6795 LossD_Real: 0.6768  LossG_Adv: 0.7078 LossG_L1: 1.7512 LossG_Style 1.8246 LossG_Content 0.0000\n",
            "===> Epoch[71](6/7): Loss_D: 0.6838 Loss_G: 4.2527 LossD_Fake: 0.6767 LossD_Real: 0.6908  LossG_Adv: 0.7104 LossG_L1: 1.7942 LossG_Style 1.7482 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_71_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[71](7/7): Loss_D: 0.6786 Loss_G: 4.2142 LossD_Fake: 0.6748 LossD_Real: 0.6824  LossG_Adv: 0.7129 LossG_L1: 1.6283 LossG_Style 1.8729 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[72](1/7): Loss_D: 0.6862 Loss_G: 4.5428 LossD_Fake: 0.6812 LossD_Real: 0.6912  LossG_Adv: 0.7048 LossG_L1: 1.8395 LossG_Style 1.9985 LossG_Content 0.0000\n",
            "===> Epoch[72](2/7): Loss_D: 0.6807 Loss_G: 4.3420 LossD_Fake: 0.6779 LossD_Real: 0.6835  LossG_Adv: 0.7091 LossG_L1: 1.7931 LossG_Style 1.8398 LossG_Content 0.0000\n",
            "===> Epoch[72](3/7): Loss_D: 0.6788 Loss_G: 4.0324 LossD_Fake: 0.6745 LossD_Real: 0.6830  LossG_Adv: 0.7125 LossG_L1: 1.6455 LossG_Style 1.6744 LossG_Content 0.0000\n",
            "===> Epoch[72](4/7): Loss_D: 0.6763 Loss_G: 4.5133 LossD_Fake: 0.6818 LossD_Real: 0.6707  LossG_Adv: 0.7056 LossG_L1: 1.8204 LossG_Style 1.9874 LossG_Content 0.0000\n",
            "===> Epoch[72](5/7): Loss_D: 0.6794 Loss_G: 4.2744 LossD_Fake: 0.6807 LossD_Real: 0.6780  LossG_Adv: 0.7062 LossG_L1: 1.6884 LossG_Style 1.8798 LossG_Content 0.0000\n",
            "===> Epoch[72](6/7): Loss_D: 0.6768 Loss_G: 3.9840 LossD_Fake: 0.6747 LossD_Real: 0.6789  LossG_Adv: 0.7123 LossG_L1: 1.6643 LossG_Style 1.6074 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_72_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[72](7/7): Loss_D: 0.6815 Loss_G: 3.8660 LossD_Fake: 0.6756 LossD_Real: 0.6873  LossG_Adv: 0.7114 LossG_L1: 1.6366 LossG_Style 1.5180 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[73](1/7): Loss_D: 0.6883 Loss_G: 4.3789 LossD_Fake: 0.6838 LossD_Real: 0.6928  LossG_Adv: 0.6919 LossG_L1: 1.7612 LossG_Style 1.9257 LossG_Content 0.0000\n",
            "===> Epoch[73](2/7): Loss_D: 0.6770 Loss_G: 4.4109 LossD_Fake: 0.6925 LossD_Real: 0.6615  LossG_Adv: 0.6942 LossG_L1: 1.8051 LossG_Style 1.9116 LossG_Content 0.0000\n",
            "===> Epoch[73](3/7): Loss_D: 0.6771 Loss_G: 4.2813 LossD_Fake: 0.6898 LossD_Real: 0.6644  LossG_Adv: 0.6969 LossG_L1: 1.7624 LossG_Style 1.8220 LossG_Content 0.0000\n",
            "===> Epoch[73](4/7): Loss_D: 0.6810 Loss_G: 4.0393 LossD_Fake: 0.6920 LossD_Real: 0.6701  LossG_Adv: 0.6948 LossG_L1: 1.6611 LossG_Style 1.6835 LossG_Content 0.0000\n",
            "===> Epoch[73](5/7): Loss_D: 0.6780 Loss_G: 3.9999 LossD_Fake: 0.6845 LossD_Real: 0.6714  LossG_Adv: 0.7022 LossG_L1: 1.7103 LossG_Style 1.5874 LossG_Content 0.0000\n",
            "===> Epoch[73](6/7): Loss_D: 0.6798 Loss_G: 4.0567 LossD_Fake: 0.6919 LossD_Real: 0.6677  LossG_Adv: 0.6949 LossG_L1: 1.5138 LossG_Style 1.8480 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_73_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[73](7/7): Loss_D: 0.6816 Loss_G: 4.2907 LossD_Fake: 0.7018 LossD_Real: 0.6615  LossG_Adv: 0.6856 LossG_L1: 1.7758 LossG_Style 1.8293 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[74](1/7): Loss_D: 0.6817 Loss_G: 4.2582 LossD_Fake: 0.6901 LossD_Real: 0.6734  LossG_Adv: 0.7042 LossG_L1: 1.6805 LossG_Style 1.8735 LossG_Content 0.0000\n",
            "===> Epoch[74](2/7): Loss_D: 0.6794 Loss_G: 4.2964 LossD_Fake: 0.6841 LossD_Real: 0.6747  LossG_Adv: 0.7025 LossG_L1: 1.7405 LossG_Style 1.8534 LossG_Content 0.0000\n",
            "===> Epoch[74](3/7): Loss_D: 0.6765 Loss_G: 4.5681 LossD_Fake: 0.6861 LossD_Real: 0.6668  LossG_Adv: 0.7009 LossG_L1: 1.8213 LossG_Style 2.0458 LossG_Content 0.0000\n",
            "===> Epoch[74](4/7): Loss_D: 0.6761 Loss_G: 4.7354 LossD_Fake: 0.6845 LossD_Real: 0.6677  LossG_Adv: 0.7022 LossG_L1: 1.9819 LossG_Style 2.0513 LossG_Content 0.0000\n",
            "===> Epoch[74](5/7): Loss_D: 0.6838 Loss_G: 4.0188 LossD_Fake: 0.6857 LossD_Real: 0.6818  LossG_Adv: 0.7010 LossG_L1: 1.6350 LossG_Style 1.6828 LossG_Content 0.0000\n",
            "===> Epoch[74](6/7): Loss_D: 0.6798 Loss_G: 4.1069 LossD_Fake: 0.6823 LossD_Real: 0.6773  LossG_Adv: 0.7046 LossG_L1: 1.7473 LossG_Style 1.6550 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_74_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[74](7/7): Loss_D: 0.6766 Loss_G: 4.0043 LossD_Fake: 0.6796 LossD_Real: 0.6736  LossG_Adv: 0.7071 LossG_L1: 1.6236 LossG_Style 1.6737 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[75](1/7): Loss_D: 0.6805 Loss_G: 4.2677 LossD_Fake: 0.6884 LossD_Real: 0.6726  LossG_Adv: 0.7161 LossG_L1: 1.7326 LossG_Style 1.8190 LossG_Content 0.0000\n",
            "===> Epoch[75](2/7): Loss_D: 0.6792 Loss_G: 4.0113 LossD_Fake: 0.6647 LossD_Real: 0.6938  LossG_Adv: 0.7229 LossG_L1: 1.6005 LossG_Style 1.6879 LossG_Content 0.0000\n",
            "===> Epoch[75](3/7): Loss_D: 0.6763 Loss_G: 4.2902 LossD_Fake: 0.6709 LossD_Real: 0.6818  LossG_Adv: 0.7164 LossG_L1: 1.7812 LossG_Style 1.7926 LossG_Content 0.0000\n",
            "===> Epoch[75](4/7): Loss_D: 0.6843 Loss_G: 4.2211 LossD_Fake: 0.6759 LossD_Real: 0.6926  LossG_Adv: 0.7116 LossG_L1: 1.6006 LossG_Style 1.9088 LossG_Content 0.0000\n",
            "===> Epoch[75](5/7): Loss_D: 0.6788 Loss_G: 4.0776 LossD_Fake: 0.6700 LossD_Real: 0.6875  LossG_Adv: 0.7171 LossG_L1: 1.6105 LossG_Style 1.7499 LossG_Content 0.0000\n",
            "===> Epoch[75](6/7): Loss_D: 0.6766 Loss_G: 4.2970 LossD_Fake: 0.6658 LossD_Real: 0.6873  LossG_Adv: 0.7217 LossG_L1: 1.6155 LossG_Style 1.9597 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_75_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[75](7/7): Loss_D: 0.6794 Loss_G: 4.1387 LossD_Fake: 0.6746 LossD_Real: 0.6843  LossG_Adv: 0.7134 LossG_L1: 1.5772 LossG_Style 1.8481 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[76](1/7): Loss_D: 0.6795 Loss_G: 4.1291 LossD_Fake: 0.6692 LossD_Real: 0.6898  LossG_Adv: 0.7155 LossG_L1: 1.6498 LossG_Style 1.7639 LossG_Content 0.0000\n",
            "===> Epoch[76](2/7): Loss_D: 0.6774 Loss_G: 4.3786 LossD_Fake: 0.6789 LossD_Real: 0.6759  LossG_Adv: 0.7086 LossG_L1: 1.7409 LossG_Style 1.9291 LossG_Content 0.0000\n",
            "===> Epoch[76](3/7): Loss_D: 0.6791 Loss_G: 3.8058 LossD_Fake: 0.6694 LossD_Real: 0.6887  LossG_Adv: 0.7179 LossG_L1: 1.5807 LossG_Style 1.5072 LossG_Content 0.0000\n",
            "===> Epoch[76](4/7): Loss_D: 0.6861 Loss_G: 4.0975 LossD_Fake: 0.6782 LossD_Real: 0.6939  LossG_Adv: 0.7097 LossG_L1: 1.6380 LossG_Style 1.7499 LossG_Content 0.0000\n",
            "===> Epoch[76](5/7): Loss_D: 0.6772 Loss_G: 3.8700 LossD_Fake: 0.6727 LossD_Real: 0.6818  LossG_Adv: 0.7145 LossG_L1: 1.5622 LossG_Style 1.5934 LossG_Content 0.0000\n",
            "===> Epoch[76](6/7): Loss_D: 0.6701 Loss_G: 4.2772 LossD_Fake: 0.6725 LossD_Real: 0.6676  LossG_Adv: 0.7147 LossG_L1: 1.7521 LossG_Style 1.8104 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_76_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[76](7/7): Loss_D: 0.6879 Loss_G: 3.7211 LossD_Fake: 0.6747 LossD_Real: 0.7010  LossG_Adv: 0.7122 LossG_L1: 1.5582 LossG_Style 1.4507 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[77](1/7): Loss_D: 0.6760 Loss_G: 4.1841 LossD_Fake: 0.6649 LossD_Real: 0.6871  LossG_Adv: 0.7044 LossG_L1: 1.5880 LossG_Style 1.8917 LossG_Content 0.0000\n",
            "===> Epoch[77](2/7): Loss_D: 0.6738 Loss_G: 3.8311 LossD_Fake: 0.6911 LossD_Real: 0.6566  LossG_Adv: 0.6957 LossG_L1: 1.5915 LossG_Style 1.5440 LossG_Content 0.0000\n",
            "===> Epoch[77](3/7): Loss_D: 0.6804 Loss_G: 4.1642 LossD_Fake: 0.6983 LossD_Real: 0.6625  LossG_Adv: 0.6891 LossG_L1: 1.5288 LossG_Style 1.9464 LossG_Content 0.0000\n",
            "===> Epoch[77](4/7): Loss_D: 0.6841 Loss_G: 4.1611 LossD_Fake: 0.7059 LossD_Real: 0.6624  LossG_Adv: 0.6817 LossG_L1: 1.6257 LossG_Style 1.8536 LossG_Content 0.0000\n",
            "===> Epoch[77](5/7): Loss_D: 0.6725 Loss_G: 4.2075 LossD_Fake: 0.6905 LossD_Real: 0.6545  LossG_Adv: 0.6963 LossG_L1: 1.7186 LossG_Style 1.7926 LossG_Content 0.0000\n",
            "===> Epoch[77](6/7): Loss_D: 0.6728 Loss_G: 4.1085 LossD_Fake: 0.6920 LossD_Real: 0.6537  LossG_Adv: 0.6949 LossG_L1: 1.6937 LossG_Style 1.7199 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_77_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[77](7/7): Loss_D: 0.6822 Loss_G: 3.7984 LossD_Fake: 0.6988 LossD_Real: 0.6656  LossG_Adv: 0.6880 LossG_L1: 1.3572 LossG_Style 1.7532 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[78](1/7): Loss_D: 0.6771 Loss_G: 4.2480 LossD_Fake: 0.7002 LossD_Real: 0.6540  LossG_Adv: 0.7109 LossG_L1: 1.8189 LossG_Style 1.7181 LossG_Content 0.0000\n",
            "===> Epoch[78](2/7): Loss_D: 0.6740 Loss_G: 4.2993 LossD_Fake: 0.6740 LossD_Real: 0.6739  LossG_Adv: 0.7132 LossG_L1: 1.8005 LossG_Style 1.7856 LossG_Content 0.0000\n",
            "===> Epoch[78](3/7): Loss_D: 0.6774 Loss_G: 4.1161 LossD_Fake: 0.6692 LossD_Real: 0.6856  LossG_Adv: 0.7181 LossG_L1: 1.5970 LossG_Style 1.8011 LossG_Content 0.0000\n",
            "===> Epoch[78](4/7): Loss_D: 0.6790 Loss_G: 4.2876 LossD_Fake: 0.6679 LossD_Real: 0.6900  LossG_Adv: 0.7195 LossG_L1: 1.8992 LossG_Style 1.6688 LossG_Content 0.0000\n",
            "===> Epoch[78](5/7): Loss_D: 0.6813 Loss_G: 4.0379 LossD_Fake: 0.6771 LossD_Real: 0.6855  LossG_Adv: 0.7108 LossG_L1: 1.5572 LossG_Style 1.7699 LossG_Content 0.0000\n",
            "===> Epoch[78](6/7): Loss_D: 0.6745 Loss_G: 4.5255 LossD_Fake: 0.6723 LossD_Real: 0.6767  LossG_Adv: 0.7153 LossG_L1: 1.9298 LossG_Style 1.8804 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_78_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[78](7/7): Loss_D: 0.6700 Loss_G: 4.1930 LossD_Fake: 0.6733 LossD_Real: 0.6667  LossG_Adv: 0.7139 LossG_L1: 1.7270 LossG_Style 1.7520 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[79](1/7): Loss_D: 0.6782 Loss_G: 4.0658 LossD_Fake: 0.6753 LossD_Real: 0.6810  LossG_Adv: 0.7148 LossG_L1: 1.7508 LossG_Style 1.6001 LossG_Content 0.0000\n",
            "===> Epoch[79](2/7): Loss_D: 0.6687 Loss_G: 4.1069 LossD_Fake: 0.6772 LossD_Real: 0.6602  LossG_Adv: 0.7108 LossG_L1: 1.6942 LossG_Style 1.7018 LossG_Content 0.0000\n",
            "===> Epoch[79](3/7): Loss_D: 0.6773 Loss_G: 4.1086 LossD_Fake: 0.6751 LossD_Real: 0.6796  LossG_Adv: 0.7125 LossG_L1: 1.7031 LossG_Style 1.6930 LossG_Content 0.0000\n",
            "===> Epoch[79](4/7): Loss_D: 0.6771 Loss_G: 4.0780 LossD_Fake: 0.6751 LossD_Real: 0.6790  LossG_Adv: 0.7125 LossG_L1: 1.6597 LossG_Style 1.7059 LossG_Content 0.0000\n",
            "===> Epoch[79](5/7): Loss_D: 0.6855 Loss_G: 4.1417 LossD_Fake: 0.6765 LossD_Real: 0.6945  LossG_Adv: 0.7115 LossG_L1: 1.5548 LossG_Style 1.8754 LossG_Content 0.0000\n",
            "===> Epoch[79](6/7): Loss_D: 0.6813 Loss_G: 3.9211 LossD_Fake: 0.6724 LossD_Real: 0.6902  LossG_Adv: 0.7150 LossG_L1: 1.5518 LossG_Style 1.6543 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_79_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[79](7/7): Loss_D: 0.6818 Loss_G: 3.8575 LossD_Fake: 0.6671 LossD_Real: 0.6966  LossG_Adv: 0.7204 LossG_L1: 1.4568 LossG_Style 1.6803 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[80](1/7): Loss_D: 0.6750 Loss_G: 4.0853 LossD_Fake: 0.6774 LossD_Real: 0.6725  LossG_Adv: 0.7104 LossG_L1: 1.6790 LossG_Style 1.6958 LossG_Content 0.0000\n",
            "===> Epoch[80](2/7): Loss_D: 0.6804 Loss_G: 4.0995 LossD_Fake: 0.6745 LossD_Real: 0.6863  LossG_Adv: 0.7128 LossG_L1: 1.6255 LossG_Style 1.7612 LossG_Content 0.0000\n",
            "===> Epoch[80](3/7): Loss_D: 0.6805 Loss_G: 4.3402 LossD_Fake: 0.6779 LossD_Real: 0.6832  LossG_Adv: 0.7101 LossG_L1: 1.7405 LossG_Style 1.8896 LossG_Content 0.0000\n",
            "===> Epoch[80](4/7): Loss_D: 0.6829 Loss_G: 3.9114 LossD_Fake: 0.6713 LossD_Real: 0.6946  LossG_Adv: 0.7165 LossG_L1: 1.4877 LossG_Style 1.7072 LossG_Content 0.0000\n",
            "===> Epoch[80](5/7): Loss_D: 0.6678 Loss_G: 4.2569 LossD_Fake: 0.6701 LossD_Real: 0.6655  LossG_Adv: 0.7173 LossG_L1: 1.8386 LossG_Style 1.7010 LossG_Content 0.0000\n",
            "===> Epoch[80](6/7): Loss_D: 0.6842 Loss_G: 4.1211 LossD_Fake: 0.6740 LossD_Real: 0.6945  LossG_Adv: 0.7142 LossG_L1: 1.5113 LossG_Style 1.8956 LossG_Content 0.0000\n",
            "\n",
            "saving sample dataset_80_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[80](7/7): Loss_D: 0.6545 Loss_G: 3.7557 LossD_Fake: 0.6671 LossD_Real: 0.6418  LossG_Adv: 0.7207 LossG_L1: 1.6727 LossG_Style 1.3623 LossG_Content 0.0000\n",
            "Checkpoint saved to checkpointdataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Zj66z8QbE8"
      },
      "source": [
        "def run():\r\n",
        "    torch.multiprocessing.freeze_support()\r\n",
        "    print('loop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsvBwy22Qc_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7873ed-e498-4713-9815-731339aa7de6"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}