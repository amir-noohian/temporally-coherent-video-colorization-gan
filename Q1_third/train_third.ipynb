{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_third.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYNlIRTPzNbI"
      },
      "source": [
        "## In this code, we consider GAN loss, L1 loss, Style loss, and content loss. In addition, we just use the current lineart frame to input the generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hif97tj5cj9o",
        "outputId": "1b20b1d8-d780-42a7-be29-a579c1c920d0"
      },
      "source": [
        "!pip uninstall scipy\r\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling scipy-1.1.0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy-1.1.0.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/scipy/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled scipy-1.1.0\n",
            "Collecting scipy==1.1.0\n",
            "  Using cached https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQTf3rjcOnz"
      },
      "source": [
        "import sys\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "from math import log10\r\n",
        "from os.path import join\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.backends.cudnn as cudnn\r\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB_WEhnDvOjF"
      },
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgM5pqPIU9d9",
        "outputId": "dc8a63d6-3a6d-4201-86d0-50090d50e0f8"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3EZsqYjVQoS"
      },
      "source": [
        "sys.path.append('/content/gdrive/MyDrive/src_third')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxJDA28aUJe9"
      },
      "source": [
        "from models import define_G, define_D, print_network\r\n",
        "from data import get_training_set, get_test_set, create_iterator\r\n",
        "from dataset import DatasetFromFolder\r\n",
        "from loss import AdversarialLoss, StyleLoss, PerceptualLoss\r\n",
        "from util import Progbar, stitch_images, postprocess, load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T5HnCEwsgXS"
      },
      "source": [
        "root = '/content/gdrive/MyDrive'\r\n",
        "dataset = 'dataset'\r\n",
        "logfile = 'trainlogs.dat'\r\n",
        "checkpoint_path_G = False\r\n",
        "checkpoint_path_D = False\r\n",
        "batchSize = 16\r\n",
        "testBatchSize = 1\r\n",
        "nEpochs = 100\r\n",
        "input_nc = 1\r\n",
        "output_nc = 3\r\n",
        "lr = 0.0001\r\n",
        "beta1 = 0\r\n",
        "cuda = True\r\n",
        "threads = 0\r\n",
        "seed = 123\r\n",
        "L1lamb = 10\r\n",
        "Stylelamb = 1000\r\n",
        "Contentlamb = 1\r\n",
        "Adversariallamb = 0.1\r\n",
        "ngf = 2\r\n",
        "ndf = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af92GbOgPG2j"
      },
      "source": [
        "if cuda and not torch.cuda.is_available():\r\n",
        "    raise Exception(\"No GPU found, please run without --cuda\")\r\n",
        "\r\n",
        "cudnn.benchmark = True\r\n",
        "\r\n",
        "torch.manual_seed(seed)\r\n",
        "if cuda:\r\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGXUruQOvpvV",
        "outputId": "8eaeeea3-9675-4785-f9de-264aac50508d"
      },
      "source": [
        "print('===> Loading datasets')\r\n",
        "root_path = root\r\n",
        "train_set = get_training_set(join(root_path , dataset))\r\n",
        "test_set = get_test_set(join(root_path , dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Loading datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUec3y0aPRZE"
      },
      "source": [
        "training_data_loader = DataLoader(dataset=train_set, num_workers=threads, batch_size=batchSize, shuffle=True)\r\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=threads, batch_size=testBatchSize, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv2Sg-JBPVPd"
      },
      "source": [
        "sample_iterator = create_iterator(4, test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9O_Y9qkPY9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93a3708b-67e5-4441-acc8-ce23b8dd41f4"
      },
      "source": [
        "print('===> Building model')\r\n",
        "netG = define_G(input_nc, output_nc, ngf, False, [0])\r\n",
        "netD = define_D(input_nc + output_nc, ndf, False, [0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Building model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xi4LWxEPbul"
      },
      "source": [
        "if checkpoint_path_G and checkpoint_path_D:\r\n",
        "    load(checkpoint_path_G, checkpoint_path_D, netG, netD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T5sTtucPfBj"
      },
      "source": [
        "criterionGAN = AdversarialLoss()\r\n",
        "criterionSTYLE = StyleLoss()\r\n",
        "criterionCONTENT = PerceptualLoss()\r\n",
        "criterionL1 = nn.L1Loss()\r\n",
        "criterionMSE = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP6Lr9sTPhSL"
      },
      "source": [
        "# setup optimizer\r\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\r\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr * 0.1, betas=(beta1, 0.999))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TzXshGnPj19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57516097-a954-4e1d-fef0-e8a0a362dbcb"
      },
      "source": [
        "print('---------- Networks initialized -------------')\r\n",
        "print_network(netG)\r\n",
        "print_network(netD)\r\n",
        "print('-----------------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------- Networks initialized -------------\n",
            "InpaintGenerator(\n",
            "  (encoder): Sequential(\n",
            "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (9): ReLU(inplace=True)\n",
            "  )\n",
            "  (middle): Sequential(\n",
            "    (0): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (2): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (3): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (4): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (5): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (6): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (7): ResnetBlock(\n",
            "      (conv_block): Sequential(\n",
            "        (0): ReflectionPad2d((2, 2, 2, 2))\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
            "        (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
            "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ReflectionPad2d((3, 3, 3, 3))\n",
            "    (7): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 10765187\n",
            "Discriminator(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(4, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 2764800\n",
            "-----------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHE6eEPIPmhx"
      },
      "source": [
        "real_a = torch.FloatTensor(batchSize, input_nc, 256, 256)\r\n",
        "real_b = torch.FloatTensor(batchSize, output_nc, 256, 256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cp-1DnRPrcM"
      },
      "source": [
        "if cuda:\r\n",
        "    netD = netD.cuda()\r\n",
        "    netG = netG.cuda()\r\n",
        "    criterionGAN = criterionGAN.cuda()\r\n",
        "    criterionL1 = criterionL1.cuda()\r\n",
        "    critertionSTYLE = criterionSTYLE.cuda()\r\n",
        "    criterionCONTENT = criterionCONTENT.cuda()\r\n",
        "    criterionMSE = criterionMSE.cuda()\r\n",
        "    real_a = real_a.cuda()\r\n",
        "    real_b = real_b.cuda()\r\n",
        "\r\n",
        "real_a = Variable(real_a)\r\n",
        "real_b = Variable(real_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jZpTDafPzv9"
      },
      "source": [
        "def train(epoch):\r\n",
        "\r\n",
        "    for iteration, batch in enumerate(training_data_loader, 1):\r\n",
        "        # forward\r\n",
        "        real_a_cpu, real_b_cpu = batch[0], batch[1]\r\n",
        "        with torch.no_grad():\r\n",
        "          real_a.resize_(real_a_cpu.size()).copy_(real_a_cpu)\r\n",
        "          real_b.resize_(real_b_cpu.size()).copy_(real_b_cpu)\r\n",
        "        \r\n",
        "        input_joined = real_a\r\n",
        "\r\n",
        "        fake_b = netG(input_joined)\r\n",
        "\r\n",
        "        ############################\r\n",
        "        # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))\r\n",
        "        ###########################\r\n",
        "\r\n",
        "        optimizerD.zero_grad()\r\n",
        "\r\n",
        "        # train with fake\r\n",
        "        fake_ab = torch.cat((real_a, fake_b), 1)\r\n",
        "        pred_fake = netD.forward(fake_ab.detach())\r\n",
        "        loss_d_fake = criterionGAN(pred_fake,False,True)\r\n",
        "\r\n",
        "        # train with real\r\n",
        "        real_ab = torch.cat((real_a, real_b), 1)\r\n",
        "        pred_real = netD.forward(real_ab)\r\n",
        "        loss_d_real = criterionGAN(pred_real, True, True) \r\n",
        "\r\n",
        "\r\n",
        "        # Combined loss\r\n",
        "        loss_d = (loss_d_fake + loss_d_real) * 0.5\r\n",
        "\r\n",
        "        loss_d.backward()\r\n",
        "\r\n",
        "        #Discriminator parameters update every 12 iterations \r\n",
        "        if (iteration == 1 or iteration % 12 == 0):\r\n",
        "            optimizerD.step()\r\n",
        "\r\n",
        "        ############################\r\n",
        "        # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))\r\n",
        "        ##########################\r\n",
        "        optimizerG.zero_grad()\r\n",
        "\r\n",
        "        # First, G(A) should fake the discriminator\r\n",
        "        fake_ab = torch.cat((real_a, fake_b), 1)\r\n",
        "        pred_fake = netD.forward(fake_ab)\r\n",
        "        loss_g_gan = criterionGAN(pred_fake, True, False)\r\n",
        "\r\n",
        "        # Second, G(A) = B\r\n",
        "        loss_g_l1 = criterionL1(fake_b, real_b) * L1lamb\r\n",
        "        loss_g = loss_g_gan + loss_g_l1\r\n",
        "\r\n",
        "        loss_g_style = criterionSTYLE(fake_b,real_b) * Stylelamb\r\n",
        "        loss_g = loss_g + loss_g_style\r\n",
        "\r\n",
        "        loss_g_content = criterionCONTENT(fake_b,real_b) * Contentlamb\r\n",
        "        loss_g = loss_g + loss_g_content\r\n",
        "\r\n",
        "        loss_g.backward()\r\n",
        "\r\n",
        "        optimizerG.step()\r\n",
        "\r\n",
        "        if (iteration % 7 == 0):\r\n",
        "            logs = [(\"epoc\", epoch),(\"iter\", iteration),(\"Loss_G\", loss_g.item()),(\"Loss_D\", loss_d.item()), (\"Loss_G_adv\",loss_g_gan.item()),(\"Loss_G_L1\",loss_g_l1.item()),(\"Loss_G_style\",loss_g_style.item()),(\"Loss_G_content\",loss_g_content.item()),(\"Loss_D_Real\",loss_d_real.item()),(\"Loss_D_Fake\",loss_d_fake.item())]\r\n",
        "            log_train_data(logs)\r\n",
        "\r\n",
        "        if (iteration % 7 == 0):\r\n",
        "            sample(iteration)\r\n",
        "\r\n",
        "\r\n",
        "        print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f} LossD_Fake: {:.4f} LossD_Real: {:.4f}  LossG_Adv: {:.4f} LossG_L1: {:.4f} LossG_Style {:.4f} LossG_Content {:.4f}\".format(\r\n",
        "           epoch, iteration, len(training_data_loader), loss_d, loss_g, loss_d_fake, loss_d_real, loss_g_gan, loss_g_l1, loss_g_style, loss_g_content))\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grV9tKdNQDer"
      },
      "source": [
        "def sample(iteration):\r\n",
        "    with torch.no_grad():\r\n",
        "\r\n",
        "        input,target,prev_frame = next(sample_iterator)\r\n",
        "        \r\n",
        "        if cuda:\r\n",
        "            input = input.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "\r\n",
        "        pred_input = input\r\n",
        "        prediction = netG(pred_input)\r\n",
        "        prediction = postprocess(prediction)\r\n",
        "        input = postprocess(input)\r\n",
        "        target = postprocess(target)\r\n",
        "\r\n",
        "    img = stitch_images(input, target, prediction)\r\n",
        "    samples_dir = root_path + \"/samples_third\"\r\n",
        "\r\n",
        "    if not os.path.exists(samples_dir):\r\n",
        "        os.makedirs(samples_dir)\r\n",
        "\r\n",
        "    sample = dataset + \"_\" + str(epoch) + \"_\" + str(iteration).zfill(2) + \".jpg\"\r\n",
        "    print('\\nsaving sample ' + sample + ' - learning rate: ' + str(lr))\r\n",
        "    img.save(os.path.join(samples_dir, sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc16nvL7QMGV"
      },
      "source": [
        "def log_train_data(loginfo):\r\n",
        "    log_dir = root_path + \"/logs_third\"\r\n",
        "    if not os.path.exists(log_dir):\r\n",
        "        os.makedirs(log_dir)\r\n",
        "    log_file = log_dir + \"/\" + logfile\r\n",
        "    with open(log_file, 'a') as f:\r\n",
        "        f.write('%s\\n' % ' '.join([str(item[1]) for item in loginfo]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y65ILFkOsSNF"
      },
      "source": [
        "def checkpoint(epoch):\r\n",
        "    checkpoint_dir = root_path + '/checkpoint_third'\r\n",
        "    if not os.path.exists(checkpoint_dir):\r\n",
        "        os.makedirs(checkpoint_dir)\r\n",
        "\r\n",
        "    net_g_model_out_path = checkpoint_dir + \"/netG_weights_epoch_{}.pth\".format(epoch)\r\n",
        "    net_d_model_out_path = checkpoint_dir + \"/netD_weights_epoch_{}.pth\".format(epoch)\r\n",
        "\r\n",
        "    torch.save({'generator': netG.state_dict()}, net_g_model_out_path)\r\n",
        "    torch.save({'discriminator': netD.state_dict()}, net_d_model_out_path)\r\n",
        "    \r\n",
        "    print(\"Checkpoint saved to {}\".format(\"checkpoint\" + dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLUULk4yQYsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d5ed77-0b87-4cfa-9f57-2e4a3ff90947"
      },
      "source": [
        "for epoch in range(1, nEpochs + 1):\r\n",
        "    train(epoch)\r\n",
        "    checkpoint(epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===> Epoch[1](1/7): Loss_D: 0.6832 Loss_G: 14.0837 LossD_Fake: 0.6447 LossD_Real: 0.7217  LossG_Adv: 0.7350 LossG_L1: 3.6607 LossG_Style 5.6899 LossG_Content 3.9980\n",
            "===> Epoch[1](2/7): Loss_D: 0.6891 Loss_G: 13.1459 LossD_Fake: 0.6582 LossD_Real: 0.7200  LossG_Adv: 0.7254 LossG_L1: 3.6023 LossG_Style 4.9593 LossG_Content 3.8589\n",
            "===> Epoch[1](3/7): Loss_D: 0.6907 Loss_G: 14.3026 LossD_Fake: 0.6630 LossD_Real: 0.7183  LossG_Adv: 0.7229 LossG_L1: 3.6329 LossG_Style 5.6010 LossG_Content 4.3460\n",
            "===> Epoch[1](4/7): Loss_D: 0.6900 Loss_G: 13.5641 LossD_Fake: 0.6653 LossD_Real: 0.7146  LossG_Adv: 0.7212 LossG_L1: 3.7488 LossG_Style 5.0525 LossG_Content 4.0416\n",
            "===> Epoch[1](5/7): Loss_D: 0.6910 Loss_G: 13.3888 LossD_Fake: 0.6679 LossD_Real: 0.7142  LossG_Adv: 0.7187 LossG_L1: 3.5990 LossG_Style 5.0853 LossG_Content 3.9858\n",
            "===> Epoch[1](6/7): Loss_D: 0.6922 Loss_G: 13.8372 LossD_Fake: 0.6689 LossD_Real: 0.7154  LossG_Adv: 0.7178 LossG_L1: 3.6498 LossG_Style 5.2741 LossG_Content 4.1955\n",
            "\n",
            "saving sample dataset_1_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[1](7/7): Loss_D: 0.6921 Loss_G: 13.7082 LossD_Fake: 0.6715 LossD_Real: 0.7127  LossG_Adv: 0.7151 LossG_L1: 3.3715 LossG_Style 5.5166 LossG_Content 4.1050\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[2](1/7): Loss_D: 0.6935 Loss_G: 13.5694 LossD_Fake: 0.6721 LossD_Real: 0.7149  LossG_Adv: 0.7143 LossG_L1: 3.4719 LossG_Style 5.3780 LossG_Content 4.0053\n",
            "===> Epoch[2](2/7): Loss_D: 0.6923 Loss_G: 12.6059 LossD_Fake: 0.6738 LossD_Real: 0.7108  LossG_Adv: 0.7128 LossG_L1: 3.2419 LossG_Style 4.6940 LossG_Content 3.9571\n",
            "===> Epoch[2](3/7): Loss_D: 0.6924 Loss_G: 13.1603 LossD_Fake: 0.6747 LossD_Real: 0.7101  LossG_Adv: 0.7118 LossG_L1: 3.2079 LossG_Style 5.1523 LossG_Content 4.0883\n",
            "===> Epoch[2](4/7): Loss_D: 0.6930 Loss_G: 13.0791 LossD_Fake: 0.6761 LossD_Real: 0.7100  LossG_Adv: 0.7105 LossG_L1: 3.4614 LossG_Style 4.8929 LossG_Content 4.0144\n",
            "===> Epoch[2](5/7): Loss_D: 0.6939 Loss_G: 12.7024 LossD_Fake: 0.6764 LossD_Real: 0.7114  LossG_Adv: 0.7101 LossG_L1: 3.3427 LossG_Style 4.7662 LossG_Content 3.8834\n",
            "===> Epoch[2](6/7): Loss_D: 0.6935 Loss_G: 13.0205 LossD_Fake: 0.6765 LossD_Real: 0.7106  LossG_Adv: 0.7101 LossG_L1: 3.3464 LossG_Style 4.9662 LossG_Content 3.9978\n",
            "\n",
            "saving sample dataset_2_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[2](7/7): Loss_D: 0.6939 Loss_G: 12.6168 LossD_Fake: 0.6770 LossD_Real: 0.7107  LossG_Adv: 0.7096 LossG_L1: 3.5716 LossG_Style 4.6350 LossG_Content 3.7006\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[3](1/7): Loss_D: 0.6942 Loss_G: 12.8456 LossD_Fake: 0.6781 LossD_Real: 0.7104  LossG_Adv: 0.7080 LossG_L1: 3.2255 LossG_Style 5.0227 LossG_Content 3.8894\n",
            "===> Epoch[3](2/7): Loss_D: 0.6935 Loss_G: 11.6834 LossD_Fake: 0.6790 LossD_Real: 0.7081  LossG_Adv: 0.7075 LossG_L1: 3.2121 LossG_Style 4.1678 LossG_Content 3.5960\n",
            "===> Epoch[3](3/7): Loss_D: 0.6933 Loss_G: 12.4831 LossD_Fake: 0.6790 LossD_Real: 0.7076  LossG_Adv: 0.7075 LossG_L1: 3.0643 LossG_Style 4.9879 LossG_Content 3.7234\n",
            "===> Epoch[3](4/7): Loss_D: 0.6933 Loss_G: 11.8330 LossD_Fake: 0.6789 LossD_Real: 0.7077  LossG_Adv: 0.7076 LossG_L1: 3.2071 LossG_Style 4.3373 LossG_Content 3.5810\n",
            "===> Epoch[3](5/7): Loss_D: 0.6928 Loss_G: 11.3709 LossD_Fake: 0.6788 LossD_Real: 0.7069  LossG_Adv: 0.7077 LossG_L1: 2.9643 LossG_Style 4.3071 LossG_Content 3.3918\n",
            "===> Epoch[3](6/7): Loss_D: 0.6933 Loss_G: 11.9556 LossD_Fake: 0.6796 LossD_Real: 0.7070  LossG_Adv: 0.7069 LossG_L1: 2.9616 LossG_Style 4.6131 LossG_Content 3.6741\n",
            "\n",
            "saving sample dataset_3_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[3](7/7): Loss_D: 0.6942 Loss_G: 13.7034 LossD_Fake: 0.6794 LossD_Real: 0.7090  LossG_Adv: 0.7071 LossG_L1: 3.4585 LossG_Style 5.5857 LossG_Content 3.9521\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[4](1/7): Loss_D: 0.6930 Loss_G: 11.7860 LossD_Fake: 0.6783 LossD_Real: 0.7078  LossG_Adv: 0.7067 LossG_L1: 3.1546 LossG_Style 4.4997 LossG_Content 3.4249\n",
            "===> Epoch[4](2/7): Loss_D: 0.6922 Loss_G: 11.5994 LossD_Fake: 0.6805 LossD_Real: 0.7039  LossG_Adv: 0.7060 LossG_L1: 2.8607 LossG_Style 4.5499 LossG_Content 3.4828\n",
            "===> Epoch[4](3/7): Loss_D: 0.6929 Loss_G: 10.8459 LossD_Fake: 0.6813 LossD_Real: 0.7044  LossG_Adv: 0.7052 LossG_L1: 2.7047 LossG_Style 4.0360 LossG_Content 3.4000\n",
            "===> Epoch[4](4/7): Loss_D: 0.6931 Loss_G: 11.4962 LossD_Fake: 0.6811 LossD_Real: 0.7051  LossG_Adv: 0.7054 LossG_L1: 3.0572 LossG_Style 4.4184 LossG_Content 3.3152\n",
            "===> Epoch[4](5/7): Loss_D: 0.6924 Loss_G: 11.6830 LossD_Fake: 0.6807 LossD_Real: 0.7042  LossG_Adv: 0.7058 LossG_L1: 3.1779 LossG_Style 4.5003 LossG_Content 3.2990\n",
            "===> Epoch[4](6/7): Loss_D: 0.6926 Loss_G: 11.9642 LossD_Fake: 0.6807 LossD_Real: 0.7046  LossG_Adv: 0.7058 LossG_L1: 3.2120 LossG_Style 4.6156 LossG_Content 3.4308\n",
            "\n",
            "saving sample dataset_4_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[4](7/7): Loss_D: 0.6913 Loss_G: 10.2848 LossD_Fake: 0.6808 LossD_Real: 0.7017  LossG_Adv: 0.7057 LossG_L1: 2.8907 LossG_Style 3.6142 LossG_Content 3.0742\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[5](1/7): Loss_D: 0.6936 Loss_G: 11.4513 LossD_Fake: 0.6805 LossD_Real: 0.7067  LossG_Adv: 0.7060 LossG_L1: 3.1316 LossG_Style 4.3102 LossG_Content 3.3035\n",
            "===> Epoch[5](2/7): Loss_D: 0.6914 Loss_G: 10.8704 LossD_Fake: 0.6808 LossD_Real: 0.7020  LossG_Adv: 0.7057 LossG_L1: 3.0720 LossG_Style 3.9908 LossG_Content 3.1019\n",
            "===> Epoch[5](3/7): Loss_D: 0.6919 Loss_G: 11.4719 LossD_Fake: 0.6811 LossD_Real: 0.7026  LossG_Adv: 0.7054 LossG_L1: 3.0186 LossG_Style 4.4740 LossG_Content 3.2738\n",
            "===> Epoch[5](4/7): Loss_D: 0.6918 Loss_G: 11.0486 LossD_Fake: 0.6816 LossD_Real: 0.7021  LossG_Adv: 0.7049 LossG_L1: 2.6615 LossG_Style 4.4305 LossG_Content 3.2517\n",
            "===> Epoch[5](5/7): Loss_D: 0.6926 Loss_G: 10.0972 LossD_Fake: 0.6815 LossD_Real: 0.7038  LossG_Adv: 0.7050 LossG_L1: 2.8216 LossG_Style 3.6121 LossG_Content 2.9585\n",
            "===> Epoch[5](6/7): Loss_D: 0.6919 Loss_G: 11.3789 LossD_Fake: 0.6817 LossD_Real: 0.7022  LossG_Adv: 0.7048 LossG_L1: 2.9061 LossG_Style 4.5036 LossG_Content 3.2645\n",
            "\n",
            "saving sample dataset_5_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[5](7/7): Loss_D: 0.6926 Loss_G: 11.1295 LossD_Fake: 0.6809 LossD_Real: 0.7042  LossG_Adv: 0.7056 LossG_L1: 2.7611 LossG_Style 4.3736 LossG_Content 3.2892\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[6](1/7): Loss_D: 0.6922 Loss_G: 11.3649 LossD_Fake: 0.6814 LossD_Real: 0.7031  LossG_Adv: 0.7037 LossG_L1: 2.7499 LossG_Style 4.5697 LossG_Content 3.3415\n",
            "===> Epoch[6](2/7): Loss_D: 0.6914 Loss_G: 11.4609 LossD_Fake: 0.6827 LossD_Real: 0.7000  LossG_Adv: 0.7037 LossG_L1: 2.8706 LossG_Style 4.5630 LossG_Content 3.3235\n",
            "===> Epoch[6](3/7): Loss_D: 0.6919 Loss_G: 10.9047 LossD_Fake: 0.6827 LossD_Real: 0.7011  LossG_Adv: 0.7037 LossG_L1: 3.1924 LossG_Style 3.9538 LossG_Content 3.0548\n",
            "===> Epoch[6](4/7): Loss_D: 0.6913 Loss_G: 11.0483 LossD_Fake: 0.6829 LossD_Real: 0.6996  LossG_Adv: 0.7035 LossG_L1: 2.9752 LossG_Style 4.2228 LossG_Content 3.1468\n",
            "===> Epoch[6](5/7): Loss_D: 0.6919 Loss_G: 10.3351 LossD_Fake: 0.6836 LossD_Real: 0.7003  LossG_Adv: 0.7028 LossG_L1: 2.7032 LossG_Style 3.9326 LossG_Content 2.9966\n",
            "===> Epoch[6](6/7): Loss_D: 0.6926 Loss_G: 10.1736 LossD_Fake: 0.6837 LossD_Real: 0.7016  LossG_Adv: 0.7028 LossG_L1: 2.8511 LossG_Style 3.6491 LossG_Content 2.9706\n",
            "\n",
            "saving sample dataset_6_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[6](7/7): Loss_D: 0.6910 Loss_G: 11.2042 LossD_Fake: 0.6832 LossD_Real: 0.6988  LossG_Adv: 0.7032 LossG_L1: 3.3355 LossG_Style 4.0388 LossG_Content 3.1267\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[7](1/7): Loss_D: 0.6924 Loss_G: 10.4775 LossD_Fake: 0.6834 LossD_Real: 0.7015  LossG_Adv: 0.7017 LossG_L1: 2.9200 LossG_Style 3.8641 LossG_Content 2.9917\n",
            "===> Epoch[7](2/7): Loss_D: 0.6915 Loss_G: 9.6428 LossD_Fake: 0.6847 LossD_Real: 0.6982  LossG_Adv: 0.7017 LossG_L1: 2.5692 LossG_Style 3.5350 LossG_Content 2.8370\n",
            "===> Epoch[7](3/7): Loss_D: 0.6910 Loss_G: 10.1956 LossD_Fake: 0.6846 LossD_Real: 0.6973  LossG_Adv: 0.7018 LossG_L1: 3.0305 LossG_Style 3.5781 LossG_Content 2.8851\n",
            "===> Epoch[7](4/7): Loss_D: 0.6911 Loss_G: 10.7543 LossD_Fake: 0.6851 LossD_Real: 0.6970  LossG_Adv: 0.7013 LossG_L1: 2.6802 LossG_Style 4.2516 LossG_Content 3.1212\n",
            "===> Epoch[7](5/7): Loss_D: 0.6907 Loss_G: 11.3799 LossD_Fake: 0.6835 LossD_Real: 0.6978  LossG_Adv: 0.7029 LossG_L1: 2.8347 LossG_Style 4.4821 LossG_Content 3.3602\n",
            "===> Epoch[7](6/7): Loss_D: 0.6908 Loss_G: 11.7601 LossD_Fake: 0.6848 LossD_Real: 0.6967  LossG_Adv: 0.7016 LossG_L1: 3.0980 LossG_Style 4.6514 LossG_Content 3.3091\n",
            "\n",
            "saving sample dataset_7_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[7](7/7): Loss_D: 0.6919 Loss_G: 10.7922 LossD_Fake: 0.6846 LossD_Real: 0.6993  LossG_Adv: 0.7018 LossG_L1: 2.8030 LossG_Style 4.2220 LossG_Content 3.0654\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[8](1/7): Loss_D: 0.6911 Loss_G: 10.5050 LossD_Fake: 0.6841 LossD_Real: 0.6982  LossG_Adv: 0.7010 LossG_L1: 3.0286 LossG_Style 3.8155 LossG_Content 2.9599\n",
            "===> Epoch[8](2/7): Loss_D: 0.6905 Loss_G: 9.7808 LossD_Fake: 0.6858 LossD_Real: 0.6951  LossG_Adv: 0.7006 LossG_L1: 2.6267 LossG_Style 3.5126 LossG_Content 2.9410\n",
            "===> Epoch[8](3/7): Loss_D: 0.6904 Loss_G: 10.4224 LossD_Fake: 0.6863 LossD_Real: 0.6944  LossG_Adv: 0.7000 LossG_L1: 2.9337 LossG_Style 3.7764 LossG_Content 3.0123\n",
            "===> Epoch[8](4/7): Loss_D: 0.6909 Loss_G: 10.2919 LossD_Fake: 0.6865 LossD_Real: 0.6953  LossG_Adv: 0.6998 LossG_L1: 2.7745 LossG_Style 3.8364 LossG_Content 2.9812\n",
            "===> Epoch[8](5/7): Loss_D: 0.6910 Loss_G: 9.8397 LossD_Fake: 0.6858 LossD_Real: 0.6962  LossG_Adv: 0.7006 LossG_L1: 2.6955 LossG_Style 3.5575 LossG_Content 2.8861\n",
            "===> Epoch[8](6/7): Loss_D: 0.6902 Loss_G: 10.4372 LossD_Fake: 0.6865 LossD_Real: 0.6939  LossG_Adv: 0.6999 LossG_L1: 2.7917 LossG_Style 3.9532 LossG_Content 2.9924\n",
            "\n",
            "saving sample dataset_8_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[8](7/7): Loss_D: 0.6906 Loss_G: 9.7571 LossD_Fake: 0.6864 LossD_Real: 0.6947  LossG_Adv: 0.7000 LossG_L1: 2.8401 LossG_Style 3.2821 LossG_Content 2.9349\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[9](1/7): Loss_D: 0.6905 Loss_G: 10.0575 LossD_Fake: 0.6864 LossD_Real: 0.6945  LossG_Adv: 0.6987 LossG_L1: 2.7283 LossG_Style 3.6908 LossG_Content 2.9398\n",
            "===> Epoch[9](2/7): Loss_D: 0.6899 Loss_G: 9.8307 LossD_Fake: 0.6868 LossD_Real: 0.6930  LossG_Adv: 0.6996 LossG_L1: 2.8662 LossG_Style 3.4229 LossG_Content 2.8420\n",
            "===> Epoch[9](3/7): Loss_D: 0.6899 Loss_G: 10.6834 LossD_Fake: 0.6880 LossD_Real: 0.6919  LossG_Adv: 0.6984 LossG_L1: 2.8712 LossG_Style 4.0957 LossG_Content 3.0182\n",
            "===> Epoch[9](4/7): Loss_D: 0.6896 Loss_G: 9.9371 LossD_Fake: 0.6872 LossD_Real: 0.6919  LossG_Adv: 0.6991 LossG_L1: 2.8299 LossG_Style 3.5087 LossG_Content 2.8994\n",
            "===> Epoch[9](5/7): Loss_D: 0.6914 Loss_G: 8.8537 LossD_Fake: 0.6883 LossD_Real: 0.6945  LossG_Adv: 0.6981 LossG_L1: 2.5420 LossG_Style 3.0228 LossG_Content 2.5909\n",
            "===> Epoch[9](6/7): Loss_D: 0.6901 Loss_G: 10.2236 LossD_Fake: 0.6877 LossD_Real: 0.6926  LossG_Adv: 0.6987 LossG_L1: 2.8891 LossG_Style 3.7204 LossG_Content 2.9154\n",
            "\n",
            "saving sample dataset_9_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[9](7/7): Loss_D: 0.6907 Loss_G: 8.6229 LossD_Fake: 0.6863 LossD_Real: 0.6951  LossG_Adv: 0.7001 LossG_L1: 2.5049 LossG_Style 2.7835 LossG_Content 2.6345\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[10](1/7): Loss_D: 0.6911 Loss_G: 9.4886 LossD_Fake: 0.6880 LossD_Real: 0.6942  LossG_Adv: 0.6978 LossG_L1: 2.6267 LossG_Style 3.4046 LossG_Content 2.7595\n",
            "===> Epoch[10](2/7): Loss_D: 0.6894 Loss_G: 9.9246 LossD_Fake: 0.6877 LossD_Real: 0.6912  LossG_Adv: 0.6987 LossG_L1: 2.6569 LossG_Style 3.7067 LossG_Content 2.8623\n",
            "===> Epoch[10](3/7): Loss_D: 0.6898 Loss_G: 9.3034 LossD_Fake: 0.6874 LossD_Real: 0.6921  LossG_Adv: 0.6989 LossG_L1: 2.7234 LossG_Style 3.1716 LossG_Content 2.7094\n",
            "===> Epoch[10](4/7): Loss_D: 0.6898 Loss_G: 9.9076 LossD_Fake: 0.6876 LossD_Real: 0.6921  LossG_Adv: 0.6988 LossG_L1: 2.7805 LossG_Style 3.5549 LossG_Content 2.8734\n",
            "===> Epoch[10](5/7): Loss_D: 0.6898 Loss_G: 10.1541 LossD_Fake: 0.6886 LossD_Real: 0.6910  LossG_Adv: 0.6978 LossG_L1: 2.7747 LossG_Style 3.7026 LossG_Content 2.9789\n",
            "===> Epoch[10](6/7): Loss_D: 0.6895 Loss_G: 10.1389 LossD_Fake: 0.6889 LossD_Real: 0.6900  LossG_Adv: 0.6975 LossG_L1: 2.8953 LossG_Style 3.6186 LossG_Content 2.9275\n",
            "\n",
            "saving sample dataset_10_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[10](7/7): Loss_D: 0.6899 Loss_G: 9.2548 LossD_Fake: 0.6883 LossD_Real: 0.6915  LossG_Adv: 0.6981 LossG_L1: 2.6585 LossG_Style 3.1896 LossG_Content 2.7087\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[11](1/7): Loss_D: 0.6897 Loss_G: 9.9341 LossD_Fake: 0.6892 LossD_Real: 0.6902  LossG_Adv: 0.6955 LossG_L1: 2.8699 LossG_Style 3.5467 LossG_Content 2.8220\n",
            "===> Epoch[11](2/7): Loss_D: 0.6900 Loss_G: 9.5060 LossD_Fake: 0.6905 LossD_Real: 0.6895  LossG_Adv: 0.6958 LossG_L1: 2.5088 LossG_Style 3.4484 LossG_Content 2.8529\n",
            "===> Epoch[11](3/7): Loss_D: 0.6903 Loss_G: 9.4217 LossD_Fake: 0.6908 LossD_Real: 0.6898  LossG_Adv: 0.6956 LossG_L1: 2.5635 LossG_Style 3.4004 LossG_Content 2.7622\n",
            "===> Epoch[11](4/7): Loss_D: 0.6894 Loss_G: 9.3312 LossD_Fake: 0.6894 LossD_Real: 0.6893  LossG_Adv: 0.6970 LossG_L1: 2.8459 LossG_Style 3.0655 LossG_Content 2.7228\n",
            "===> Epoch[11](5/7): Loss_D: 0.6898 Loss_G: 9.3408 LossD_Fake: 0.6911 LossD_Real: 0.6886  LossG_Adv: 0.6953 LossG_L1: 2.7251 LossG_Style 3.1840 LossG_Content 2.7364\n",
            "===> Epoch[11](6/7): Loss_D: 0.6892 Loss_G: 9.2013 LossD_Fake: 0.6896 LossD_Real: 0.6888  LossG_Adv: 0.6967 LossG_L1: 2.8100 LossG_Style 3.0071 LossG_Content 2.6875\n",
            "\n",
            "saving sample dataset_11_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[11](7/7): Loss_D: 0.6907 Loss_G: 8.3686 LossD_Fake: 0.6914 LossD_Real: 0.6901  LossG_Adv: 0.6950 LossG_L1: 2.4086 LossG_Style 2.7050 LossG_Content 2.5601\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[12](1/7): Loss_D: 0.6907 Loss_G: 8.8658 LossD_Fake: 0.6896 LossD_Real: 0.6918  LossG_Adv: 0.6970 LossG_L1: 2.4766 LossG_Style 3.0326 LossG_Content 2.6596\n",
            "===> Epoch[12](2/7): Loss_D: 0.6890 Loss_G: 9.7893 LossD_Fake: 0.6903 LossD_Real: 0.6878  LossG_Adv: 0.6961 LossG_L1: 2.9012 LossG_Style 3.3897 LossG_Content 2.8023\n",
            "===> Epoch[12](3/7): Loss_D: 0.6895 Loss_G: 9.1096 LossD_Fake: 0.6891 LossD_Real: 0.6899  LossG_Adv: 0.6973 LossG_L1: 2.7474 LossG_Style 3.0066 LossG_Content 2.6583\n",
            "===> Epoch[12](4/7): Loss_D: 0.6888 Loss_G: 9.2606 LossD_Fake: 0.6895 LossD_Real: 0.6881  LossG_Adv: 0.6968 LossG_L1: 2.6101 LossG_Style 3.1855 LossG_Content 2.7681\n",
            "===> Epoch[12](5/7): Loss_D: 0.6884 Loss_G: 9.6822 LossD_Fake: 0.6900 LossD_Real: 0.6869  LossG_Adv: 0.6964 LossG_L1: 2.7512 LossG_Style 3.4391 LossG_Content 2.7955\n",
            "===> Epoch[12](6/7): Loss_D: 0.6889 Loss_G: 9.1455 LossD_Fake: 0.6906 LossD_Real: 0.6871  LossG_Adv: 0.6957 LossG_L1: 2.6297 LossG_Style 3.1120 LossG_Content 2.7081\n",
            "\n",
            "saving sample dataset_12_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[12](7/7): Loss_D: 0.6894 Loss_G: 8.4628 LossD_Fake: 0.6912 LossD_Real: 0.6876  LossG_Adv: 0.6951 LossG_L1: 2.7114 LossG_Style 2.4902 LossG_Content 2.5660\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[13](1/7): Loss_D: 0.6886 Loss_G: 9.5238 LossD_Fake: 0.6904 LossD_Real: 0.6867  LossG_Adv: 0.6939 LossG_L1: 2.7181 LossG_Style 3.2917 LossG_Content 2.8201\n",
            "===> Epoch[13](2/7): Loss_D: 0.6906 Loss_G: 8.9035 LossD_Fake: 0.6940 LossD_Real: 0.6872  LossG_Adv: 0.6924 LossG_L1: 2.6886 LossG_Style 2.8933 LossG_Content 2.6293\n",
            "===> Epoch[13](3/7): Loss_D: 0.6891 Loss_G: 9.2662 LossD_Fake: 0.6932 LossD_Real: 0.6850  LossG_Adv: 0.6932 LossG_L1: 2.6948 LossG_Style 3.1569 LossG_Content 2.7213\n",
            "===> Epoch[13](4/7): Loss_D: 0.6882 Loss_G: 9.1001 LossD_Fake: 0.6926 LossD_Real: 0.6838  LossG_Adv: 0.6938 LossG_L1: 2.7414 LossG_Style 2.9566 LossG_Content 2.7084\n",
            "===> Epoch[13](5/7): Loss_D: 0.6896 Loss_G: 9.1553 LossD_Fake: 0.6930 LossD_Real: 0.6862  LossG_Adv: 0.6934 LossG_L1: 2.6369 LossG_Style 3.1569 LossG_Content 2.6681\n",
            "===> Epoch[13](6/7): Loss_D: 0.6892 Loss_G: 9.0617 LossD_Fake: 0.6926 LossD_Real: 0.6859  LossG_Adv: 0.6938 LossG_L1: 2.6055 LossG_Style 3.0350 LossG_Content 2.7275\n",
            "\n",
            "saving sample dataset_13_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[13](7/7): Loss_D: 0.6894 Loss_G: 9.4958 LossD_Fake: 0.6936 LossD_Real: 0.6852  LossG_Adv: 0.6928 LossG_L1: 2.3962 LossG_Style 3.5931 LossG_Content 2.8138\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[14](1/7): Loss_D: 0.6899 Loss_G: 8.7160 LossD_Fake: 0.6946 LossD_Real: 0.6851  LossG_Adv: 0.6910 LossG_L1: 2.5801 LossG_Style 2.7104 LossG_Content 2.7344\n",
            "===> Epoch[14](2/7): Loss_D: 0.6893 Loss_G: 9.0400 LossD_Fake: 0.6952 LossD_Real: 0.6835  LossG_Adv: 0.6912 LossG_L1: 2.6485 LossG_Style 2.9428 LossG_Content 2.7575\n",
            "===> Epoch[14](3/7): Loss_D: 0.6892 Loss_G: 9.1715 LossD_Fake: 0.6933 LossD_Real: 0.6851  LossG_Adv: 0.6931 LossG_L1: 2.6735 LossG_Style 3.0435 LossG_Content 2.7614\n",
            "===> Epoch[14](4/7): Loss_D: 0.6882 Loss_G: 9.7882 LossD_Fake: 0.6952 LossD_Real: 0.6812  LossG_Adv: 0.6912 LossG_L1: 2.8290 LossG_Style 3.4237 LossG_Content 2.8442\n",
            "===> Epoch[14](5/7): Loss_D: 0.6901 Loss_G: 9.6323 LossD_Fake: 0.6944 LossD_Real: 0.6857  LossG_Adv: 0.6920 LossG_L1: 2.4827 LossG_Style 3.5015 LossG_Content 2.9561\n",
            "===> Epoch[14](6/7): Loss_D: 0.6882 Loss_G: 10.2444 LossD_Fake: 0.6929 LossD_Real: 0.6834  LossG_Adv: 0.6934 LossG_L1: 2.8240 LossG_Style 3.7124 LossG_Content 3.0145\n",
            "\n",
            "saving sample dataset_14_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[14](7/7): Loss_D: 0.6916 Loss_G: 8.9345 LossD_Fake: 0.6972 LossD_Real: 0.6859  LossG_Adv: 0.6893 LossG_L1: 2.7104 LossG_Style 2.9086 LossG_Content 2.6263\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[15](1/7): Loss_D: 0.6905 Loss_G: 9.1654 LossD_Fake: 0.6969 LossD_Real: 0.6840  LossG_Adv: 0.6893 LossG_L1: 2.6688 LossG_Style 3.0696 LossG_Content 2.7377\n",
            "===> Epoch[15](2/7): Loss_D: 0.6895 Loss_G: 9.9636 LossD_Fake: 0.6968 LossD_Real: 0.6823  LossG_Adv: 0.6897 LossG_L1: 2.7732 LossG_Style 3.5513 LossG_Content 2.9495\n",
            "===> Epoch[15](3/7): Loss_D: 0.6899 Loss_G: 8.8302 LossD_Fake: 0.6948 LossD_Real: 0.6851  LossG_Adv: 0.6916 LossG_L1: 2.6310 LossG_Style 2.8398 LossG_Content 2.6677\n",
            "===> Epoch[15](4/7): Loss_D: 0.6876 Loss_G: 9.9827 LossD_Fake: 0.6946 LossD_Real: 0.6807  LossG_Adv: 0.6918 LossG_L1: 2.8406 LossG_Style 3.5616 LossG_Content 2.8888\n",
            "===> Epoch[15](5/7): Loss_D: 0.6892 Loss_G: 8.6068 LossD_Fake: 0.6945 LossD_Real: 0.6839  LossG_Adv: 0.6919 LossG_L1: 2.7801 LossG_Style 2.5293 LossG_Content 2.6056\n",
            "===> Epoch[15](6/7): Loss_D: 0.6890 Loss_G: 8.9573 LossD_Fake: 0.6941 LossD_Real: 0.6840  LossG_Adv: 0.6923 LossG_L1: 2.6757 LossG_Style 2.9418 LossG_Content 2.6475\n",
            "\n",
            "saving sample dataset_15_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[15](7/7): Loss_D: 0.6870 Loss_G: 9.6084 LossD_Fake: 0.6940 LossD_Real: 0.6801  LossG_Adv: 0.6924 LossG_L1: 3.2471 LossG_Style 2.9491 LossG_Content 2.7198\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[16](1/7): Loss_D: 0.6882 Loss_G: 8.7666 LossD_Fake: 0.6928 LossD_Real: 0.6835  LossG_Adv: 0.6921 LossG_L1: 2.7061 LossG_Style 2.7365 LossG_Content 2.6319\n",
            "===> Epoch[16](2/7): Loss_D: 0.6879 Loss_G: 8.9354 LossD_Fake: 0.6957 LossD_Real: 0.6801  LossG_Adv: 0.6907 LossG_L1: 2.7309 LossG_Style 2.8903 LossG_Content 2.6235\n",
            "===> Epoch[16](3/7): Loss_D: 0.6871 Loss_G: 8.7027 LossD_Fake: 0.6951 LossD_Real: 0.6792  LossG_Adv: 0.6913 LossG_L1: 2.6767 LossG_Style 2.7526 LossG_Content 2.5821\n",
            "===> Epoch[16](4/7): Loss_D: 0.6893 Loss_G: 8.6511 LossD_Fake: 0.6970 LossD_Real: 0.6816  LossG_Adv: 0.6894 LossG_L1: 2.5187 LossG_Style 2.7961 LossG_Content 2.6469\n",
            "===> Epoch[16](5/7): Loss_D: 0.6893 Loss_G: 8.8962 LossD_Fake: 0.6965 LossD_Real: 0.6822  LossG_Adv: 0.6899 LossG_L1: 2.5932 LossG_Style 2.9548 LossG_Content 2.6582\n",
            "===> Epoch[16](6/7): Loss_D: 0.6871 Loss_G: 8.8313 LossD_Fake: 0.6956 LossD_Real: 0.6787  LossG_Adv: 0.6908 LossG_L1: 2.6937 LossG_Style 2.8443 LossG_Content 2.6025\n",
            "\n",
            "saving sample dataset_16_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[16](7/7): Loss_D: 0.6893 Loss_G: 10.6975 LossD_Fake: 0.6997 LossD_Real: 0.6789  LossG_Adv: 0.6868 LossG_L1: 2.4598 LossG_Style 4.3800 LossG_Content 3.1708\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[17](1/7): Loss_D: 0.6899 Loss_G: 8.5353 LossD_Fake: 0.6970 LossD_Real: 0.6828  LossG_Adv: 0.6918 LossG_L1: 2.6921 LossG_Style 2.5478 LossG_Content 2.6036\n",
            "===> Epoch[17](2/7): Loss_D: 0.6873 Loss_G: 9.2241 LossD_Fake: 0.6940 LossD_Real: 0.6806  LossG_Adv: 0.6924 LossG_L1: 2.6415 LossG_Style 3.1730 LossG_Content 2.7172\n",
            "===> Epoch[17](3/7): Loss_D: 0.6888 Loss_G: 8.2051 LossD_Fake: 0.6947 LossD_Real: 0.6830  LossG_Adv: 0.6918 LossG_L1: 2.4960 LossG_Style 2.4886 LossG_Content 2.5288\n",
            "===> Epoch[17](4/7): Loss_D: 0.6870 Loss_G: 9.6458 LossD_Fake: 0.6935 LossD_Real: 0.6805  LossG_Adv: 0.6929 LossG_L1: 2.7104 LossG_Style 3.4037 LossG_Content 2.8388\n",
            "===> Epoch[17](5/7): Loss_D: 0.6883 Loss_G: 9.2038 LossD_Fake: 0.6948 LossD_Real: 0.6819  LossG_Adv: 0.6917 LossG_L1: 2.5942 LossG_Style 3.1827 LossG_Content 2.7353\n",
            "===> Epoch[17](6/7): Loss_D: 0.6875 Loss_G: 8.8761 LossD_Fake: 0.6956 LossD_Real: 0.6794  LossG_Adv: 0.6908 LossG_L1: 2.6103 LossG_Style 2.8701 LossG_Content 2.7048\n",
            "\n",
            "saving sample dataset_17_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[17](7/7): Loss_D: 0.6897 Loss_G: 8.1282 LossD_Fake: 0.6949 LossD_Real: 0.6846  LossG_Adv: 0.6916 LossG_L1: 2.6592 LossG_Style 2.2203 LossG_Content 2.5571\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[18](1/7): Loss_D: 0.6857 Loss_G: 9.6676 LossD_Fake: 0.6920 LossD_Real: 0.6795  LossG_Adv: 0.6929 LossG_L1: 2.8144 LossG_Style 3.3709 LossG_Content 2.7894\n",
            "===> Epoch[18](2/7): Loss_D: 0.6899 Loss_G: 8.9926 LossD_Fake: 0.6998 LossD_Real: 0.6801  LossG_Adv: 0.6868 LossG_L1: 2.8394 LossG_Style 2.8472 LossG_Content 2.6193\n",
            "===> Epoch[18](3/7): Loss_D: 0.6891 Loss_G: 8.4179 LossD_Fake: 0.6983 LossD_Real: 0.6800  LossG_Adv: 0.6882 LossG_L1: 2.5322 LossG_Style 2.6063 LossG_Content 2.5913\n",
            "===> Epoch[18](4/7): Loss_D: 0.6883 Loss_G: 8.7756 LossD_Fake: 0.6986 LossD_Real: 0.6780  LossG_Adv: 0.6879 LossG_L1: 2.5608 LossG_Style 2.9139 LossG_Content 2.6130\n",
            "===> Epoch[18](5/7): Loss_D: 0.6882 Loss_G: 8.5852 LossD_Fake: 0.6978 LossD_Real: 0.6786  LossG_Adv: 0.6887 LossG_L1: 2.6404 LossG_Style 2.7162 LossG_Content 2.5400\n",
            "===> Epoch[18](6/7): Loss_D: 0.6869 Loss_G: 8.8250 LossD_Fake: 0.6971 LossD_Real: 0.6768  LossG_Adv: 0.6894 LossG_L1: 2.7836 LossG_Style 2.7514 LossG_Content 2.6006\n",
            "\n",
            "saving sample dataset_18_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[18](7/7): Loss_D: 0.6880 Loss_G: 8.5300 LossD_Fake: 0.6978 LossD_Real: 0.6781  LossG_Adv: 0.6887 LossG_L1: 2.8163 LossG_Style 2.5310 LossG_Content 2.4939\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[19](1/7): Loss_D: 0.6856 Loss_G: 8.9852 LossD_Fake: 0.6957 LossD_Real: 0.6756  LossG_Adv: 0.6896 LossG_L1: 2.7174 LossG_Style 2.9964 LossG_Content 2.5817\n",
            "===> Epoch[19](2/7): Loss_D: 0.6879 Loss_G: 8.6742 LossD_Fake: 0.6985 LossD_Real: 0.6773  LossG_Adv: 0.6880 LossG_L1: 2.6671 LossG_Style 2.7413 LossG_Content 2.5777\n",
            "===> Epoch[19](3/7): Loss_D: 0.6873 Loss_G: 8.5219 LossD_Fake: 0.6986 LossD_Real: 0.6760  LossG_Adv: 0.6879 LossG_L1: 2.5612 LossG_Style 2.6974 LossG_Content 2.5754\n",
            "===> Epoch[19](4/7): Loss_D: 0.6876 Loss_G: 8.7686 LossD_Fake: 0.6986 LossD_Real: 0.6767  LossG_Adv: 0.6879 LossG_L1: 2.5786 LossG_Style 2.9057 LossG_Content 2.5963\n",
            "===> Epoch[19](5/7): Loss_D: 0.6865 Loss_G: 8.5899 LossD_Fake: 0.6964 LossD_Real: 0.6767  LossG_Adv: 0.6901 LossG_L1: 2.5250 LossG_Style 2.8075 LossG_Content 2.5673\n",
            "===> Epoch[19](6/7): Loss_D: 0.6863 Loss_G: 8.4546 LossD_Fake: 0.6968 LossD_Real: 0.6758  LossG_Adv: 0.6897 LossG_L1: 2.5388 LossG_Style 2.7178 LossG_Content 2.5083\n",
            "\n",
            "saving sample dataset_19_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[19](7/7): Loss_D: 0.6836 Loss_G: 9.3712 LossD_Fake: 0.6973 LossD_Real: 0.6699  LossG_Adv: 0.6892 LossG_L1: 2.9084 LossG_Style 2.9984 LossG_Content 2.7752\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[20](1/7): Loss_D: 0.6876 Loss_G: 8.7911 LossD_Fake: 0.6999 LossD_Real: 0.6753  LossG_Adv: 0.6881 LossG_L1: 2.5205 LossG_Style 2.9302 LossG_Content 2.6523\n",
            "===> Epoch[20](2/7): Loss_D: 0.6875 Loss_G: 8.9616 LossD_Fake: 0.6990 LossD_Real: 0.6760  LossG_Adv: 0.6876 LossG_L1: 2.6642 LossG_Style 2.9116 LossG_Content 2.6982\n",
            "===> Epoch[20](3/7): Loss_D: 0.6869 Loss_G: 8.1924 LossD_Fake: 0.6976 LossD_Real: 0.6762  LossG_Adv: 0.6889 LossG_L1: 2.5601 LossG_Style 2.4381 LossG_Content 2.5053\n",
            "===> Epoch[20](4/7): Loss_D: 0.6854 Loss_G: 8.8589 LossD_Fake: 0.6968 LossD_Real: 0.6740  LossG_Adv: 0.6897 LossG_L1: 2.7862 LossG_Style 2.8206 LossG_Content 2.5625\n",
            "===> Epoch[20](5/7): Loss_D: 0.6895 Loss_G: 7.8814 LossD_Fake: 0.7003 LossD_Real: 0.6787  LossG_Adv: 0.6863 LossG_L1: 2.3618 LossG_Style 2.3519 LossG_Content 2.4815\n",
            "===> Epoch[20](6/7): Loss_D: 0.6851 Loss_G: 9.3077 LossD_Fake: 0.6976 LossD_Real: 0.6726  LossG_Adv: 0.6889 LossG_L1: 2.6322 LossG_Style 3.3116 LossG_Content 2.6749\n",
            "\n",
            "saving sample dataset_20_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[20](7/7): Loss_D: 0.6948 Loss_G: 7.0886 LossD_Fake: 0.7002 LossD_Real: 0.6893  LossG_Adv: 0.6864 LossG_L1: 2.2461 LossG_Style 1.8982 LossG_Content 2.2579\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[21](1/7): Loss_D: 0.6838 Loss_G: 8.7200 LossD_Fake: 0.6924 LossD_Real: 0.6752  LossG_Adv: 0.6926 LossG_L1: 2.6829 LossG_Style 2.8579 LossG_Content 2.4866\n",
            "===> Epoch[21](2/7): Loss_D: 0.6862 Loss_G: 7.9873 LossD_Fake: 0.6977 LossD_Real: 0.6747  LossG_Adv: 0.6888 LossG_L1: 2.3611 LossG_Style 2.5455 LossG_Content 2.3918\n",
            "===> Epoch[21](3/7): Loss_D: 0.6847 Loss_G: 8.9356 LossD_Fake: 0.6981 LossD_Real: 0.6712  LossG_Adv: 0.6884 LossG_L1: 2.6883 LossG_Style 2.9556 LossG_Content 2.6033\n",
            "===> Epoch[21](4/7): Loss_D: 0.6869 Loss_G: 8.5874 LossD_Fake: 0.6987 LossD_Real: 0.6751  LossG_Adv: 0.6878 LossG_L1: 2.5173 LossG_Style 2.7960 LossG_Content 2.5863\n",
            "===> Epoch[21](5/7): Loss_D: 0.6865 Loss_G: 8.4852 LossD_Fake: 0.6995 LossD_Real: 0.6734  LossG_Adv: 0.6870 LossG_L1: 2.6334 LossG_Style 2.6017 LossG_Content 2.5630\n",
            "===> Epoch[21](6/7): Loss_D: 0.6853 Loss_G: 8.3660 LossD_Fake: 0.6988 LossD_Real: 0.6719  LossG_Adv: 0.6877 LossG_L1: 2.4641 LossG_Style 2.6795 LossG_Content 2.5347\n",
            "\n",
            "saving sample dataset_21_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[21](7/7): Loss_D: 0.6832 Loss_G: 8.1674 LossD_Fake: 0.7008 LossD_Real: 0.6656  LossG_Adv: 0.6858 LossG_L1: 2.7678 LossG_Style 2.3310 LossG_Content 2.3828\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[22](1/7): Loss_D: 0.6873 Loss_G: 7.9762 LossD_Fake: 0.7008 LossD_Real: 0.6737  LossG_Adv: 0.6872 LossG_L1: 2.5599 LossG_Style 2.3442 LossG_Content 2.3849\n",
            "===> Epoch[22](2/7): Loss_D: 0.6866 Loss_G: 8.6032 LossD_Fake: 0.6972 LossD_Real: 0.6759  LossG_Adv: 0.6894 LossG_L1: 2.5274 LossG_Style 2.8105 LossG_Content 2.5760\n",
            "===> Epoch[22](3/7): Loss_D: 0.6873 Loss_G: 7.9170 LossD_Fake: 0.6997 LossD_Real: 0.6748  LossG_Adv: 0.6869 LossG_L1: 2.4055 LossG_Style 2.3646 LossG_Content 2.4601\n",
            "===> Epoch[22](4/7): Loss_D: 0.6847 Loss_G: 9.0528 LossD_Fake: 0.6998 LossD_Real: 0.6696  LossG_Adv: 0.6868 LossG_L1: 2.5768 LossG_Style 3.1373 LossG_Content 2.6519\n",
            "===> Epoch[22](5/7): Loss_D: 0.6872 Loss_G: 8.2094 LossD_Fake: 0.6992 LossD_Real: 0.6752  LossG_Adv: 0.6873 LossG_L1: 2.4855 LossG_Style 2.4945 LossG_Content 2.5420\n",
            "===> Epoch[22](6/7): Loss_D: 0.6849 Loss_G: 8.4369 LossD_Fake: 0.7003 LossD_Real: 0.6695  LossG_Adv: 0.6863 LossG_L1: 2.6403 LossG_Style 2.6151 LossG_Content 2.4953\n",
            "\n",
            "saving sample dataset_22_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[22](7/7): Loss_D: 0.6854 Loss_G: 9.2654 LossD_Fake: 0.6993 LossD_Real: 0.6716  LossG_Adv: 0.6873 LossG_L1: 2.5593 LossG_Style 3.3001 LossG_Content 2.7187\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[23](1/7): Loss_D: 0.6883 Loss_G: 8.4251 LossD_Fake: 0.7015 LossD_Real: 0.6751  LossG_Adv: 0.6869 LossG_L1: 2.5916 LossG_Style 2.6348 LossG_Content 2.5118\n",
            "===> Epoch[23](2/7): Loss_D: 0.6837 Loss_G: 8.3647 LossD_Fake: 0.6952 LossD_Real: 0.6722  LossG_Adv: 0.6914 LossG_L1: 2.5732 LossG_Style 2.5560 LossG_Content 2.5441\n",
            "===> Epoch[23](3/7): Loss_D: 0.6882 Loss_G: 8.0454 LossD_Fake: 0.7008 LossD_Real: 0.6756  LossG_Adv: 0.6858 LossG_L1: 2.4024 LossG_Style 2.4984 LossG_Content 2.4588\n",
            "===> Epoch[23](4/7): Loss_D: 0.6855 Loss_G: 8.1197 LossD_Fake: 0.6980 LossD_Real: 0.6730  LossG_Adv: 0.6886 LossG_L1: 2.4884 LossG_Style 2.5063 LossG_Content 2.4364\n",
            "===> Epoch[23](5/7): Loss_D: 0.6865 Loss_G: 8.5002 LossD_Fake: 0.6998 LossD_Real: 0.6731  LossG_Adv: 0.6868 LossG_L1: 2.5488 LossG_Style 2.6911 LossG_Content 2.5735\n",
            "===> Epoch[23](6/7): Loss_D: 0.6849 Loss_G: 8.0477 LossD_Fake: 0.6954 LossD_Real: 0.6744  LossG_Adv: 0.6911 LossG_L1: 2.4509 LossG_Style 2.4302 LossG_Content 2.4754\n",
            "\n",
            "saving sample dataset_23_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[23](7/7): Loss_D: 0.6868 Loss_G: 8.4533 LossD_Fake: 0.7014 LossD_Real: 0.6722  LossG_Adv: 0.6854 LossG_L1: 2.5589 LossG_Style 2.7384 LossG_Content 2.4706\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[24](1/7): Loss_D: 0.6874 Loss_G: 8.2136 LossD_Fake: 0.7003 LossD_Real: 0.6745  LossG_Adv: 0.6882 LossG_L1: 2.5408 LossG_Style 2.4076 LossG_Content 2.5770\n",
            "===> Epoch[24](2/7): Loss_D: 0.6860 Loss_G: 7.9472 LossD_Fake: 0.6942 LossD_Real: 0.6777  LossG_Adv: 0.6923 LossG_L1: 2.4173 LossG_Style 2.4838 LossG_Content 2.3537\n",
            "===> Epoch[24](3/7): Loss_D: 0.6859 Loss_G: 8.3567 LossD_Fake: 0.6966 LossD_Real: 0.6752  LossG_Adv: 0.6900 LossG_L1: 2.4488 LossG_Style 2.6421 LossG_Content 2.5757\n",
            "===> Epoch[24](4/7): Loss_D: 0.6854 Loss_G: 8.0022 LossD_Fake: 0.6969 LossD_Real: 0.6739  LossG_Adv: 0.6897 LossG_L1: 2.5080 LossG_Style 2.4116 LossG_Content 2.3929\n",
            "===> Epoch[24](5/7): Loss_D: 0.6841 Loss_G: 8.4882 LossD_Fake: 0.6955 LossD_Real: 0.6727  LossG_Adv: 0.6910 LossG_L1: 2.6452 LossG_Style 2.5912 LossG_Content 2.5608\n",
            "===> Epoch[24](6/7): Loss_D: 0.6844 Loss_G: 8.2078 LossD_Fake: 0.6955 LossD_Real: 0.6733  LossG_Adv: 0.6911 LossG_L1: 2.4749 LossG_Style 2.5643 LossG_Content 2.4775\n",
            "\n",
            "saving sample dataset_24_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[24](7/7): Loss_D: 0.6925 Loss_G: 8.6654 LossD_Fake: 0.7017 LossD_Real: 0.6834  LossG_Adv: 0.6851 LossG_L1: 2.2750 LossG_Style 3.0252 LossG_Content 2.6801\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[25](1/7): Loss_D: 0.6838 Loss_G: 8.1259 LossD_Fake: 0.6923 LossD_Real: 0.6754  LossG_Adv: 0.6925 LossG_L1: 2.3947 LossG_Style 2.5464 LossG_Content 2.4922\n",
            "===> Epoch[25](2/7): Loss_D: 0.6880 Loss_G: 8.2891 LossD_Fake: 0.7033 LossD_Real: 0.6727  LossG_Adv: 0.6835 LossG_L1: 2.5563 LossG_Style 2.5252 LossG_Content 2.5241\n",
            "===> Epoch[25](3/7): Loss_D: 0.6851 Loss_G: 8.2540 LossD_Fake: 0.6972 LossD_Real: 0.6731  LossG_Adv: 0.6894 LossG_L1: 2.3799 LossG_Style 2.6691 LossG_Content 2.5156\n",
            "===> Epoch[25](4/7): Loss_D: 0.6857 Loss_G: 7.9549 LossD_Fake: 0.6998 LossD_Real: 0.6715  LossG_Adv: 0.6870 LossG_L1: 2.4631 LossG_Style 2.3594 LossG_Content 2.4454\n",
            "===> Epoch[25](5/7): Loss_D: 0.6848 Loss_G: 8.1190 LossD_Fake: 0.6998 LossD_Real: 0.6698  LossG_Adv: 0.6868 LossG_L1: 2.6356 LossG_Style 2.3895 LossG_Content 2.4071\n",
            "===> Epoch[25](6/7): Loss_D: 0.6847 Loss_G: 8.0199 LossD_Fake: 0.6977 LossD_Real: 0.6717  LossG_Adv: 0.6889 LossG_L1: 2.5613 LossG_Style 2.3094 LossG_Content 2.4603\n",
            "\n",
            "saving sample dataset_25_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[25](7/7): Loss_D: 0.6852 Loss_G: 8.9618 LossD_Fake: 0.7018 LossD_Real: 0.6686  LossG_Adv: 0.6849 LossG_L1: 2.4109 LossG_Style 3.2203 LossG_Content 2.6457\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[26](1/7): Loss_D: 0.6892 Loss_G: 8.1497 LossD_Fake: 0.7040 LossD_Real: 0.6743  LossG_Adv: 0.6861 LossG_L1: 2.3736 LossG_Style 2.5968 LossG_Content 2.4933\n",
            "===> Epoch[26](2/7): Loss_D: 0.6831 Loss_G: 8.7369 LossD_Fake: 0.6951 LossD_Real: 0.6711  LossG_Adv: 0.6915 LossG_L1: 2.6404 LossG_Style 2.8251 LossG_Content 2.5799\n",
            "===> Epoch[26](3/7): Loss_D: 0.6857 Loss_G: 8.0174 LossD_Fake: 0.6966 LossD_Real: 0.6748  LossG_Adv: 0.6900 LossG_L1: 2.4326 LossG_Style 2.3864 LossG_Content 2.5084\n",
            "===> Epoch[26](4/7): Loss_D: 0.6850 Loss_G: 7.8788 LossD_Fake: 0.6953 LossD_Real: 0.6748  LossG_Adv: 0.6913 LossG_L1: 2.3842 LossG_Style 2.3648 LossG_Content 2.4385\n",
            "===> Epoch[26](5/7): Loss_D: 0.6854 Loss_G: 8.0338 LossD_Fake: 0.6948 LossD_Real: 0.6760  LossG_Adv: 0.6918 LossG_L1: 2.4241 LossG_Style 2.4030 LossG_Content 2.5149\n",
            "===> Epoch[26](6/7): Loss_D: 0.6852 Loss_G: 8.4272 LossD_Fake: 0.6991 LossD_Real: 0.6712  LossG_Adv: 0.6875 LossG_L1: 2.6063 LossG_Style 2.6404 LossG_Content 2.4930\n",
            "\n",
            "saving sample dataset_26_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[26](7/7): Loss_D: 0.6902 Loss_G: 7.9145 LossD_Fake: 0.6974 LossD_Real: 0.6829  LossG_Adv: 0.6892 LossG_L1: 2.4183 LossG_Style 2.3219 LossG_Content 2.4851\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[27](1/7): Loss_D: 0.6850 Loss_G: 8.1742 LossD_Fake: 0.6921 LossD_Real: 0.6780  LossG_Adv: 0.6951 LossG_L1: 2.4423 LossG_Style 2.6754 LossG_Content 2.3614\n",
            "===> Epoch[27](2/7): Loss_D: 0.6852 Loss_G: 8.2561 LossD_Fake: 0.6961 LossD_Real: 0.6743  LossG_Adv: 0.6905 LossG_L1: 2.4688 LossG_Style 2.6011 LossG_Content 2.4957\n",
            "===> Epoch[27](3/7): Loss_D: 0.6829 Loss_G: 8.0010 LossD_Fake: 0.6951 LossD_Real: 0.6708  LossG_Adv: 0.6915 LossG_L1: 2.6501 LossG_Style 2.2704 LossG_Content 2.3891\n",
            "===> Epoch[27](4/7): Loss_D: 0.6843 Loss_G: 8.1394 LossD_Fake: 0.6958 LossD_Real: 0.6728  LossG_Adv: 0.6907 LossG_L1: 2.3652 LossG_Style 2.5430 LossG_Content 2.5405\n",
            "===> Epoch[27](5/7): Loss_D: 0.6854 Loss_G: 8.0408 LossD_Fake: 0.6989 LossD_Real: 0.6719  LossG_Adv: 0.6877 LossG_L1: 2.4370 LossG_Style 2.4418 LossG_Content 2.4743\n",
            "===> Epoch[27](6/7): Loss_D: 0.6867 Loss_G: 7.8257 LossD_Fake: 0.6969 LossD_Real: 0.6765  LossG_Adv: 0.6896 LossG_L1: 2.4311 LossG_Style 2.2698 LossG_Content 2.4351\n",
            "\n",
            "saving sample dataset_27_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[27](7/7): Loss_D: 0.6830 Loss_G: 8.4558 LossD_Fake: 0.6960 LossD_Real: 0.6699  LossG_Adv: 0.6906 LossG_L1: 2.7559 LossG_Style 2.5405 LossG_Content 2.4688\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[28](1/7): Loss_D: 0.6828 Loss_G: 8.6185 LossD_Fake: 0.6945 LossD_Real: 0.6712  LossG_Adv: 0.6921 LossG_L1: 2.5315 LossG_Style 2.7545 LossG_Content 2.6405\n",
            "===> Epoch[28](2/7): Loss_D: 0.6862 Loss_G: 7.7329 LossD_Fake: 0.6986 LossD_Real: 0.6738  LossG_Adv: 0.6882 LossG_L1: 2.6171 LossG_Style 2.1521 LossG_Content 2.2754\n",
            "===> Epoch[28](3/7): Loss_D: 0.6833 Loss_G: 7.7616 LossD_Fake: 0.6919 LossD_Real: 0.6748  LossG_Adv: 0.6947 LossG_L1: 2.4481 LossG_Style 2.2147 LossG_Content 2.4041\n",
            "===> Epoch[28](4/7): Loss_D: 0.6850 Loss_G: 8.2128 LossD_Fake: 0.7005 LossD_Real: 0.6696  LossG_Adv: 0.6862 LossG_L1: 2.4802 LossG_Style 2.5650 LossG_Content 2.4815\n",
            "===> Epoch[28](5/7): Loss_D: 0.6864 Loss_G: 7.5837 LossD_Fake: 0.6993 LossD_Real: 0.6734  LossG_Adv: 0.6873 LossG_L1: 2.1836 LossG_Style 2.2442 LossG_Content 2.4685\n",
            "===> Epoch[28](6/7): Loss_D: 0.6863 Loss_G: 8.0457 LossD_Fake: 0.6992 LossD_Real: 0.6735  LossG_Adv: 0.6875 LossG_L1: 2.3240 LossG_Style 2.5685 LossG_Content 2.4656\n",
            "\n",
            "saving sample dataset_28_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[28](7/7): Loss_D: 0.6832 Loss_G: 8.0557 LossD_Fake: 0.6970 LossD_Real: 0.6693  LossG_Adv: 0.6897 LossG_L1: 2.5507 LossG_Style 2.3762 LossG_Content 2.4391\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[29](1/7): Loss_D: 0.6851 Loss_G: 8.1596 LossD_Fake: 0.6992 LossD_Real: 0.6711  LossG_Adv: 0.6908 LossG_L1: 2.4652 LossG_Style 2.5081 LossG_Content 2.4956\n",
            "===> Epoch[29](2/7): Loss_D: 0.6827 Loss_G: 8.0477 LossD_Fake: 0.6932 LossD_Real: 0.6723  LossG_Adv: 0.6935 LossG_L1: 2.5205 LossG_Style 2.3674 LossG_Content 2.4663\n",
            "===> Epoch[29](3/7): Loss_D: 0.6858 Loss_G: 8.0799 LossD_Fake: 0.6985 LossD_Real: 0.6732  LossG_Adv: 0.6883 LossG_L1: 2.4555 LossG_Style 2.4884 LossG_Content 2.4477\n",
            "===> Epoch[29](4/7): Loss_D: 0.6879 Loss_G: 7.7149 LossD_Fake: 0.6977 LossD_Real: 0.6781  LossG_Adv: 0.6890 LossG_L1: 2.2961 LossG_Style 2.2898 LossG_Content 2.4400\n",
            "===> Epoch[29](5/7): Loss_D: 0.6829 Loss_G: 7.7991 LossD_Fake: 0.6909 LossD_Real: 0.6749  LossG_Adv: 0.6957 LossG_L1: 2.3856 LossG_Style 2.2876 LossG_Content 2.4302\n",
            "===> Epoch[29](6/7): Loss_D: 0.6887 Loss_G: 8.0328 LossD_Fake: 0.7005 LossD_Real: 0.6770  LossG_Adv: 0.6863 LossG_L1: 2.5231 LossG_Style 2.4709 LossG_Content 2.3524\n",
            "\n",
            "saving sample dataset_29_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[29](7/7): Loss_D: 0.6810 Loss_G: 8.7492 LossD_Fake: 0.6911 LossD_Real: 0.6708  LossG_Adv: 0.6955 LossG_L1: 2.4605 LossG_Style 2.9061 LossG_Content 2.6872\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[30](1/7): Loss_D: 0.6880 Loss_G: 8.3940 LossD_Fake: 0.6993 LossD_Real: 0.6767  LossG_Adv: 0.6880 LossG_L1: 2.5718 LossG_Style 2.5829 LossG_Content 2.5512\n",
            "===> Epoch[30](2/7): Loss_D: 0.6828 Loss_G: 7.7574 LossD_Fake: 0.6911 LossD_Real: 0.6744  LossG_Adv: 0.6956 LossG_L1: 2.3597 LossG_Style 2.3106 LossG_Content 2.3915\n",
            "===> Epoch[30](3/7): Loss_D: 0.6846 Loss_G: 8.0827 LossD_Fake: 0.6966 LossD_Real: 0.6727  LossG_Adv: 0.6901 LossG_L1: 2.5387 LossG_Style 2.3741 LossG_Content 2.4798\n",
            "===> Epoch[30](4/7): Loss_D: 0.6840 Loss_G: 8.0243 LossD_Fake: 0.6934 LossD_Real: 0.6747  LossG_Adv: 0.6932 LossG_L1: 2.3856 LossG_Style 2.4531 LossG_Content 2.4923\n",
            "===> Epoch[30](5/7): Loss_D: 0.6856 Loss_G: 7.7502 LossD_Fake: 0.6978 LossD_Real: 0.6734  LossG_Adv: 0.6890 LossG_L1: 2.4708 LossG_Style 2.2193 LossG_Content 2.3711\n",
            "===> Epoch[30](6/7): Loss_D: 0.6851 Loss_G: 7.3696 LossD_Fake: 0.6951 LossD_Real: 0.6751  LossG_Adv: 0.6916 LossG_L1: 2.4274 LossG_Style 1.9990 LossG_Content 2.2516\n",
            "\n",
            "saving sample dataset_30_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[30](7/7): Loss_D: 0.6846 Loss_G: 7.9870 LossD_Fake: 0.6952 LossD_Real: 0.6740  LossG_Adv: 0.6915 LossG_L1: 2.2872 LossG_Style 2.5746 LossG_Content 2.4337\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[31](1/7): Loss_D: 0.6841 Loss_G: 7.8954 LossD_Fake: 0.6924 LossD_Real: 0.6759  LossG_Adv: 0.6954 LossG_L1: 2.4542 LossG_Style 2.2941 LossG_Content 2.4517\n",
            "===> Epoch[31](2/7): Loss_D: 0.6843 Loss_G: 8.2349 LossD_Fake: 0.6947 LossD_Real: 0.6739  LossG_Adv: 0.6920 LossG_L1: 2.4229 LossG_Style 2.6772 LossG_Content 2.4428\n",
            "===> Epoch[31](3/7): Loss_D: 0.6822 Loss_G: 7.7532 LossD_Fake: 0.6917 LossD_Real: 0.6726  LossG_Adv: 0.6949 LossG_L1: 2.3688 LossG_Style 2.2457 LossG_Content 2.4438\n",
            "===> Epoch[31](4/7): Loss_D: 0.6837 Loss_G: 8.6439 LossD_Fake: 0.6970 LossD_Real: 0.6705  LossG_Adv: 0.6898 LossG_L1: 2.5205 LossG_Style 2.7798 LossG_Content 2.6537\n",
            "===> Epoch[31](5/7): Loss_D: 0.6864 Loss_G: 7.8911 LossD_Fake: 0.6984 LossD_Real: 0.6743  LossG_Adv: 0.6884 LossG_L1: 2.2133 LossG_Style 2.4970 LossG_Content 2.4923\n",
            "===> Epoch[31](6/7): Loss_D: 0.6873 Loss_G: 7.4280 LossD_Fake: 0.6979 LossD_Real: 0.6766  LossG_Adv: 0.6889 LossG_L1: 2.4623 LossG_Style 1.9769 LossG_Content 2.2999\n",
            "\n",
            "saving sample dataset_31_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[31](7/7): Loss_D: 0.6884 Loss_G: 7.6726 LossD_Fake: 0.6929 LossD_Real: 0.6840  LossG_Adv: 0.6939 LossG_L1: 2.3954 LossG_Style 2.2457 LossG_Content 2.3375\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[32](1/7): Loss_D: 0.6833 Loss_G: 8.2212 LossD_Fake: 0.6929 LossD_Real: 0.6737  LossG_Adv: 0.6918 LossG_L1: 2.5243 LossG_Style 2.4646 LossG_Content 2.5404\n",
            "===> Epoch[32](2/7): Loss_D: 0.6808 Loss_G: 7.8790 LossD_Fake: 0.6927 LossD_Real: 0.6688  LossG_Adv: 0.6940 LossG_L1: 2.5451 LossG_Style 2.2224 LossG_Content 2.4174\n",
            "===> Epoch[32](3/7): Loss_D: 0.6828 Loss_G: 7.4390 LossD_Fake: 0.6917 LossD_Real: 0.6739  LossG_Adv: 0.6950 LossG_L1: 2.2990 LossG_Style 2.1087 LossG_Content 2.3363\n",
            "===> Epoch[32](4/7): Loss_D: 0.6833 Loss_G: 7.9040 LossD_Fake: 0.6960 LossD_Real: 0.6706  LossG_Adv: 0.6908 LossG_L1: 2.4780 LossG_Style 2.3342 LossG_Content 2.4009\n",
            "===> Epoch[32](5/7): Loss_D: 0.6829 Loss_G: 7.5279 LossD_Fake: 0.6941 LossD_Real: 0.6716  LossG_Adv: 0.6926 LossG_L1: 2.2444 LossG_Style 2.1933 LossG_Content 2.3975\n",
            "===> Epoch[32](6/7): Loss_D: 0.6858 Loss_G: 8.0239 LossD_Fake: 0.7001 LossD_Real: 0.6716  LossG_Adv: 0.6868 LossG_L1: 2.5003 LossG_Style 2.4208 LossG_Content 2.4161\n",
            "\n",
            "saving sample dataset_32_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[32](7/7): Loss_D: 0.6828 Loss_G: 8.4660 LossD_Fake: 0.6985 LossD_Real: 0.6671  LossG_Adv: 0.6882 LossG_L1: 2.3791 LossG_Style 2.8306 LossG_Content 2.5682\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[33](1/7): Loss_D: 0.6870 Loss_G: 7.9608 LossD_Fake: 0.7009 LossD_Real: 0.6730  LossG_Adv: 0.6918 LossG_L1: 2.4969 LossG_Style 2.2749 LossG_Content 2.4971\n",
            "===> Epoch[33](2/7): Loss_D: 0.6831 Loss_G: 7.6186 LossD_Fake: 0.6886 LossD_Real: 0.6776  LossG_Adv: 0.6981 LossG_L1: 2.4755 LossG_Style 2.1081 LossG_Content 2.3368\n",
            "===> Epoch[33](3/7): Loss_D: 0.6810 Loss_G: 7.4762 LossD_Fake: 0.6884 LossD_Real: 0.6735  LossG_Adv: 0.6983 LossG_L1: 2.2312 LossG_Style 2.1945 LossG_Content 2.3521\n",
            "===> Epoch[33](4/7): Loss_D: 0.6877 Loss_G: 7.3824 LossD_Fake: 0.6983 LossD_Real: 0.6770  LossG_Adv: 0.6886 LossG_L1: 2.2999 LossG_Style 2.1264 LossG_Content 2.2675\n",
            "===> Epoch[33](5/7): Loss_D: 0.6815 Loss_G: 8.1148 LossD_Fake: 0.6916 LossD_Real: 0.6714  LossG_Adv: 0.6952 LossG_L1: 2.4499 LossG_Style 2.5102 LossG_Content 2.4595\n",
            "===> Epoch[33](6/7): Loss_D: 0.6868 Loss_G: 7.5619 LossD_Fake: 0.6958 LossD_Real: 0.6778  LossG_Adv: 0.6909 LossG_L1: 2.3073 LossG_Style 2.1637 LossG_Content 2.4000\n",
            "\n",
            "saving sample dataset_33_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[33](7/7): Loss_D: 0.6809 Loss_G: 8.7915 LossD_Fake: 0.6883 LossD_Real: 0.6735  LossG_Adv: 0.6986 LossG_L1: 2.8304 LossG_Style 2.6163 LossG_Content 2.6462\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[34](1/7): Loss_D: 0.6842 Loss_G: 7.6097 LossD_Fake: 0.6870 LossD_Real: 0.6814  LossG_Adv: 0.7022 LossG_L1: 2.4479 LossG_Style 2.0653 LossG_Content 2.3943\n",
            "===> Epoch[34](2/7): Loss_D: 0.6800 Loss_G: 8.2535 LossD_Fake: 0.6859 LossD_Real: 0.6742  LossG_Adv: 0.7008 LossG_L1: 2.4241 LossG_Style 2.6467 LossG_Content 2.4818\n",
            "===> Epoch[34](3/7): Loss_D: 0.6863 Loss_G: 7.8705 LossD_Fake: 0.6928 LossD_Real: 0.6797  LossG_Adv: 0.6939 LossG_L1: 2.2571 LossG_Style 2.4003 LossG_Content 2.5192\n",
            "===> Epoch[34](4/7): Loss_D: 0.6815 Loss_G: 7.7715 LossD_Fake: 0.6885 LossD_Real: 0.6745  LossG_Adv: 0.6983 LossG_L1: 2.3905 LossG_Style 2.3388 LossG_Content 2.3439\n",
            "===> Epoch[34](5/7): Loss_D: 0.6838 Loss_G: 7.8352 LossD_Fake: 0.6936 LossD_Real: 0.6741  LossG_Adv: 0.6931 LossG_L1: 2.2970 LossG_Style 2.3823 LossG_Content 2.4629\n",
            "===> Epoch[34](6/7): Loss_D: 0.6839 Loss_G: 7.4396 LossD_Fake: 0.6917 LossD_Real: 0.6761  LossG_Adv: 0.6951 LossG_L1: 2.2666 LossG_Style 2.1398 LossG_Content 2.3381\n",
            "\n",
            "saving sample dataset_34_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[34](7/7): Loss_D: 0.6844 Loss_G: 6.9112 LossD_Fake: 0.6902 LossD_Real: 0.6786  LossG_Adv: 0.6966 LossG_L1: 2.3934 LossG_Style 1.7708 LossG_Content 2.0505\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[35](1/7): Loss_D: 0.6845 Loss_G: 7.3304 LossD_Fake: 0.6881 LossD_Real: 0.6810  LossG_Adv: 0.7042 LossG_L1: 2.2864 LossG_Style 2.0378 LossG_Content 2.3020\n",
            "===> Epoch[35](2/7): Loss_D: 0.6826 Loss_G: 8.3558 LossD_Fake: 0.6874 LossD_Real: 0.6777  LossG_Adv: 0.6993 LossG_L1: 2.4343 LossG_Style 2.6588 LossG_Content 2.5635\n",
            "===> Epoch[35](3/7): Loss_D: 0.6863 Loss_G: 7.8396 LossD_Fake: 0.6884 LossD_Real: 0.6843  LossG_Adv: 0.6983 LossG_L1: 2.3945 LossG_Style 2.2856 LossG_Content 2.4612\n",
            "===> Epoch[35](4/7): Loss_D: 0.6793 Loss_G: 7.8851 LossD_Fake: 0.6823 LossD_Real: 0.6763  LossG_Adv: 0.7045 LossG_L1: 2.5460 LossG_Style 2.3045 LossG_Content 2.3300\n",
            "===> Epoch[35](5/7): Loss_D: 0.6839 Loss_G: 7.9278 LossD_Fake: 0.6847 LossD_Real: 0.6831  LossG_Adv: 0.7020 LossG_L1: 2.3947 LossG_Style 2.3391 LossG_Content 2.4919\n",
            "===> Epoch[35](6/7): Loss_D: 0.6867 Loss_G: 7.2578 LossD_Fake: 0.6872 LossD_Real: 0.6861  LossG_Adv: 0.6995 LossG_L1: 2.2561 LossG_Style 1.9487 LossG_Content 2.3534\n",
            "\n",
            "saving sample dataset_35_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[35](7/7): Loss_D: 0.6724 Loss_G: 7.3742 LossD_Fake: 0.6798 LossD_Real: 0.6650  LossG_Adv: 0.7070 LossG_L1: 2.5604 LossG_Style 1.9944 LossG_Content 2.1123\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[36](1/7): Loss_D: 0.6889 Loss_G: 7.6410 LossD_Fake: 0.6923 LossD_Real: 0.6856  LossG_Adv: 0.7022 LossG_L1: 2.3332 LossG_Style 2.1756 LossG_Content 2.4300\n",
            "===> Epoch[36](2/7): Loss_D: 0.6832 Loss_G: 7.4221 LossD_Fake: 0.6795 LossD_Real: 0.6870  LossG_Adv: 0.7073 LossG_L1: 2.3528 LossG_Style 2.0838 LossG_Content 2.2781\n",
            "===> Epoch[36](3/7): Loss_D: 0.6851 Loss_G: 7.4172 LossD_Fake: 0.6790 LossD_Real: 0.6911  LossG_Adv: 0.7078 LossG_L1: 2.2572 LossG_Style 2.0943 LossG_Content 2.3580\n",
            "===> Epoch[36](4/7): Loss_D: 0.6827 Loss_G: 7.6792 LossD_Fake: 0.6757 LossD_Real: 0.6896  LossG_Adv: 0.7112 LossG_L1: 2.2093 LossG_Style 2.3651 LossG_Content 2.3936\n",
            "===> Epoch[36](5/7): Loss_D: 0.6839 Loss_G: 7.6425 LossD_Fake: 0.6795 LossD_Real: 0.6882  LossG_Adv: 0.7072 LossG_L1: 2.4470 LossG_Style 2.1111 LossG_Content 2.3771\n",
            "===> Epoch[36](6/7): Loss_D: 0.6806 Loss_G: 7.7411 LossD_Fake: 0.6773 LossD_Real: 0.6840  LossG_Adv: 0.7096 LossG_L1: 2.4391 LossG_Style 2.2139 LossG_Content 2.3784\n",
            "\n",
            "saving sample dataset_36_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[36](7/7): Loss_D: 0.6800 Loss_G: 7.9566 LossD_Fake: 0.6771 LossD_Real: 0.6829  LossG_Adv: 0.7097 LossG_L1: 2.5043 LossG_Style 2.3090 LossG_Content 2.4335\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[37](1/7): Loss_D: 0.6878 Loss_G: 7.6171 LossD_Fake: 0.6806 LossD_Real: 0.6951  LossG_Adv: 0.7010 LossG_L1: 2.3834 LossG_Style 2.2058 LossG_Content 2.3269\n",
            "===> Epoch[37](2/7): Loss_D: 0.6796 Loss_G: 8.0100 LossD_Fake: 0.6775 LossD_Real: 0.6816  LossG_Adv: 0.7093 LossG_L1: 2.3734 LossG_Style 2.4285 LossG_Content 2.4987\n",
            "===> Epoch[37](3/7): Loss_D: 0.6844 Loss_G: 7.3654 LossD_Fake: 0.6876 LossD_Real: 0.6812  LossG_Adv: 0.6990 LossG_L1: 2.2515 LossG_Style 2.0560 LossG_Content 2.3589\n",
            "===> Epoch[37](4/7): Loss_D: 0.6818 Loss_G: 7.3328 LossD_Fake: 0.6830 LossD_Real: 0.6805  LossG_Adv: 0.7037 LossG_L1: 2.2251 LossG_Style 2.1084 LossG_Content 2.2955\n",
            "===> Epoch[37](5/7): Loss_D: 0.6821 Loss_G: 7.1799 LossD_Fake: 0.6857 LossD_Real: 0.6786  LossG_Adv: 0.7009 LossG_L1: 2.2770 LossG_Style 1.9345 LossG_Content 2.2675\n",
            "===> Epoch[37](6/7): Loss_D: 0.6852 Loss_G: 8.0593 LossD_Fake: 0.6868 LossD_Real: 0.6835  LossG_Adv: 0.6999 LossG_L1: 2.3286 LossG_Style 2.5955 LossG_Content 2.4353\n",
            "\n",
            "saving sample dataset_37_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[37](7/7): Loss_D: 0.6858 Loss_G: 7.2919 LossD_Fake: 0.6868 LossD_Real: 0.6849  LossG_Adv: 0.6998 LossG_L1: 2.1470 LossG_Style 2.0884 LossG_Content 2.3568\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[38](1/7): Loss_D: 0.6861 Loss_G: 7.6020 LossD_Fake: 0.6856 LossD_Real: 0.6865  LossG_Adv: 0.7005 LossG_L1: 2.4320 LossG_Style 2.2231 LossG_Content 2.2464\n",
            "===> Epoch[38](2/7): Loss_D: 0.6815 Loss_G: 7.7168 LossD_Fake: 0.6843 LossD_Real: 0.6788  LossG_Adv: 0.7024 LossG_L1: 2.2515 LossG_Style 2.3148 LossG_Content 2.4481\n",
            "===> Epoch[38](3/7): Loss_D: 0.6842 Loss_G: 7.2757 LossD_Fake: 0.6887 LossD_Real: 0.6797  LossG_Adv: 0.6980 LossG_L1: 2.1456 LossG_Style 2.0932 LossG_Content 2.3389\n",
            "===> Epoch[38](4/7): Loss_D: 0.6823 Loss_G: 7.5172 LossD_Fake: 0.6842 LossD_Real: 0.6804  LossG_Adv: 0.7026 LossG_L1: 2.2600 LossG_Style 2.1423 LossG_Content 2.4123\n",
            "===> Epoch[38](5/7): Loss_D: 0.6854 Loss_G: 7.5571 LossD_Fake: 0.6931 LossD_Real: 0.6776  LossG_Adv: 0.6935 LossG_L1: 2.2073 LossG_Style 2.2863 LossG_Content 2.3699\n",
            "===> Epoch[38](6/7): Loss_D: 0.6839 Loss_G: 7.9690 LossD_Fake: 0.6893 LossD_Real: 0.6785  LossG_Adv: 0.6975 LossG_L1: 2.4362 LossG_Style 2.3097 LossG_Content 2.5257\n",
            "\n",
            "saving sample dataset_38_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[38](7/7): Loss_D: 0.6872 Loss_G: 7.5212 LossD_Fake: 0.6779 LossD_Real: 0.6965  LossG_Adv: 0.7092 LossG_L1: 2.4125 LossG_Style 2.1838 LossG_Content 2.2158\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[39](1/7): Loss_D: 0.6800 Loss_G: 7.6689 LossD_Fake: 0.6741 LossD_Real: 0.6859  LossG_Adv: 0.7120 LossG_L1: 2.3735 LossG_Style 2.2150 LossG_Content 2.3685\n",
            "===> Epoch[39](2/7): Loss_D: 0.6833 Loss_G: 8.1907 LossD_Fake: 0.6898 LossD_Real: 0.6769  LossG_Adv: 0.6969 LossG_L1: 2.4952 LossG_Style 2.4805 LossG_Content 2.5180\n",
            "===> Epoch[39](3/7): Loss_D: 0.6769 Loss_G: 7.6849 LossD_Fake: 0.6814 LossD_Real: 0.6724  LossG_Adv: 0.7054 LossG_L1: 2.3972 LossG_Style 2.1820 LossG_Content 2.4003\n",
            "===> Epoch[39](4/7): Loss_D: 0.6831 Loss_G: 8.0652 LossD_Fake: 0.6916 LossD_Real: 0.6745  LossG_Adv: 0.6951 LossG_L1: 2.5261 LossG_Style 2.4139 LossG_Content 2.4301\n",
            "===> Epoch[39](5/7): Loss_D: 0.6811 Loss_G: 7.6956 LossD_Fake: 0.6871 LossD_Real: 0.6750  LossG_Adv: 0.6997 LossG_L1: 2.2513 LossG_Style 2.3274 LossG_Content 2.4172\n",
            "===> Epoch[39](6/7): Loss_D: 0.6852 Loss_G: 7.5866 LossD_Fake: 0.6900 LossD_Real: 0.6804  LossG_Adv: 0.6968 LossG_L1: 2.4774 LossG_Style 2.0488 LossG_Content 2.3635\n",
            "\n",
            "saving sample dataset_39_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[39](7/7): Loss_D: 0.6805 Loss_G: 7.2675 LossD_Fake: 0.6845 LossD_Real: 0.6765  LossG_Adv: 0.7023 LossG_L1: 2.3000 LossG_Style 1.9913 LossG_Content 2.2738\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[40](1/7): Loss_D: 0.6860 Loss_G: 7.8148 LossD_Fake: 0.6895 LossD_Real: 0.6824  LossG_Adv: 0.7029 LossG_L1: 2.2694 LossG_Style 2.3122 LossG_Content 2.5303\n",
            "===> Epoch[40](2/7): Loss_D: 0.6786 Loss_G: 7.2000 LossD_Fake: 0.6779 LossD_Real: 0.6793  LossG_Adv: 0.7090 LossG_L1: 2.3171 LossG_Style 1.9648 LossG_Content 2.2091\n",
            "===> Epoch[40](3/7): Loss_D: 0.6879 Loss_G: 7.3445 LossD_Fake: 0.6881 LossD_Real: 0.6877  LossG_Adv: 0.6987 LossG_L1: 2.2971 LossG_Style 2.0310 LossG_Content 2.3178\n",
            "===> Epoch[40](4/7): Loss_D: 0.6789 Loss_G: 7.6389 LossD_Fake: 0.6803 LossD_Real: 0.6774  LossG_Adv: 0.7064 LossG_L1: 2.1289 LossG_Style 2.4886 LossG_Content 2.3150\n",
            "===> Epoch[40](5/7): Loss_D: 0.6863 Loss_G: 7.8799 LossD_Fake: 0.6915 LossD_Real: 0.6811  LossG_Adv: 0.6953 LossG_L1: 2.5843 LossG_Style 2.1412 LossG_Content 2.4590\n",
            "===> Epoch[40](6/7): Loss_D: 0.6790 Loss_G: 7.7241 LossD_Fake: 0.6809 LossD_Real: 0.6771  LossG_Adv: 0.7060 LossG_L1: 2.4677 LossG_Style 2.2135 LossG_Content 2.3369\n",
            "\n",
            "saving sample dataset_40_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[40](7/7): Loss_D: 0.6847 Loss_G: 7.3109 LossD_Fake: 0.6874 LossD_Real: 0.6821  LossG_Adv: 0.6994 LossG_L1: 2.2320 LossG_Style 2.0236 LossG_Content 2.3559\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[41](1/7): Loss_D: 0.6849 Loss_G: 7.1997 LossD_Fake: 0.6857 LossD_Real: 0.6842  LossG_Adv: 0.7052 LossG_L1: 2.2494 LossG_Style 2.0113 LossG_Content 2.2338\n",
            "===> Epoch[41](2/7): Loss_D: 0.6825 Loss_G: 8.2924 LossD_Fake: 0.6818 LossD_Real: 0.6832  LossG_Adv: 0.7051 LossG_L1: 2.5610 LossG_Style 2.5605 LossG_Content 2.4658\n",
            "===> Epoch[41](3/7): Loss_D: 0.6809 Loss_G: 7.3980 LossD_Fake: 0.6768 LossD_Real: 0.6851  LossG_Adv: 0.7101 LossG_L1: 2.1599 LossG_Style 2.1237 LossG_Content 2.4043\n",
            "===> Epoch[41](4/7): Loss_D: 0.6817 Loss_G: 7.0065 LossD_Fake: 0.6818 LossD_Real: 0.6817  LossG_Adv: 0.7050 LossG_L1: 2.0353 LossG_Style 2.0556 LossG_Content 2.2107\n",
            "===> Epoch[41](5/7): Loss_D: 0.6820 Loss_G: 7.5924 LossD_Fake: 0.6823 LossD_Real: 0.6816  LossG_Adv: 0.7045 LossG_L1: 2.4081 LossG_Style 2.0207 LossG_Content 2.4592\n",
            "===> Epoch[41](6/7): Loss_D: 0.6861 Loss_G: 7.2398 LossD_Fake: 0.6819 LossD_Real: 0.6903  LossG_Adv: 0.7050 LossG_L1: 2.2225 LossG_Style 2.0408 LossG_Content 2.2715\n",
            "\n",
            "saving sample dataset_41_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[41](7/7): Loss_D: 0.6843 Loss_G: 7.4500 LossD_Fake: 0.6804 LossD_Real: 0.6882  LossG_Adv: 0.7063 LossG_L1: 2.2448 LossG_Style 2.0136 LossG_Content 2.4853\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[42](1/7): Loss_D: 0.6777 Loss_G: 8.4058 LossD_Fake: 0.6738 LossD_Real: 0.6815  LossG_Adv: 0.7018 LossG_L1: 2.4937 LossG_Style 2.7092 LossG_Content 2.5011\n",
            "===> Epoch[42](2/7): Loss_D: 0.6833 Loss_G: 7.6554 LossD_Fake: 0.6965 LossD_Real: 0.6702  LossG_Adv: 0.6906 LossG_L1: 2.3879 LossG_Style 2.1739 LossG_Content 2.4030\n",
            "===> Epoch[42](3/7): Loss_D: 0.6829 Loss_G: 7.4860 LossD_Fake: 0.6920 LossD_Real: 0.6738  LossG_Adv: 0.6948 LossG_L1: 2.3305 LossG_Style 2.1415 LossG_Content 2.3191\n",
            "===> Epoch[42](4/7): Loss_D: 0.6789 Loss_G: 7.1469 LossD_Fake: 0.6870 LossD_Real: 0.6708  LossG_Adv: 0.7001 LossG_L1: 2.2089 LossG_Style 1.9513 LossG_Content 2.2866\n",
            "===> Epoch[42](5/7): Loss_D: 0.6862 Loss_G: 7.0242 LossD_Fake: 0.7001 LossD_Real: 0.6722  LossG_Adv: 0.6867 LossG_L1: 2.2175 LossG_Style 1.8374 LossG_Content 2.2826\n",
            "===> Epoch[42](6/7): Loss_D: 0.6808 Loss_G: 7.6274 LossD_Fake: 0.6921 LossD_Real: 0.6694  LossG_Adv: 0.6947 LossG_L1: 2.2087 LossG_Style 2.3697 LossG_Content 2.3543\n",
            "\n",
            "saving sample dataset_42_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[42](7/7): Loss_D: 0.6870 Loss_G: 6.3458 LossD_Fake: 0.7001 LossD_Real: 0.6739  LossG_Adv: 0.6868 LossG_L1: 1.7804 LossG_Style 1.6786 LossG_Content 2.2000\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[43](1/7): Loss_D: 0.6835 Loss_G: 7.5244 LossD_Fake: 0.6979 LossD_Real: 0.6692  LossG_Adv: 0.6910 LossG_L1: 2.1797 LossG_Style 2.3708 LossG_Content 2.2829\n",
            "===> Epoch[43](2/7): Loss_D: 0.6790 Loss_G: 7.2437 LossD_Fake: 0.6857 LossD_Real: 0.6722  LossG_Adv: 0.7011 LossG_L1: 2.2222 LossG_Style 2.0137 LossG_Content 2.3067\n",
            "===> Epoch[43](3/7): Loss_D: 0.6839 Loss_G: 7.1670 LossD_Fake: 0.6960 LossD_Real: 0.6719  LossG_Adv: 0.6910 LossG_L1: 2.1384 LossG_Style 2.0601 LossG_Content 2.2775\n",
            "===> Epoch[43](4/7): Loss_D: 0.6813 Loss_G: 7.8627 LossD_Fake: 0.6938 LossD_Real: 0.6687  LossG_Adv: 0.6932 LossG_L1: 2.4318 LossG_Style 2.2932 LossG_Content 2.4444\n",
            "===> Epoch[43](5/7): Loss_D: 0.6841 Loss_G: 7.5480 LossD_Fake: 0.6944 LossD_Real: 0.6738  LossG_Adv: 0.6924 LossG_L1: 2.1759 LossG_Style 2.2849 LossG_Content 2.3949\n",
            "===> Epoch[43](6/7): Loss_D: 0.6797 Loss_G: 7.2233 LossD_Fake: 0.6862 LossD_Real: 0.6732  LossG_Adv: 0.7008 LossG_L1: 2.2893 LossG_Style 1.9496 LossG_Content 2.2836\n",
            "\n",
            "saving sample dataset_43_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[43](7/7): Loss_D: 0.6791 Loss_G: 7.1581 LossD_Fake: 0.6923 LossD_Real: 0.6659  LossG_Adv: 0.6944 LossG_L1: 2.2386 LossG_Style 1.8905 LossG_Content 2.3346\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[44](1/7): Loss_D: 0.6817 Loss_G: 7.1540 LossD_Fake: 0.6945 LossD_Real: 0.6689  LossG_Adv: 0.6987 LossG_L1: 2.0215 LossG_Style 2.1388 LossG_Content 2.2950\n",
            "===> Epoch[44](2/7): Loss_D: 0.6837 Loss_G: 6.8345 LossD_Fake: 0.6919 LossD_Real: 0.6755  LossG_Adv: 0.6950 LossG_L1: 2.0958 LossG_Style 1.7814 LossG_Content 2.2622\n",
            "===> Epoch[44](3/7): Loss_D: 0.6838 Loss_G: 6.7873 LossD_Fake: 0.6914 LossD_Real: 0.6761  LossG_Adv: 0.6956 LossG_L1: 1.9805 LossG_Style 1.9711 LossG_Content 2.1402\n",
            "===> Epoch[44](4/7): Loss_D: 0.6832 Loss_G: 7.7729 LossD_Fake: 0.6835 LossD_Real: 0.6829  LossG_Adv: 0.7035 LossG_L1: 2.2256 LossG_Style 2.3414 LossG_Content 2.5024\n",
            "===> Epoch[44](5/7): Loss_D: 0.6758 Loss_G: 7.5289 LossD_Fake: 0.6777 LossD_Real: 0.6739  LossG_Adv: 0.7095 LossG_L1: 2.2993 LossG_Style 2.1912 LossG_Content 2.3289\n",
            "===> Epoch[44](6/7): Loss_D: 0.6858 Loss_G: 7.1366 LossD_Fake: 0.6965 LossD_Real: 0.6752  LossG_Adv: 0.6903 LossG_L1: 2.2224 LossG_Style 1.8850 LossG_Content 2.3388\n",
            "\n",
            "saving sample dataset_44_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[44](7/7): Loss_D: 0.6847 Loss_G: 6.5286 LossD_Fake: 0.6900 LossD_Real: 0.6793  LossG_Adv: 0.6969 LossG_L1: 2.1389 LossG_Style 1.6016 LossG_Content 2.0912\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[45](1/7): Loss_D: 0.6845 Loss_G: 7.5563 LossD_Fake: 0.6916 LossD_Real: 0.6774  LossG_Adv: 0.7067 LossG_L1: 2.4292 LossG_Style 2.2162 LossG_Content 2.2042\n",
            "===> Epoch[45](2/7): Loss_D: 0.6807 Loss_G: 7.2800 LossD_Fake: 0.6728 LossD_Real: 0.6887  LossG_Adv: 0.7143 LossG_L1: 2.1394 LossG_Style 2.0692 LossG_Content 2.3571\n",
            "===> Epoch[45](3/7): Loss_D: 0.6835 Loss_G: 7.2516 LossD_Fake: 0.6780 LossD_Real: 0.6891  LossG_Adv: 0.7089 LossG_L1: 2.1664 LossG_Style 2.0831 LossG_Content 2.2933\n",
            "===> Epoch[45](4/7): Loss_D: 0.6813 Loss_G: 7.2240 LossD_Fake: 0.6741 LossD_Real: 0.6885  LossG_Adv: 0.7129 LossG_L1: 2.2244 LossG_Style 1.8843 LossG_Content 2.4024\n",
            "===> Epoch[45](5/7): Loss_D: 0.6787 Loss_G: 7.1401 LossD_Fake: 0.6742 LossD_Real: 0.6833  LossG_Adv: 0.7129 LossG_L1: 2.1074 LossG_Style 2.0542 LossG_Content 2.2655\n",
            "===> Epoch[45](6/7): Loss_D: 0.6846 Loss_G: 7.2211 LossD_Fake: 0.6842 LossD_Real: 0.6850  LossG_Adv: 0.7027 LossG_L1: 2.1746 LossG_Style 2.0327 LossG_Content 2.3111\n",
            "\n",
            "saving sample dataset_45_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[45](7/7): Loss_D: 0.6768 Loss_G: 8.0229 LossD_Fake: 0.6762 LossD_Real: 0.6774  LossG_Adv: 0.7108 LossG_L1: 2.1895 LossG_Style 2.7120 LossG_Content 2.4106\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[46](1/7): Loss_D: 0.6846 Loss_G: 7.0845 LossD_Fake: 0.6808 LossD_Real: 0.6884  LossG_Adv: 0.7023 LossG_L1: 2.2801 LossG_Style 1.8266 LossG_Content 2.2755\n",
            "===> Epoch[46](2/7): Loss_D: 0.6800 Loss_G: 7.8074 LossD_Fake: 0.6830 LossD_Real: 0.6771  LossG_Adv: 0.7039 LossG_L1: 2.3270 LossG_Style 2.3715 LossG_Content 2.4050\n",
            "===> Epoch[46](3/7): Loss_D: 0.6779 Loss_G: 7.8343 LossD_Fake: 0.6810 LossD_Real: 0.6748  LossG_Adv: 0.7060 LossG_L1: 2.1985 LossG_Style 2.4463 LossG_Content 2.4835\n",
            "===> Epoch[46](4/7): Loss_D: 0.6836 Loss_G: 6.9735 LossD_Fake: 0.6880 LossD_Real: 0.6792  LossG_Adv: 0.6989 LossG_L1: 2.1949 LossG_Style 1.8676 LossG_Content 2.2121\n",
            "===> Epoch[46](5/7): Loss_D: 0.6856 Loss_G: 7.1750 LossD_Fake: 0.6882 LossD_Real: 0.6829  LossG_Adv: 0.6989 LossG_L1: 2.1206 LossG_Style 2.0596 LossG_Content 2.2960\n",
            "===> Epoch[46](6/7): Loss_D: 0.6859 Loss_G: 6.8535 LossD_Fake: 0.6818 LossD_Real: 0.6901  LossG_Adv: 0.7053 LossG_L1: 2.0473 LossG_Style 1.8234 LossG_Content 2.2775\n",
            "\n",
            "saving sample dataset_46_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[46](7/7): Loss_D: 0.6810 Loss_G: 6.3026 LossD_Fake: 0.6796 LossD_Real: 0.6825  LossG_Adv: 0.7076 LossG_L1: 1.9731 LossG_Style 1.5887 LossG_Content 2.0332\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[47](1/7): Loss_D: 0.6768 Loss_G: 7.4480 LossD_Fake: 0.6783 LossD_Real: 0.6753  LossG_Adv: 0.7043 LossG_L1: 2.3395 LossG_Style 2.0516 LossG_Content 2.3526\n",
            "===> Epoch[47](2/7): Loss_D: 0.6824 Loss_G: 6.8798 LossD_Fake: 0.6864 LossD_Real: 0.6784  LossG_Adv: 0.7009 LossG_L1: 2.1172 LossG_Style 1.8647 LossG_Content 2.1971\n",
            "===> Epoch[47](3/7): Loss_D: 0.6819 Loss_G: 7.0173 LossD_Fake: 0.6901 LossD_Real: 0.6736  LossG_Adv: 0.6970 LossG_L1: 2.1716 LossG_Style 1.8954 LossG_Content 2.2533\n",
            "===> Epoch[47](4/7): Loss_D: 0.6838 Loss_G: 7.5161 LossD_Fake: 0.6915 LossD_Real: 0.6761  LossG_Adv: 0.6955 LossG_L1: 2.2969 LossG_Style 2.1075 LossG_Content 2.4162\n",
            "===> Epoch[47](5/7): Loss_D: 0.6807 Loss_G: 6.7340 LossD_Fake: 0.6897 LossD_Real: 0.6717  LossG_Adv: 0.6972 LossG_L1: 1.9664 LossG_Style 1.8662 LossG_Content 2.2042\n",
            "===> Epoch[47](6/7): Loss_D: 0.6873 Loss_G: 6.6920 LossD_Fake: 0.6949 LossD_Real: 0.6796  LossG_Adv: 0.6924 LossG_L1: 1.9653 LossG_Style 1.8536 LossG_Content 2.1807\n",
            "\n",
            "saving sample dataset_47_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[47](7/7): Loss_D: 0.6840 Loss_G: 7.2483 LossD_Fake: 0.6851 LossD_Real: 0.6830  LossG_Adv: 0.7019 LossG_L1: 2.0935 LossG_Style 2.0231 LossG_Content 2.4299\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[48](1/7): Loss_D: 0.6814 Loss_G: 6.8185 LossD_Fake: 0.6856 LossD_Real: 0.6771  LossG_Adv: 0.6992 LossG_L1: 1.9624 LossG_Style 1.8922 LossG_Content 2.2647\n",
            "===> Epoch[48](2/7): Loss_D: 0.6844 Loss_G: 6.7848 LossD_Fake: 0.6967 LossD_Real: 0.6722  LossG_Adv: 0.6903 LossG_L1: 1.9412 LossG_Style 1.8869 LossG_Content 2.2664\n",
            "===> Epoch[48](3/7): Loss_D: 0.6798 Loss_G: 7.3549 LossD_Fake: 0.6892 LossD_Real: 0.6704  LossG_Adv: 0.6980 LossG_L1: 2.2201 LossG_Style 2.0928 LossG_Content 2.3440\n",
            "===> Epoch[48](4/7): Loss_D: 0.6856 Loss_G: 6.6832 LossD_Fake: 0.6911 LossD_Real: 0.6801  LossG_Adv: 0.6959 LossG_L1: 2.0161 LossG_Style 1.7776 LossG_Content 2.1936\n",
            "===> Epoch[48](5/7): Loss_D: 0.6774 Loss_G: 7.8823 LossD_Fake: 0.6854 LossD_Real: 0.6695  LossG_Adv: 0.7022 LossG_L1: 2.4283 LossG_Style 2.3864 LossG_Content 2.3655\n",
            "===> Epoch[48](6/7): Loss_D: 0.6743 Loss_G: 7.2201 LossD_Fake: 0.6855 LossD_Real: 0.6630  LossG_Adv: 0.7015 LossG_L1: 2.1421 LossG_Style 2.0444 LossG_Content 2.3321\n",
            "\n",
            "saving sample dataset_48_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[48](7/7): Loss_D: 0.6791 Loss_G: 7.0745 LossD_Fake: 0.6908 LossD_Real: 0.6674  LossG_Adv: 0.6967 LossG_L1: 2.4691 LossG_Style 1.7868 LossG_Content 2.1218\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[49](1/7): Loss_D: 0.6766 Loss_G: 7.3061 LossD_Fake: 0.6875 LossD_Real: 0.6658  LossG_Adv: 0.7031 LossG_L1: 2.3172 LossG_Style 2.0030 LossG_Content 2.2828\n",
            "===> Epoch[49](2/7): Loss_D: 0.6809 Loss_G: 7.1811 LossD_Fake: 0.6878 LossD_Real: 0.6740  LossG_Adv: 0.6998 LossG_L1: 2.2586 LossG_Style 1.9339 LossG_Content 2.2889\n",
            "===> Epoch[49](3/7): Loss_D: 0.6796 Loss_G: 7.5980 LossD_Fake: 0.6905 LossD_Real: 0.6688  LossG_Adv: 0.6968 LossG_L1: 1.9989 LossG_Style 2.5141 LossG_Content 2.3881\n",
            "===> Epoch[49](4/7): Loss_D: 0.6834 Loss_G: 7.1904 LossD_Fake: 0.6939 LossD_Real: 0.6729  LossG_Adv: 0.6932 LossG_L1: 2.0442 LossG_Style 2.0452 LossG_Content 2.4077\n",
            "===> Epoch[49](5/7): Loss_D: 0.6823 Loss_G: 7.4103 LossD_Fake: 0.6894 LossD_Real: 0.6751  LossG_Adv: 0.6977 LossG_L1: 2.2564 LossG_Style 2.1707 LossG_Content 2.2856\n",
            "===> Epoch[49](6/7): Loss_D: 0.6830 Loss_G: 6.8276 LossD_Fake: 0.6907 LossD_Real: 0.6752  LossG_Adv: 0.6966 LossG_L1: 2.1232 LossG_Style 1.7615 LossG_Content 2.2464\n",
            "\n",
            "saving sample dataset_49_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[49](7/7): Loss_D: 0.6885 Loss_G: 5.7916 LossD_Fake: 0.6946 LossD_Real: 0.6824  LossG_Adv: 0.6928 LossG_L1: 1.6273 LossG_Style 1.5492 LossG_Content 1.9223\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[50](1/7): Loss_D: 0.6837 Loss_G: 6.4205 LossD_Fake: 0.6885 LossD_Real: 0.6789  LossG_Adv: 0.7000 LossG_L1: 2.0479 LossG_Style 1.6079 LossG_Content 2.0646\n",
            "===> Epoch[50](2/7): Loss_D: 0.6787 Loss_G: 7.4304 LossD_Fake: 0.6871 LossD_Real: 0.6703  LossG_Adv: 0.7000 LossG_L1: 2.0494 LossG_Style 2.2979 LossG_Content 2.3831\n",
            "===> Epoch[50](3/7): Loss_D: 0.6837 Loss_G: 6.9674 LossD_Fake: 0.6934 LossD_Real: 0.6740  LossG_Adv: 0.6939 LossG_L1: 2.1469 LossG_Style 1.8304 LossG_Content 2.2962\n",
            "===> Epoch[50](4/7): Loss_D: 0.6814 Loss_G: 6.4282 LossD_Fake: 0.6890 LossD_Real: 0.6737  LossG_Adv: 0.6983 LossG_L1: 1.9339 LossG_Style 1.7049 LossG_Content 2.0912\n",
            "===> Epoch[50](5/7): Loss_D: 0.6798 Loss_G: 7.3988 LossD_Fake: 0.6870 LossD_Real: 0.6726  LossG_Adv: 0.7005 LossG_L1: 2.1203 LossG_Style 2.2119 LossG_Content 2.3661\n",
            "===> Epoch[50](6/7): Loss_D: 0.6803 Loss_G: 7.0818 LossD_Fake: 0.6943 LossD_Real: 0.6663  LossG_Adv: 0.6927 LossG_L1: 2.1771 LossG_Style 1.9066 LossG_Content 2.3054\n",
            "\n",
            "saving sample dataset_50_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[50](7/7): Loss_D: 0.6808 Loss_G: 6.6729 LossD_Fake: 0.6937 LossD_Real: 0.6678  LossG_Adv: 0.6935 LossG_L1: 2.1779 LossG_Style 1.6547 LossG_Content 2.1468\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[51](1/7): Loss_D: 0.6842 Loss_G: 7.0311 LossD_Fake: 0.6959 LossD_Real: 0.6725  LossG_Adv: 0.7000 LossG_L1: 2.0309 LossG_Style 1.9914 LossG_Content 2.3089\n",
            "===> Epoch[51](2/7): Loss_D: 0.6759 Loss_G: 7.0110 LossD_Fake: 0.6798 LossD_Real: 0.6719  LossG_Adv: 0.7076 LossG_L1: 2.1434 LossG_Style 1.9268 LossG_Content 2.2333\n",
            "===> Epoch[51](3/7): Loss_D: 0.6848 Loss_G: 6.9749 LossD_Fake: 0.6910 LossD_Real: 0.6785  LossG_Adv: 0.6961 LossG_L1: 2.1405 LossG_Style 1.8401 LossG_Content 2.2982\n",
            "===> Epoch[51](4/7): Loss_D: 0.6851 Loss_G: 6.4898 LossD_Fake: 0.6839 LossD_Real: 0.6863  LossG_Adv: 0.7036 LossG_L1: 1.8051 LossG_Style 1.8433 LossG_Content 2.1378\n",
            "===> Epoch[51](5/7): Loss_D: 0.6788 Loss_G: 6.9177 LossD_Fake: 0.6823 LossD_Real: 0.6753  LossG_Adv: 0.7050 LossG_L1: 2.0653 LossG_Style 1.8938 LossG_Content 2.2535\n",
            "===> Epoch[51](6/7): Loss_D: 0.6820 Loss_G: 7.1817 LossD_Fake: 0.6816 LossD_Real: 0.6825  LossG_Adv: 0.7058 LossG_L1: 2.1216 LossG_Style 2.0398 LossG_Content 2.3145\n",
            "\n",
            "saving sample dataset_51_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[51](7/7): Loss_D: 0.6786 Loss_G: 6.6205 LossD_Fake: 0.6710 LossD_Real: 0.6861  LossG_Adv: 0.7166 LossG_L1: 2.1071 LossG_Style 1.6825 LossG_Content 2.1142\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[52](1/7): Loss_D: 0.6903 Loss_G: 7.4732 LossD_Fake: 0.6951 LossD_Real: 0.6854  LossG_Adv: 0.7005 LossG_L1: 2.3415 LossG_Style 2.0948 LossG_Content 2.3363\n",
            "===> Epoch[52](2/7): Loss_D: 0.6801 Loss_G: 6.6762 LossD_Fake: 0.6682 LossD_Real: 0.6920  LossG_Adv: 0.7194 LossG_L1: 2.0075 LossG_Style 1.7579 LossG_Content 2.1914\n",
            "===> Epoch[52](3/7): Loss_D: 0.6758 Loss_G: 6.8928 LossD_Fake: 0.6717 LossD_Real: 0.6800  LossG_Adv: 0.7158 LossG_L1: 2.1519 LossG_Style 1.8678 LossG_Content 2.1573\n",
            "===> Epoch[52](4/7): Loss_D: 0.6823 Loss_G: 7.4837 LossD_Fake: 0.6783 LossD_Real: 0.6862  LossG_Adv: 0.7089 LossG_L1: 2.2816 LossG_Style 2.0920 LossG_Content 2.4012\n",
            "===> Epoch[52](5/7): Loss_D: 0.6779 Loss_G: 6.7981 LossD_Fake: 0.6712 LossD_Real: 0.6845  LossG_Adv: 0.7162 LossG_L1: 1.9209 LossG_Style 1.9959 LossG_Content 2.1651\n",
            "===> Epoch[52](6/7): Loss_D: 0.6802 Loss_G: 7.0315 LossD_Fake: 0.6769 LossD_Real: 0.6835  LossG_Adv: 0.7105 LossG_L1: 2.0782 LossG_Style 1.9449 LossG_Content 2.2978\n",
            "\n",
            "saving sample dataset_52_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[52](7/7): Loss_D: 0.6792 Loss_G: 7.4962 LossD_Fake: 0.6738 LossD_Real: 0.6846  LossG_Adv: 0.7136 LossG_L1: 2.1467 LossG_Style 2.2054 LossG_Content 2.4304\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[53](1/7): Loss_D: 0.6834 Loss_G: 7.3643 LossD_Fake: 0.6848 LossD_Real: 0.6820  LossG_Adv: 0.7117 LossG_L1: 2.1445 LossG_Style 2.0741 LossG_Content 2.4341\n",
            "===> Epoch[53](2/7): Loss_D: 0.6830 Loss_G: 7.0553 LossD_Fake: 0.6763 LossD_Real: 0.6896  LossG_Adv: 0.7110 LossG_L1: 2.0495 LossG_Style 2.0727 LossG_Content 2.2221\n",
            "===> Epoch[53](3/7): Loss_D: 0.6852 Loss_G: 6.6949 LossD_Fake: 0.6709 LossD_Real: 0.6995  LossG_Adv: 0.7166 LossG_L1: 1.8494 LossG_Style 1.9461 LossG_Content 2.1827\n",
            "===> Epoch[53](4/7): Loss_D: 0.6785 Loss_G: 6.8861 LossD_Fake: 0.6678 LossD_Real: 0.6892  LossG_Adv: 0.7198 LossG_L1: 1.9917 LossG_Style 1.9201 LossG_Content 2.2545\n",
            "===> Epoch[53](5/7): Loss_D: 0.6845 Loss_G: 6.8089 LossD_Fake: 0.6710 LossD_Real: 0.6980  LossG_Adv: 0.7165 LossG_L1: 2.2198 LossG_Style 1.6706 LossG_Content 2.2020\n",
            "===> Epoch[53](6/7): Loss_D: 0.6818 Loss_G: 6.8021 LossD_Fake: 0.6647 LossD_Real: 0.6989  LossG_Adv: 0.7232 LossG_L1: 2.0632 LossG_Style 1.7419 LossG_Content 2.2738\n",
            "\n",
            "saving sample dataset_53_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[53](7/7): Loss_D: 0.6793 Loss_G: 7.2658 LossD_Fake: 0.6699 LossD_Real: 0.6887  LossG_Adv: 0.7177 LossG_L1: 2.2415 LossG_Style 2.1306 LossG_Content 2.1760\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[54](1/7): Loss_D: 0.6794 Loss_G: 7.1583 LossD_Fake: 0.6649 LossD_Real: 0.6940  LossG_Adv: 0.7223 LossG_L1: 2.2073 LossG_Style 1.9019 LossG_Content 2.3268\n",
            "===> Epoch[54](2/7): Loss_D: 0.6792 Loss_G: 6.9885 LossD_Fake: 0.6635 LossD_Real: 0.6949  LossG_Adv: 0.7244 LossG_L1: 2.1675 LossG_Style 1.9290 LossG_Content 2.1676\n",
            "===> Epoch[54](3/7): Loss_D: 0.6767 Loss_G: 7.1970 LossD_Fake: 0.6632 LossD_Real: 0.6903  LossG_Adv: 0.7247 LossG_L1: 2.1322 LossG_Style 2.0037 LossG_Content 2.3364\n",
            "===> Epoch[54](4/7): Loss_D: 0.6815 Loss_G: 7.0409 LossD_Fake: 0.6723 LossD_Real: 0.6908  LossG_Adv: 0.7152 LossG_L1: 2.0214 LossG_Style 2.0067 LossG_Content 2.2976\n",
            "===> Epoch[54](5/7): Loss_D: 0.6788 Loss_G: 7.0178 LossD_Fake: 0.6666 LossD_Real: 0.6909  LossG_Adv: 0.7208 LossG_L1: 1.9602 LossG_Style 1.9554 LossG_Content 2.3814\n",
            "===> Epoch[54](6/7): Loss_D: 0.6839 Loss_G: 6.6720 LossD_Fake: 0.6760 LossD_Real: 0.6919  LossG_Adv: 0.7112 LossG_L1: 2.0074 LossG_Style 1.7988 LossG_Content 2.1546\n",
            "\n",
            "saving sample dataset_54_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[54](7/7): Loss_D: 0.6764 Loss_G: 7.1314 LossD_Fake: 0.6681 LossD_Real: 0.6846  LossG_Adv: 0.7193 LossG_L1: 1.8635 LossG_Style 2.3091 LossG_Content 2.2395\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[55](1/7): Loss_D: 0.6859 Loss_G: 7.4444 LossD_Fake: 0.6810 LossD_Real: 0.6908  LossG_Adv: 0.7014 LossG_L1: 2.3722 LossG_Style 2.0651 LossG_Content 2.3058\n",
            "===> Epoch[55](2/7): Loss_D: 0.6845 Loss_G: 6.7869 LossD_Fake: 0.6795 LossD_Real: 0.6895  LossG_Adv: 0.7077 LossG_L1: 2.0659 LossG_Style 1.7657 LossG_Content 2.2477\n",
            "===> Epoch[55](3/7): Loss_D: 0.6789 Loss_G: 6.7496 LossD_Fake: 0.6722 LossD_Real: 0.6856  LossG_Adv: 0.7152 LossG_L1: 2.0060 LossG_Style 1.8051 LossG_Content 2.2233\n",
            "===> Epoch[55](4/7): Loss_D: 0.6817 Loss_G: 6.9013 LossD_Fake: 0.6759 LossD_Real: 0.6874  LossG_Adv: 0.7113 LossG_L1: 2.0101 LossG_Style 1.9430 LossG_Content 2.2369\n",
            "===> Epoch[55](5/7): Loss_D: 0.6772 Loss_G: 6.9085 LossD_Fake: 0.6721 LossD_Real: 0.6824  LossG_Adv: 0.7155 LossG_L1: 1.9482 LossG_Style 1.9764 LossG_Content 2.2684\n",
            "===> Epoch[55](6/7): Loss_D: 0.6796 Loss_G: 6.9291 LossD_Fake: 0.6745 LossD_Real: 0.6847  LossG_Adv: 0.7127 LossG_L1: 2.1708 LossG_Style 1.7885 LossG_Content 2.2570\n",
            "\n",
            "saving sample dataset_55_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[55](7/7): Loss_D: 0.6797 Loss_G: 6.1432 LossD_Fake: 0.6749 LossD_Real: 0.6845  LossG_Adv: 0.7123 LossG_L1: 1.8724 LossG_Style 1.5236 LossG_Content 2.0349\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[56](1/7): Loss_D: 0.6848 Loss_G: 6.5153 LossD_Fake: 0.6765 LossD_Real: 0.6930  LossG_Adv: 0.7183 LossG_L1: 1.9713 LossG_Style 1.6419 LossG_Content 2.1838\n",
            "===> Epoch[56](2/7): Loss_D: 0.6771 Loss_G: 7.0565 LossD_Fake: 0.6644 LossD_Real: 0.6899  LossG_Adv: 0.7233 LossG_L1: 2.0569 LossG_Style 2.0084 LossG_Content 2.2679\n",
            "===> Epoch[56](3/7): Loss_D: 0.6803 Loss_G: 6.7142 LossD_Fake: 0.6686 LossD_Real: 0.6920  LossG_Adv: 0.7188 LossG_L1: 2.0568 LossG_Style 1.7615 LossG_Content 2.1770\n",
            "===> Epoch[56](4/7): Loss_D: 0.6777 Loss_G: 6.5535 LossD_Fake: 0.6643 LossD_Real: 0.6912  LossG_Adv: 0.7234 LossG_L1: 1.9931 LossG_Style 1.6616 LossG_Content 2.1754\n",
            "===> Epoch[56](5/7): Loss_D: 0.6830 Loss_G: 6.5650 LossD_Fake: 0.6750 LossD_Real: 0.6909  LossG_Adv: 0.7121 LossG_L1: 1.8218 LossG_Style 1.9609 LossG_Content 2.0701\n",
            "===> Epoch[56](6/7): Loss_D: 0.6783 Loss_G: 6.8920 LossD_Fake: 0.6689 LossD_Real: 0.6876  LossG_Adv: 0.7184 LossG_L1: 1.9860 LossG_Style 1.8726 LossG_Content 2.3150\n",
            "\n",
            "saving sample dataset_56_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[56](7/7): Loss_D: 0.6813 Loss_G: 6.4335 LossD_Fake: 0.6737 LossD_Real: 0.6888  LossG_Adv: 0.7134 LossG_L1: 1.8299 LossG_Style 1.8204 LossG_Content 2.0698\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[57](1/7): Loss_D: 0.6788 Loss_G: 6.3684 LossD_Fake: 0.6708 LossD_Real: 0.6867  LossG_Adv: 0.7188 LossG_L1: 1.8395 LossG_Style 1.6847 LossG_Content 2.1254\n",
            "===> Epoch[57](2/7): Loss_D: 0.6826 Loss_G: 6.6245 LossD_Fake: 0.6682 LossD_Real: 0.6971  LossG_Adv: 0.7196 LossG_L1: 1.9102 LossG_Style 1.8153 LossG_Content 2.1795\n",
            "===> Epoch[57](3/7): Loss_D: 0.6790 Loss_G: 6.6581 LossD_Fake: 0.6641 LossD_Real: 0.6939  LossG_Adv: 0.7236 LossG_L1: 1.9028 LossG_Style 1.8514 LossG_Content 2.1803\n",
            "===> Epoch[57](4/7): Loss_D: 0.6745 Loss_G: 6.9942 LossD_Fake: 0.6637 LossD_Real: 0.6854  LossG_Adv: 0.7241 LossG_L1: 2.0099 LossG_Style 1.9472 LossG_Content 2.3131\n",
            "===> Epoch[57](5/7): Loss_D: 0.6820 Loss_G: 6.4848 LossD_Fake: 0.6719 LossD_Real: 0.6922  LossG_Adv: 0.7156 LossG_L1: 2.0365 LossG_Style 1.5950 LossG_Content 2.1377\n",
            "===> Epoch[57](6/7): Loss_D: 0.6827 Loss_G: 6.5834 LossD_Fake: 0.6677 LossD_Real: 0.6978  LossG_Adv: 0.7197 LossG_L1: 1.8466 LossG_Style 1.8064 LossG_Content 2.2108\n",
            "\n",
            "saving sample dataset_57_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[57](7/7): Loss_D: 0.6813 Loss_G: 5.9358 LossD_Fake: 0.6698 LossD_Real: 0.6927  LossG_Adv: 0.7175 LossG_L1: 1.7139 LossG_Style 1.5087 LossG_Content 1.9957\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[58](1/7): Loss_D: 0.6793 Loss_G: 7.0607 LossD_Fake: 0.6677 LossD_Real: 0.6909  LossG_Adv: 0.7118 LossG_L1: 2.0444 LossG_Style 1.9833 LossG_Content 2.3212\n",
            "===> Epoch[58](2/7): Loss_D: 0.6773 Loss_G: 6.6756 LossD_Fake: 0.6678 LossD_Real: 0.6868  LossG_Adv: 0.7199 LossG_L1: 1.9984 LossG_Style 1.7504 LossG_Content 2.2070\n",
            "===> Epoch[58](3/7): Loss_D: 0.6828 Loss_G: 6.4520 LossD_Fake: 0.6786 LossD_Real: 0.6870  LossG_Adv: 0.7086 LossG_L1: 1.9817 LossG_Style 1.6788 LossG_Content 2.0828\n",
            "===> Epoch[58](4/7): Loss_D: 0.6771 Loss_G: 6.6358 LossD_Fake: 0.6737 LossD_Real: 0.6804  LossG_Adv: 0.7134 LossG_L1: 1.8614 LossG_Style 1.8506 LossG_Content 2.2104\n",
            "===> Epoch[58](5/7): Loss_D: 0.6823 Loss_G: 6.3854 LossD_Fake: 0.6787 LossD_Real: 0.6858  LossG_Adv: 0.7083 LossG_L1: 1.7139 LossG_Style 1.7575 LossG_Content 2.2058\n",
            "===> Epoch[58](6/7): Loss_D: 0.6791 Loss_G: 6.6813 LossD_Fake: 0.6790 LossD_Real: 0.6792  LossG_Adv: 0.7081 LossG_L1: 1.8218 LossG_Style 2.1121 LossG_Content 2.0391\n",
            "\n",
            "saving sample dataset_58_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[58](7/7): Loss_D: 0.6681 Loss_G: 6.9142 LossD_Fake: 0.6683 LossD_Real: 0.6679  LossG_Adv: 0.7192 LossG_L1: 1.9920 LossG_Style 1.8465 LossG_Content 2.3566\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[59](1/7): Loss_D: 0.6823 Loss_G: 7.2806 LossD_Fake: 0.6800 LossD_Real: 0.6845  LossG_Adv: 0.6979 LossG_L1: 1.9573 LossG_Style 2.2948 LossG_Content 2.3306\n",
            "===> Epoch[59](2/7): Loss_D: 0.6764 Loss_G: 6.5479 LossD_Fake: 0.6860 LossD_Real: 0.6668  LossG_Adv: 0.7009 LossG_L1: 1.8932 LossG_Style 1.7113 LossG_Content 2.2425\n",
            "===> Epoch[59](3/7): Loss_D: 0.6812 Loss_G: 6.4289 LossD_Fake: 0.6932 LossD_Real: 0.6692  LossG_Adv: 0.6940 LossG_L1: 1.9294 LossG_Style 1.7616 LossG_Content 2.0438\n",
            "===> Epoch[59](4/7): Loss_D: 0.6759 Loss_G: 6.8826 LossD_Fake: 0.6774 LossD_Real: 0.6743  LossG_Adv: 0.7099 LossG_L1: 2.0633 LossG_Style 1.7904 LossG_Content 2.3189\n",
            "===> Epoch[59](5/7): Loss_D: 0.6831 Loss_G: 6.3565 LossD_Fake: 0.6902 LossD_Real: 0.6760  LossG_Adv: 0.6968 LossG_L1: 1.7814 LossG_Style 1.7546 LossG_Content 2.1237\n",
            "===> Epoch[59](6/7): Loss_D: 0.6761 Loss_G: 6.6175 LossD_Fake: 0.6857 LossD_Real: 0.6665  LossG_Adv: 0.7014 LossG_L1: 2.0372 LossG_Style 1.7444 LossG_Content 2.1346\n",
            "\n",
            "saving sample dataset_59_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[59](7/7): Loss_D: 0.6854 Loss_G: 6.2146 LossD_Fake: 0.6934 LossD_Real: 0.6774  LossG_Adv: 0.6937 LossG_L1: 1.8634 LossG_Style 1.6101 LossG_Content 2.0474\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[60](1/7): Loss_D: 0.6815 Loss_G: 7.6092 LossD_Fake: 0.6947 LossD_Real: 0.6682  LossG_Adv: 0.6856 LossG_L1: 2.5440 LossG_Style 2.1321 LossG_Content 2.2475\n",
            "===> Epoch[60](2/7): Loss_D: 0.6706 Loss_G: 6.8196 LossD_Fake: 0.6829 LossD_Real: 0.6582  LossG_Adv: 0.7040 LossG_L1: 2.0898 LossG_Style 1.7462 LossG_Content 2.2796\n",
            "===> Epoch[60](3/7): Loss_D: 0.6745 Loss_G: 6.9658 LossD_Fake: 0.6898 LossD_Real: 0.6592  LossG_Adv: 0.6976 LossG_L1: 1.9757 LossG_Style 2.0982 LossG_Content 2.1943\n",
            "===> Epoch[60](4/7): Loss_D: 0.6749 Loss_G: 6.6973 LossD_Fake: 0.6962 LossD_Real: 0.6536  LossG_Adv: 0.6912 LossG_L1: 1.9887 LossG_Style 1.8259 LossG_Content 2.1915\n",
            "===> Epoch[60](5/7): Loss_D: 0.6860 Loss_G: 6.9356 LossD_Fake: 0.7013 LossD_Real: 0.6706  LossG_Adv: 0.6861 LossG_L1: 2.0075 LossG_Style 1.9925 LossG_Content 2.2495\n",
            "===> Epoch[60](6/7): Loss_D: 0.6707 Loss_G: 6.3646 LossD_Fake: 0.6877 LossD_Real: 0.6538  LossG_Adv: 0.6996 LossG_L1: 1.8623 LossG_Style 1.6976 LossG_Content 2.1051\n",
            "\n",
            "saving sample dataset_60_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[60](7/7): Loss_D: 0.6839 Loss_G: 6.4325 LossD_Fake: 0.7088 LossD_Real: 0.6589  LossG_Adv: 0.6787 LossG_L1: 1.8895 LossG_Style 1.6341 LossG_Content 2.2302\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[61](1/7): Loss_D: 0.6811 Loss_G: 6.3454 LossD_Fake: 0.6956 LossD_Real: 0.6666  LossG_Adv: 0.7108 LossG_L1: 1.9133 LossG_Style 1.5998 LossG_Content 2.1215\n",
            "===> Epoch[61](2/7): Loss_D: 0.6741 Loss_G: 6.1365 LossD_Fake: 0.6737 LossD_Real: 0.6746  LossG_Adv: 0.7139 LossG_L1: 1.7736 LossG_Style 1.5969 LossG_Content 2.0521\n",
            "===> Epoch[61](3/7): Loss_D: 0.6792 Loss_G: 6.2686 LossD_Fake: 0.6849 LossD_Real: 0.6736  LossG_Adv: 0.7023 LossG_L1: 1.7665 LossG_Style 1.7201 LossG_Content 2.0797\n",
            "===> Epoch[61](4/7): Loss_D: 0.6814 Loss_G: 6.1738 LossD_Fake: 0.6865 LossD_Real: 0.6763  LossG_Adv: 0.7004 LossG_L1: 1.6746 LossG_Style 1.6050 LossG_Content 2.1939\n",
            "===> Epoch[61](5/7): Loss_D: 0.6777 Loss_G: 6.7080 LossD_Fake: 0.6817 LossD_Real: 0.6737  LossG_Adv: 0.7058 LossG_L1: 1.8701 LossG_Style 1.9479 LossG_Content 2.1843\n",
            "===> Epoch[61](6/7): Loss_D: 0.6792 Loss_G: 6.7947 LossD_Fake: 0.6815 LossD_Real: 0.6768  LossG_Adv: 0.7056 LossG_L1: 1.9856 LossG_Style 1.8426 LossG_Content 2.2608\n",
            "\n",
            "saving sample dataset_61_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[61](7/7): Loss_D: 0.6751 Loss_G: 6.0677 LossD_Fake: 0.6867 LossD_Real: 0.6635  LossG_Adv: 0.7003 LossG_L1: 1.6579 LossG_Style 1.7316 LossG_Content 1.9779\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[62](1/7): Loss_D: 0.6863 Loss_G: 6.5159 LossD_Fake: 0.6878 LossD_Real: 0.6847  LossG_Adv: 0.7030 LossG_L1: 2.0429 LossG_Style 1.6684 LossG_Content 2.1016\n",
            "===> Epoch[62](2/7): Loss_D: 0.6749 Loss_G: 6.9307 LossD_Fake: 0.6770 LossD_Real: 0.6729  LossG_Adv: 0.7103 LossG_L1: 1.8833 LossG_Style 2.0164 LossG_Content 2.3208\n",
            "===> Epoch[62](3/7): Loss_D: 0.6830 Loss_G: 6.2744 LossD_Fake: 0.6833 LossD_Real: 0.6827  LossG_Adv: 0.7037 LossG_L1: 1.8275 LossG_Style 1.5857 LossG_Content 2.1575\n",
            "===> Epoch[62](4/7): Loss_D: 0.6721 Loss_G: 6.6448 LossD_Fake: 0.6728 LossD_Real: 0.6715  LossG_Adv: 0.7148 LossG_L1: 1.9383 LossG_Style 1.7973 LossG_Content 2.1944\n",
            "===> Epoch[62](5/7): Loss_D: 0.6812 Loss_G: 6.1500 LossD_Fake: 0.6868 LossD_Real: 0.6755  LossG_Adv: 0.7001 LossG_L1: 1.6119 LossG_Style 1.7431 LossG_Content 2.0949\n",
            "===> Epoch[62](6/7): Loss_D: 0.6770 Loss_G: 6.0450 LossD_Fake: 0.6780 LossD_Real: 0.6760  LossG_Adv: 0.7094 LossG_L1: 1.7374 LossG_Style 1.5831 LossG_Content 2.0151\n",
            "\n",
            "saving sample dataset_62_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[62](7/7): Loss_D: 0.6820 Loss_G: 5.7359 LossD_Fake: 0.6889 LossD_Real: 0.6750  LossG_Adv: 0.6980 LossG_L1: 1.5890 LossG_Style 1.4668 LossG_Content 1.9821\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[63](1/7): Loss_D: 0.6813 Loss_G: 6.6305 LossD_Fake: 0.6846 LossD_Real: 0.6781  LossG_Adv: 0.7119 LossG_L1: 1.7872 LossG_Style 1.8847 LossG_Content 2.2468\n",
            "===> Epoch[63](2/7): Loss_D: 0.6762 Loss_G: 6.0926 LossD_Fake: 0.6697 LossD_Real: 0.6827  LossG_Adv: 0.7178 LossG_L1: 1.7903 LossG_Style 1.5709 LossG_Content 2.0136\n",
            "===> Epoch[63](3/7): Loss_D: 0.6846 Loss_G: 6.2630 LossD_Fake: 0.6768 LossD_Real: 0.6923  LossG_Adv: 0.7106 LossG_L1: 1.7359 LossG_Style 1.7348 LossG_Content 2.0817\n",
            "===> Epoch[63](4/7): Loss_D: 0.6749 Loss_G: 6.6385 LossD_Fake: 0.6680 LossD_Real: 0.6818  LossG_Adv: 0.7195 LossG_L1: 1.8003 LossG_Style 1.8528 LossG_Content 2.2660\n",
            "===> Epoch[63](5/7): Loss_D: 0.6794 Loss_G: 6.4124 LossD_Fake: 0.6698 LossD_Real: 0.6889  LossG_Adv: 0.7177 LossG_L1: 1.8342 LossG_Style 1.7408 LossG_Content 2.1197\n",
            "===> Epoch[63](6/7): Loss_D: 0.6741 Loss_G: 6.1870 LossD_Fake: 0.6671 LossD_Real: 0.6811  LossG_Adv: 0.7206 LossG_L1: 1.8182 LossG_Style 1.5457 LossG_Content 2.1025\n",
            "\n",
            "saving sample dataset_63_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[63](7/7): Loss_D: 0.6830 Loss_G: 5.8508 LossD_Fake: 0.6862 LossD_Real: 0.6798  LossG_Adv: 0.7006 LossG_L1: 1.5725 LossG_Style 1.6842 LossG_Content 1.8936\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[64](1/7): Loss_D: 0.6806 Loss_G: 6.1724 LossD_Fake: 0.6747 LossD_Real: 0.6864  LossG_Adv: 0.7099 LossG_L1: 1.6467 LossG_Style 1.6350 LossG_Content 2.1808\n",
            "===> Epoch[64](2/7): Loss_D: 0.6797 Loss_G: 6.2753 LossD_Fake: 0.6772 LossD_Real: 0.6822  LossG_Adv: 0.7102 LossG_L1: 1.6663 LossG_Style 1.8295 LossG_Content 2.0692\n",
            "===> Epoch[64](3/7): Loss_D: 0.6781 Loss_G: 6.4513 LossD_Fake: 0.6759 LossD_Real: 0.6802  LossG_Adv: 0.7113 LossG_L1: 1.8609 LossG_Style 1.6795 LossG_Content 2.1996\n",
            "===> Epoch[64](4/7): Loss_D: 0.6761 Loss_G: 6.4034 LossD_Fake: 0.6786 LossD_Real: 0.6735  LossG_Adv: 0.7085 LossG_L1: 1.6452 LossG_Style 1.9761 LossG_Content 2.0735\n",
            "===> Epoch[64](5/7): Loss_D: 0.6823 Loss_G: 7.0271 LossD_Fake: 0.6813 LossD_Real: 0.6833  LossG_Adv: 0.7059 LossG_L1: 2.1023 LossG_Style 1.8901 LossG_Content 2.3289\n",
            "===> Epoch[64](6/7): Loss_D: 0.6760 Loss_G: 6.5286 LossD_Fake: 0.6666 LossD_Real: 0.6854  LossG_Adv: 0.7214 LossG_L1: 1.9642 LossG_Style 1.7428 LossG_Content 2.1003\n",
            "\n",
            "saving sample dataset_64_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[64](7/7): Loss_D: 0.6724 Loss_G: 6.6882 LossD_Fake: 0.6682 LossD_Real: 0.6767  LossG_Adv: 0.7195 LossG_L1: 1.9483 LossG_Style 1.7694 LossG_Content 2.2509\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[65](1/7): Loss_D: 0.6822 Loss_G: 6.2952 LossD_Fake: 0.6828 LossD_Real: 0.6816  LossG_Adv: 0.7087 LossG_L1: 1.7166 LossG_Style 1.7385 LossG_Content 2.1314\n",
            "===> Epoch[65](2/7): Loss_D: 0.6773 Loss_G: 6.3853 LossD_Fake: 0.6689 LossD_Real: 0.6856  LossG_Adv: 0.7186 LossG_L1: 1.9579 LossG_Style 1.5698 LossG_Content 2.1390\n",
            "===> Epoch[65](3/7): Loss_D: 0.6789 Loss_G: 6.5257 LossD_Fake: 0.6697 LossD_Real: 0.6881  LossG_Adv: 0.7180 LossG_L1: 1.7516 LossG_Style 1.9404 LossG_Content 2.1158\n",
            "===> Epoch[65](4/7): Loss_D: 0.6801 Loss_G: 6.1852 LossD_Fake: 0.6765 LossD_Real: 0.6836  LossG_Adv: 0.7107 LossG_L1: 1.8092 LossG_Style 1.5656 LossG_Content 2.0997\n",
            "===> Epoch[65](5/7): Loss_D: 0.6783 Loss_G: 6.3667 LossD_Fake: 0.6770 LossD_Real: 0.6796  LossG_Adv: 0.7102 LossG_L1: 1.7070 LossG_Style 1.8010 LossG_Content 2.1485\n",
            "===> Epoch[65](6/7): Loss_D: 0.6735 Loss_G: 6.4638 LossD_Fake: 0.6709 LossD_Real: 0.6761  LossG_Adv: 0.7166 LossG_L1: 1.8127 LossG_Style 1.7424 LossG_Content 2.1920\n",
            "\n",
            "saving sample dataset_65_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[65](7/7): Loss_D: 0.6852 Loss_G: 5.9627 LossD_Fake: 0.6733 LossD_Real: 0.6972  LossG_Adv: 0.7140 LossG_L1: 1.8532 LossG_Style 1.4265 LossG_Content 1.9690\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[66](1/7): Loss_D: 0.6659 Loss_G: 6.6591 LossD_Fake: 0.6593 LossD_Real: 0.6724  LossG_Adv: 0.7132 LossG_L1: 1.9611 LossG_Style 1.9019 LossG_Content 2.0829\n",
            "===> Epoch[66](2/7): Loss_D: 0.6834 Loss_G: 5.7773 LossD_Fake: 0.7002 LossD_Real: 0.6665  LossG_Adv: 0.6873 LossG_L1: 1.6027 LossG_Style 1.4899 LossG_Content 1.9974\n",
            "===> Epoch[66](3/7): Loss_D: 0.6733 Loss_G: 6.3511 LossD_Fake: 0.6880 LossD_Real: 0.6585  LossG_Adv: 0.6994 LossG_L1: 1.8281 LossG_Style 1.7171 LossG_Content 2.1064\n",
            "===> Epoch[66](4/7): Loss_D: 0.6768 Loss_G: 5.9954 LossD_Fake: 0.6948 LossD_Real: 0.6587  LossG_Adv: 0.6924 LossG_L1: 1.6590 LossG_Style 1.5135 LossG_Content 2.1305\n",
            "===> Epoch[66](5/7): Loss_D: 0.6860 Loss_G: 6.1031 LossD_Fake: 0.6957 LossD_Real: 0.6763  LossG_Adv: 0.6919 LossG_L1: 1.6579 LossG_Style 1.7203 LossG_Content 2.0329\n",
            "===> Epoch[66](6/7): Loss_D: 0.6779 Loss_G: 6.7245 LossD_Fake: 0.6921 LossD_Real: 0.6638  LossG_Adv: 0.6952 LossG_L1: 1.7493 LossG_Style 1.9713 LossG_Content 2.3087\n",
            "\n",
            "saving sample dataset_66_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[66](7/7): Loss_D: 0.6787 Loss_G: 6.0570 LossD_Fake: 0.6885 LossD_Real: 0.6690  LossG_Adv: 0.6991 LossG_L1: 2.0288 LossG_Style 1.3639 LossG_Content 1.9652\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[67](1/7): Loss_D: 0.6725 Loss_G: 6.4839 LossD_Fake: 0.6867 LossD_Real: 0.6582  LossG_Adv: 0.7202 LossG_L1: 1.8460 LossG_Style 1.7735 LossG_Content 2.1442\n",
            "===> Epoch[67](2/7): Loss_D: 0.6835 Loss_G: 6.3951 LossD_Fake: 0.6779 LossD_Real: 0.6891  LossG_Adv: 0.7098 LossG_L1: 1.8969 LossG_Style 1.6905 LossG_Content 2.0979\n",
            "===> Epoch[67](3/7): Loss_D: 0.6720 Loss_G: 6.2684 LossD_Fake: 0.6678 LossD_Real: 0.6762  LossG_Adv: 0.7198 LossG_L1: 1.7881 LossG_Style 1.6965 LossG_Content 2.0639\n",
            "===> Epoch[67](4/7): Loss_D: 0.6783 Loss_G: 6.4391 LossD_Fake: 0.6772 LossD_Real: 0.6794  LossG_Adv: 0.7101 LossG_L1: 1.8532 LossG_Style 1.7062 LossG_Content 2.1697\n",
            "===> Epoch[67](5/7): Loss_D: 0.6746 Loss_G: 6.3488 LossD_Fake: 0.6681 LossD_Real: 0.6810  LossG_Adv: 0.7200 LossG_L1: 1.8128 LossG_Style 1.6935 LossG_Content 2.1226\n",
            "===> Epoch[67](6/7): Loss_D: 0.6746 Loss_G: 6.4181 LossD_Fake: 0.6700 LossD_Real: 0.6792  LossG_Adv: 0.7178 LossG_L1: 1.9425 LossG_Style 1.6011 LossG_Content 2.1567\n",
            "\n",
            "saving sample dataset_67_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[67](7/7): Loss_D: 0.6673 Loss_G: 6.6487 LossD_Fake: 0.6702 LossD_Real: 0.6643  LossG_Adv: 0.7172 LossG_L1: 1.9989 LossG_Style 1.7020 LossG_Content 2.2306\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[68](1/7): Loss_D: 0.6789 Loss_G: 6.9477 LossD_Fake: 0.6757 LossD_Real: 0.6821  LossG_Adv: 0.7106 LossG_L1: 2.1323 LossG_Style 1.9152 LossG_Content 2.1896\n",
            "===> Epoch[68](2/7): Loss_D: 0.6677 Loss_G: 6.5308 LossD_Fake: 0.6623 LossD_Real: 0.6731  LossG_Adv: 0.7257 LossG_L1: 1.9032 LossG_Style 1.6644 LossG_Content 2.2376\n",
            "===> Epoch[68](3/7): Loss_D: 0.6767 Loss_G: 6.8083 LossD_Fake: 0.6815 LossD_Real: 0.6720  LossG_Adv: 0.7058 LossG_L1: 1.9001 LossG_Style 2.0619 LossG_Content 2.1406\n",
            "===> Epoch[68](4/7): Loss_D: 0.6739 Loss_G: 6.0849 LossD_Fake: 0.6735 LossD_Real: 0.6744  LossG_Adv: 0.7139 LossG_L1: 1.6902 LossG_Style 1.5981 LossG_Content 2.0827\n",
            "===> Epoch[68](5/7): Loss_D: 0.6781 Loss_G: 6.3747 LossD_Fake: 0.6783 LossD_Real: 0.6779  LossG_Adv: 0.7095 LossG_L1: 1.8635 LossG_Style 1.7384 LossG_Content 2.0634\n",
            "===> Epoch[68](6/7): Loss_D: 0.6759 Loss_G: 6.1072 LossD_Fake: 0.6750 LossD_Real: 0.6767  LossG_Adv: 0.7125 LossG_L1: 1.7305 LossG_Style 1.5841 LossG_Content 2.0800\n",
            "\n",
            "saving sample dataset_68_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[68](7/7): Loss_D: 0.6724 Loss_G: 5.8922 LossD_Fake: 0.6781 LossD_Real: 0.6666  LossG_Adv: 0.7092 LossG_L1: 1.7176 LossG_Style 1.3873 LossG_Content 2.0781\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[69](1/7): Loss_D: 0.6820 Loss_G: 5.9377 LossD_Fake: 0.6784 LossD_Real: 0.6856  LossG_Adv: 0.7000 LossG_L1: 1.5726 LossG_Style 1.6685 LossG_Content 1.9966\n",
            "===> Epoch[69](2/7): Loss_D: 0.6777 Loss_G: 6.1572 LossD_Fake: 0.6945 LossD_Real: 0.6609  LossG_Adv: 0.6928 LossG_L1: 1.7301 LossG_Style 1.6311 LossG_Content 2.1032\n",
            "===> Epoch[69](3/7): Loss_D: 0.6798 Loss_G: 5.9441 LossD_Fake: 0.6846 LossD_Real: 0.6749  LossG_Adv: 0.7032 LossG_L1: 1.5999 LossG_Style 1.7138 LossG_Content 1.9272\n",
            "===> Epoch[69](4/7): Loss_D: 0.6685 Loss_G: 6.7483 LossD_Fake: 0.6841 LossD_Real: 0.6530  LossG_Adv: 0.7033 LossG_L1: 2.0785 LossG_Style 1.7335 LossG_Content 2.2330\n",
            "===> Epoch[69](5/7): Loss_D: 0.6773 Loss_G: 6.3720 LossD_Fake: 0.6915 LossD_Real: 0.6631  LossG_Adv: 0.6958 LossG_L1: 1.6943 LossG_Style 1.7767 LossG_Content 2.2052\n",
            "===> Epoch[69](6/7): Loss_D: 0.6755 Loss_G: 6.2741 LossD_Fake: 0.6899 LossD_Real: 0.6612  LossG_Adv: 0.6974 LossG_L1: 1.8549 LossG_Style 1.6313 LossG_Content 2.0905\n",
            "\n",
            "saving sample dataset_69_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[69](7/7): Loss_D: 0.6701 Loss_G: 7.0808 LossD_Fake: 0.6901 LossD_Real: 0.6501  LossG_Adv: 0.6976 LossG_L1: 1.7902 LossG_Style 2.3171 LossG_Content 2.2759\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[70](1/7): Loss_D: 0.6842 Loss_G: 6.6916 LossD_Fake: 0.6902 LossD_Real: 0.6782  LossG_Adv: 0.6956 LossG_L1: 2.0333 LossG_Style 1.7163 LossG_Content 2.2464\n",
            "===> Epoch[70](2/7): Loss_D: 0.6744 Loss_G: 6.6902 LossD_Fake: 0.6838 LossD_Real: 0.6650  LossG_Adv: 0.7040 LossG_L1: 1.9779 LossG_Style 1.8973 LossG_Content 2.1109\n",
            "===> Epoch[70](3/7): Loss_D: 0.6696 Loss_G: 6.5583 LossD_Fake: 0.6776 LossD_Real: 0.6615  LossG_Adv: 0.7099 LossG_L1: 1.8726 LossG_Style 1.7873 LossG_Content 2.1885\n",
            "===> Epoch[70](4/7): Loss_D: 0.6769 Loss_G: 5.9890 LossD_Fake: 0.6940 LossD_Real: 0.6598  LossG_Adv: 0.6937 LossG_L1: 1.6091 LossG_Style 1.6852 LossG_Content 2.0010\n",
            "===> Epoch[70](5/7): Loss_D: 0.6746 Loss_G: 6.2671 LossD_Fake: 0.6923 LossD_Real: 0.6569  LossG_Adv: 0.6951 LossG_L1: 1.7575 LossG_Style 1.6720 LossG_Content 2.1426\n",
            "===> Epoch[70](6/7): Loss_D: 0.6766 Loss_G: 6.0802 LossD_Fake: 0.6966 LossD_Real: 0.6565  LossG_Adv: 0.6910 LossG_L1: 1.6702 LossG_Style 1.6486 LossG_Content 2.0704\n",
            "\n",
            "saving sample dataset_70_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[70](7/7): Loss_D: 0.6701 Loss_G: 6.8026 LossD_Fake: 0.6951 LossD_Real: 0.6452  LossG_Adv: 0.6922 LossG_L1: 2.0102 LossG_Style 1.7677 LossG_Content 2.3324\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[71](1/7): Loss_D: 0.6810 Loss_G: 6.5263 LossD_Fake: 0.6993 LossD_Real: 0.6627  LossG_Adv: 0.7120 LossG_L1: 1.8120 LossG_Style 1.7983 LossG_Content 2.2040\n",
            "===> Epoch[71](2/7): Loss_D: 0.6723 Loss_G: 6.4233 LossD_Fake: 0.6638 LossD_Real: 0.6808  LossG_Adv: 0.7245 LossG_L1: 1.8934 LossG_Style 1.6141 LossG_Content 2.1914\n",
            "===> Epoch[71](3/7): Loss_D: 0.6726 Loss_G: 5.7298 LossD_Fake: 0.6616 LossD_Real: 0.6836  LossG_Adv: 0.7267 LossG_L1: 1.5285 LossG_Style 1.6083 LossG_Content 1.8664\n",
            "===> Epoch[71](4/7): Loss_D: 0.6773 Loss_G: 6.1902 LossD_Fake: 0.6782 LossD_Real: 0.6764  LossG_Adv: 0.7091 LossG_L1: 1.7492 LossG_Style 1.5908 LossG_Content 2.1412\n",
            "===> Epoch[71](5/7): Loss_D: 0.6726 Loss_G: 6.1966 LossD_Fake: 0.6691 LossD_Real: 0.6762  LossG_Adv: 0.7188 LossG_L1: 1.7738 LossG_Style 1.6494 LossG_Content 2.0546\n",
            "===> Epoch[71](6/7): Loss_D: 0.6789 Loss_G: 6.2510 LossD_Fake: 0.6661 LossD_Real: 0.6917  LossG_Adv: 0.7220 LossG_L1: 1.7927 LossG_Style 1.6180 LossG_Content 2.1183\n",
            "\n",
            "saving sample dataset_71_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[71](7/7): Loss_D: 0.6737 Loss_G: 6.0956 LossD_Fake: 0.6646 LossD_Real: 0.6828  LossG_Adv: 0.7239 LossG_L1: 1.6130 LossG_Style 1.6823 LossG_Content 2.0763\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[72](1/7): Loss_D: 0.6796 Loss_G: 6.4676 LossD_Fake: 0.6698 LossD_Real: 0.6894  LossG_Adv: 0.7003 LossG_L1: 1.7921 LossG_Style 1.7882 LossG_Content 2.1869\n",
            "===> Epoch[72](2/7): Loss_D: 0.6778 Loss_G: 6.1752 LossD_Fake: 0.6898 LossD_Real: 0.6657  LossG_Adv: 0.6974 LossG_L1: 1.8282 LossG_Style 1.5562 LossG_Content 2.0934\n",
            "===> Epoch[72](3/7): Loss_D: 0.6731 Loss_G: 5.6878 LossD_Fake: 0.6819 LossD_Real: 0.6643  LossG_Adv: 0.7059 LossG_L1: 1.6130 LossG_Style 1.4429 LossG_Content 1.9260\n",
            "===> Epoch[72](4/7): Loss_D: 0.6730 Loss_G: 6.2800 LossD_Fake: 0.6935 LossD_Real: 0.6526  LossG_Adv: 0.6938 LossG_L1: 1.7083 LossG_Style 1.7312 LossG_Content 2.1468\n",
            "===> Epoch[72](5/7): Loss_D: 0.6736 Loss_G: 5.9594 LossD_Fake: 0.6890 LossD_Real: 0.6583  LossG_Adv: 0.6984 LossG_L1: 1.5719 LossG_Style 1.6327 LossG_Content 2.0564\n",
            "===> Epoch[72](6/7): Loss_D: 0.6780 Loss_G: 5.8068 LossD_Fake: 0.6894 LossD_Real: 0.6666  LossG_Adv: 0.6981 LossG_L1: 1.6479 LossG_Style 1.4774 LossG_Content 1.9834\n",
            "\n",
            "saving sample dataset_72_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[72](7/7): Loss_D: 0.6778 Loss_G: 5.5024 LossD_Fake: 0.6826 LossD_Real: 0.6729  LossG_Adv: 0.7053 LossG_L1: 1.5170 LossG_Style 1.3681 LossG_Content 1.9119\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[73](1/7): Loss_D: 0.6759 Loss_G: 6.0050 LossD_Fake: 0.6837 LossD_Real: 0.6681  LossG_Adv: 0.7022 LossG_L1: 1.5851 LossG_Style 1.6751 LossG_Content 2.0426\n",
            "===> Epoch[73](2/7): Loss_D: 0.6740 Loss_G: 6.1294 LossD_Fake: 0.6922 LossD_Real: 0.6558  LossG_Adv: 0.6949 LossG_L1: 1.7336 LossG_Style 1.6137 LossG_Content 2.0872\n",
            "===> Epoch[73](3/7): Loss_D: 0.6768 Loss_G: 6.2473 LossD_Fake: 0.6951 LossD_Real: 0.6584  LossG_Adv: 0.6922 LossG_L1: 1.7400 LossG_Style 1.6657 LossG_Content 2.1493\n",
            "===> Epoch[73](4/7): Loss_D: 0.6758 Loss_G: 5.6899 LossD_Fake: 0.6880 LossD_Real: 0.6637  LossG_Adv: 0.6998 LossG_L1: 1.5817 LossG_Style 1.4239 LossG_Content 1.9845\n",
            "===> Epoch[73](5/7): Loss_D: 0.6786 Loss_G: 5.6602 LossD_Fake: 0.6885 LossD_Real: 0.6687  LossG_Adv: 0.6992 LossG_L1: 1.6486 LossG_Style 1.3611 LossG_Content 1.9513\n",
            "===> Epoch[73](6/7): Loss_D: 0.6716 Loss_G: 5.8422 LossD_Fake: 0.6856 LossD_Real: 0.6576  LossG_Adv: 0.7018 LossG_L1: 1.5082 LossG_Style 1.6574 LossG_Content 1.9749\n",
            "\n",
            "saving sample dataset_73_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[73](7/7): Loss_D: 0.6788 Loss_G: 6.4344 LossD_Fake: 0.7050 LossD_Real: 0.6527  LossG_Adv: 0.6823 LossG_L1: 1.7772 LossG_Style 1.6951 LossG_Content 2.2798\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[74](1/7): Loss_D: 0.6785 Loss_G: 5.9424 LossD_Fake: 0.6907 LossD_Real: 0.6664  LossG_Adv: 0.7074 LossG_L1: 1.5994 LossG_Style 1.7120 LossG_Content 1.9236\n",
            "===> Epoch[74](2/7): Loss_D: 0.6727 Loss_G: 5.9278 LossD_Fake: 0.6813 LossD_Real: 0.6640  LossG_Adv: 0.7060 LossG_L1: 1.6252 LossG_Style 1.5514 LossG_Content 2.0453\n",
            "===> Epoch[74](3/7): Loss_D: 0.6750 Loss_G: 6.1761 LossD_Fake: 0.6871 LossD_Real: 0.6629  LossG_Adv: 0.7007 LossG_L1: 1.6724 LossG_Style 1.7583 LossG_Content 2.0447\n",
            "===> Epoch[74](4/7): Loss_D: 0.6718 Loss_G: 6.3795 LossD_Fake: 0.6840 LossD_Real: 0.6595  LossG_Adv: 0.7034 LossG_L1: 1.6883 LossG_Style 1.7256 LossG_Content 2.2621\n",
            "===> Epoch[74](5/7): Loss_D: 0.6818 Loss_G: 5.5586 LossD_Fake: 0.6885 LossD_Real: 0.6751  LossG_Adv: 0.6991 LossG_L1: 1.5282 LossG_Style 1.3968 LossG_Content 1.9345\n",
            "===> Epoch[74](6/7): Loss_D: 0.6775 Loss_G: 5.8293 LossD_Fake: 0.6799 LossD_Real: 0.6751  LossG_Adv: 0.7080 LossG_L1: 1.6437 LossG_Style 1.4583 LossG_Content 2.0194\n",
            "\n",
            "saving sample dataset_74_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[74](7/7): Loss_D: 0.6723 Loss_G: 5.5720 LossD_Fake: 0.6737 LossD_Real: 0.6710  LossG_Adv: 0.7137 LossG_L1: 1.5685 LossG_Style 1.3452 LossG_Content 1.9446\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[75](1/7): Loss_D: 0.6784 Loss_G: 6.1560 LossD_Fake: 0.6888 LossD_Real: 0.6679  LossG_Adv: 0.7180 LossG_L1: 1.7020 LossG_Style 1.6789 LossG_Content 2.0572\n",
            "===> Epoch[75](2/7): Loss_D: 0.6703 Loss_G: 5.7828 LossD_Fake: 0.6523 LossD_Real: 0.6884  LossG_Adv: 0.7368 LossG_L1: 1.5914 LossG_Style 1.4792 LossG_Content 1.9754\n",
            "===> Epoch[75](3/7): Loss_D: 0.6741 Loss_G: 6.0866 LossD_Fake: 0.6679 LossD_Real: 0.6804  LossG_Adv: 0.7201 LossG_L1: 1.6451 LossG_Style 1.6691 LossG_Content 2.0523\n",
            "===> Epoch[75](4/7): Loss_D: 0.6786 Loss_G: 5.9465 LossD_Fake: 0.6681 LossD_Real: 0.6890  LossG_Adv: 0.7198 LossG_L1: 1.6279 LossG_Style 1.5531 LossG_Content 2.0456\n",
            "===> Epoch[75](5/7): Loss_D: 0.6749 Loss_G: 6.0691 LossD_Fake: 0.6651 LossD_Real: 0.6848  LossG_Adv: 0.7233 LossG_L1: 1.6162 LossG_Style 1.6401 LossG_Content 2.0894\n",
            "===> Epoch[75](6/7): Loss_D: 0.6732 Loss_G: 6.3362 LossD_Fake: 0.6633 LossD_Real: 0.6831  LossG_Adv: 0.7251 LossG_L1: 1.8332 LossG_Style 1.6691 LossG_Content 2.1088\n",
            "\n",
            "saving sample dataset_75_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[75](7/7): Loss_D: 0.6695 Loss_G: 6.0030 LossD_Fake: 0.6635 LossD_Real: 0.6754  LossG_Adv: 0.7247 LossG_L1: 1.6548 LossG_Style 1.6298 LossG_Content 1.9937\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[76](1/7): Loss_D: 0.6773 Loss_G: 6.4989 LossD_Fake: 0.6691 LossD_Real: 0.6855  LossG_Adv: 0.7145 LossG_L1: 1.9620 LossG_Style 1.7012 LossG_Content 2.1212\n",
            "===> Epoch[76](2/7): Loss_D: 0.6680 Loss_G: 6.5183 LossD_Fake: 0.6679 LossD_Real: 0.6681  LossG_Adv: 0.7198 LossG_L1: 1.7566 LossG_Style 1.8337 LossG_Content 2.2081\n",
            "===> Epoch[76](3/7): Loss_D: 0.6771 Loss_G: 5.8978 LossD_Fake: 0.6660 LossD_Real: 0.6883  LossG_Adv: 0.7222 LossG_L1: 1.7053 LossG_Style 1.4331 LossG_Content 2.0371\n",
            "===> Epoch[76](4/7): Loss_D: 0.6743 Loss_G: 6.1280 LossD_Fake: 0.6646 LossD_Real: 0.6840  LossG_Adv: 0.7239 LossG_L1: 1.5834 LossG_Style 1.8138 LossG_Content 2.0069\n",
            "===> Epoch[76](5/7): Loss_D: 0.6736 Loss_G: 5.9472 LossD_Fake: 0.6722 LossD_Real: 0.6751  LossG_Adv: 0.7156 LossG_L1: 1.6384 LossG_Style 1.5452 LossG_Content 2.0480\n",
            "===> Epoch[76](6/7): Loss_D: 0.6644 Loss_G: 6.3925 LossD_Fake: 0.6620 LossD_Real: 0.6668  LossG_Adv: 0.7266 LossG_L1: 1.7348 LossG_Style 1.8744 LossG_Content 2.0568\n",
            "\n",
            "saving sample dataset_76_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[76](7/7): Loss_D: 0.6827 Loss_G: 5.4056 LossD_Fake: 0.6704 LossD_Real: 0.6951  LossG_Adv: 0.7174 LossG_L1: 1.4469 LossG_Style 1.3297 LossG_Content 1.9117\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[77](1/7): Loss_D: 0.6771 Loss_G: 6.0414 LossD_Fake: 0.6700 LossD_Real: 0.6842  LossG_Adv: 0.7091 LossG_L1: 1.5638 LossG_Style 1.7979 LossG_Content 1.9706\n",
            "===> Epoch[77](2/7): Loss_D: 0.6664 Loss_G: 5.6810 LossD_Fake: 0.6699 LossD_Real: 0.6628  LossG_Adv: 0.7180 LossG_L1: 1.6115 LossG_Style 1.3734 LossG_Content 1.9782\n",
            "===> Epoch[77](3/7): Loss_D: 0.6743 Loss_G: 5.9597 LossD_Fake: 0.6862 LossD_Real: 0.6624  LossG_Adv: 0.7014 LossG_L1: 1.5558 LossG_Style 1.6826 LossG_Content 2.0199\n",
            "===> Epoch[77](4/7): Loss_D: 0.6738 Loss_G: 5.8110 LossD_Fake: 0.6861 LossD_Real: 0.6614  LossG_Adv: 0.7012 LossG_L1: 1.5333 LossG_Style 1.5412 LossG_Content 2.0352\n",
            "===> Epoch[77](5/7): Loss_D: 0.6715 Loss_G: 6.1604 LossD_Fake: 0.6789 LossD_Real: 0.6641  LossG_Adv: 0.7088 LossG_L1: 1.8831 LossG_Style 1.5384 LossG_Content 2.0301\n",
            "===> Epoch[77](6/7): Loss_D: 0.6685 Loss_G: 6.1114 LossD_Fake: 0.6737 LossD_Real: 0.6633  LossG_Adv: 0.7144 LossG_L1: 1.6915 LossG_Style 1.5326 LossG_Content 2.1729\n",
            "\n",
            "saving sample dataset_77_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[77](7/7): Loss_D: 0.6726 Loss_G: 5.4115 LossD_Fake: 0.6845 LossD_Real: 0.6606  LossG_Adv: 0.7026 LossG_L1: 1.4864 LossG_Style 1.4233 LossG_Content 1.7992\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[78](1/7): Loss_D: 0.6704 Loss_G: 5.8702 LossD_Fake: 0.6854 LossD_Real: 0.6554  LossG_Adv: 0.7158 LossG_L1: 1.6296 LossG_Style 1.4994 LossG_Content 2.0254\n",
            "===> Epoch[78](2/7): Loss_D: 0.6676 Loss_G: 6.1676 LossD_Fake: 0.6660 LossD_Real: 0.6691  LossG_Adv: 0.7223 LossG_L1: 1.7456 LossG_Style 1.5845 LossG_Content 2.1151\n",
            "===> Epoch[78](3/7): Loss_D: 0.6765 Loss_G: 5.7903 LossD_Fake: 0.6686 LossD_Real: 0.6843  LossG_Adv: 0.7196 LossG_L1: 1.5095 LossG_Style 1.5623 LossG_Content 1.9989\n",
            "===> Epoch[78](4/7): Loss_D: 0.6749 Loss_G: 5.7110 LossD_Fake: 0.6623 LossD_Real: 0.6876  LossG_Adv: 0.7260 LossG_L1: 1.6623 LossG_Style 1.3590 LossG_Content 1.9637\n",
            "===> Epoch[78](5/7): Loss_D: 0.6730 Loss_G: 5.6607 LossD_Fake: 0.6721 LossD_Real: 0.6738  LossG_Adv: 0.7157 LossG_L1: 1.4426 LossG_Style 1.5998 LossG_Content 1.9026\n",
            "===> Epoch[78](6/7): Loss_D: 0.6709 Loss_G: 6.2278 LossD_Fake: 0.6708 LossD_Real: 0.6710  LossG_Adv: 0.7174 LossG_L1: 1.6896 LossG_Style 1.6417 LossG_Content 2.1791\n",
            "\n",
            "saving sample dataset_78_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[78](7/7): Loss_D: 0.6682 Loss_G: 6.1771 LossD_Fake: 0.6688 LossD_Real: 0.6676  LossG_Adv: 0.7192 LossG_L1: 1.7412 LossG_Style 1.6471 LossG_Content 2.0697\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[79](1/7): Loss_D: 0.6716 Loss_G: 5.9618 LossD_Fake: 0.6660 LossD_Real: 0.6772  LossG_Adv: 0.7247 LossG_L1: 1.7153 LossG_Style 1.4590 LossG_Content 2.0628\n",
            "===> Epoch[79](2/7): Loss_D: 0.6597 Loss_G: 6.3869 LossD_Fake: 0.6565 LossD_Real: 0.6629  LossG_Adv: 0.7330 LossG_L1: 1.9456 LossG_Style 1.6456 LossG_Content 2.0626\n",
            "===> Epoch[79](3/7): Loss_D: 0.6664 Loss_G: 5.8413 LossD_Fake: 0.6589 LossD_Real: 0.6739  LossG_Adv: 0.7301 LossG_L1: 1.6214 LossG_Style 1.4873 LossG_Content 2.0026\n",
            "===> Epoch[79](4/7): Loss_D: 0.6727 Loss_G: 5.9112 LossD_Fake: 0.6753 LossD_Real: 0.6700  LossG_Adv: 0.7123 LossG_L1: 1.5989 LossG_Style 1.5374 LossG_Content 2.0627\n",
            "===> Epoch[79](5/7): Loss_D: 0.6767 Loss_G: 5.7980 LossD_Fake: 0.6686 LossD_Real: 0.6848  LossG_Adv: 0.7201 LossG_L1: 1.4466 LossG_Style 1.5990 LossG_Content 2.0322\n",
            "===> Epoch[79](6/7): Loss_D: 0.6756 Loss_G: 5.6241 LossD_Fake: 0.6725 LossD_Real: 0.6788  LossG_Adv: 0.7153 LossG_L1: 1.5470 LossG_Style 1.4427 LossG_Content 1.9191\n",
            "\n",
            "saving sample dataset_79_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[79](7/7): Loss_D: 0.6787 Loss_G: 5.2646 LossD_Fake: 0.6693 LossD_Real: 0.6882  LossG_Adv: 0.7183 LossG_L1: 1.3536 LossG_Style 1.3458 LossG_Content 1.8469\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[80](1/7): Loss_D: 0.6667 Loss_G: 5.9451 LossD_Fake: 0.6672 LossD_Real: 0.6661  LossG_Adv: 0.7270 LossG_L1: 1.6673 LossG_Style 1.5115 LossG_Content 2.0393\n",
            "===> Epoch[80](2/7): Loss_D: 0.6755 Loss_G: 5.8200 LossD_Fake: 0.6656 LossD_Real: 0.6854  LossG_Adv: 0.7229 LossG_L1: 1.6130 LossG_Style 1.4864 LossG_Content 1.9976\n",
            "===> Epoch[80](3/7): Loss_D: 0.6739 Loss_G: 6.0565 LossD_Fake: 0.6665 LossD_Real: 0.6814  LossG_Adv: 0.7222 LossG_L1: 1.6334 LossG_Style 1.6182 LossG_Content 2.0827\n",
            "===> Epoch[80](4/7): Loss_D: 0.6761 Loss_G: 5.4099 LossD_Fake: 0.6659 LossD_Real: 0.6863  LossG_Adv: 0.7225 LossG_L1: 1.4336 LossG_Style 1.3768 LossG_Content 1.8769\n",
            "===> Epoch[80](5/7): Loss_D: 0.6717 Loss_G: 6.1017 LossD_Fake: 0.6732 LossD_Real: 0.6702  LossG_Adv: 0.7148 LossG_L1: 1.7265 LossG_Style 1.5579 LossG_Content 2.1024\n",
            "===> Epoch[80](6/7): Loss_D: 0.6747 Loss_G: 5.6453 LossD_Fake: 0.6609 LossD_Real: 0.6884  LossG_Adv: 0.7279 LossG_L1: 1.4524 LossG_Style 1.5358 LossG_Content 1.9292\n",
            "\n",
            "saving sample dataset_80_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[80](7/7): Loss_D: 0.6532 Loss_G: 5.2635 LossD_Fake: 0.6544 LossD_Real: 0.6519  LossG_Adv: 0.7344 LossG_L1: 1.5527 LossG_Style 1.2279 LossG_Content 1.7484\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[81](1/7): Loss_D: 0.6737 Loss_G: 5.7015 LossD_Fake: 0.6689 LossD_Real: 0.6785  LossG_Adv: 0.7141 LossG_L1: 1.5681 LossG_Style 1.5136 LossG_Content 1.9057\n",
            "===> Epoch[81](2/7): Loss_D: 0.6710 Loss_G: 5.5103 LossD_Fake: 0.6765 LossD_Real: 0.6656  LossG_Adv: 0.7113 LossG_L1: 1.4581 LossG_Style 1.3834 LossG_Content 1.9574\n",
            "===> Epoch[81](3/7): Loss_D: 0.6677 Loss_G: 5.9410 LossD_Fake: 0.6686 LossD_Real: 0.6669  LossG_Adv: 0.7200 LossG_L1: 1.6570 LossG_Style 1.5825 LossG_Content 1.9815\n",
            "===> Epoch[81](4/7): Loss_D: 0.6725 Loss_G: 5.6114 LossD_Fake: 0.6765 LossD_Real: 0.6685  LossG_Adv: 0.7116 LossG_L1: 1.4544 LossG_Style 1.4386 LossG_Content 2.0069\n",
            "===> Epoch[81](5/7): Loss_D: 0.6710 Loss_G: 6.1030 LossD_Fake: 0.6773 LossD_Real: 0.6648  LossG_Adv: 0.7107 LossG_L1: 1.6727 LossG_Style 1.6602 LossG_Content 2.0594\n",
            "===> Epoch[81](6/7): Loss_D: 0.6751 Loss_G: 5.4497 LossD_Fake: 0.6683 LossD_Real: 0.6819  LossG_Adv: 0.7202 LossG_L1: 1.4284 LossG_Style 1.3543 LossG_Content 1.9468\n",
            "\n",
            "saving sample dataset_81_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[81](7/7): Loss_D: 0.6639 Loss_G: 5.9501 LossD_Fake: 0.6726 LossD_Real: 0.6551  LossG_Adv: 0.7149 LossG_L1: 1.5521 LossG_Style 1.6621 LossG_Content 2.0209\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[82](1/7): Loss_D: 0.6687 Loss_G: 5.9031 LossD_Fake: 0.6786 LossD_Real: 0.6588  LossG_Adv: 0.7373 LossG_L1: 1.5033 LossG_Style 1.5643 LossG_Content 2.0983\n",
            "===> Epoch[82](2/7): Loss_D: 0.6786 Loss_G: 5.2283 LossD_Fake: 0.6442 LossD_Real: 0.7131  LossG_Adv: 0.7459 LossG_L1: 1.4261 LossG_Style 1.3131 LossG_Content 1.7432\n",
            "===> Epoch[82](3/7): Loss_D: 0.6722 Loss_G: 5.7266 LossD_Fake: 0.6507 LossD_Real: 0.6936  LossG_Adv: 0.7389 LossG_L1: 1.4953 LossG_Style 1.5239 LossG_Content 1.9684\n",
            "===> Epoch[82](4/7): Loss_D: 0.6626 Loss_G: 6.0536 LossD_Fake: 0.6379 LossD_Real: 0.6873  LossG_Adv: 0.7536 LossG_L1: 1.6874 LossG_Style 1.5588 LossG_Content 2.0538\n",
            "===> Epoch[82](5/7): Loss_D: 0.6812 Loss_G: 5.4764 LossD_Fake: 0.6498 LossD_Real: 0.7125  LossG_Adv: 0.7401 LossG_L1: 1.4242 LossG_Style 1.3336 LossG_Content 1.9785\n",
            "===> Epoch[82](6/7): Loss_D: 0.6670 Loss_G: 6.0289 LossD_Fake: 0.6437 LossD_Real: 0.6903  LossG_Adv: 0.7471 LossG_L1: 1.5713 LossG_Style 1.6736 LossG_Content 2.0370\n",
            "\n",
            "saving sample dataset_82_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[82](7/7): Loss_D: 0.6721 Loss_G: 5.7904 LossD_Fake: 0.6537 LossD_Real: 0.6906  LossG_Adv: 0.7350 LossG_L1: 1.5412 LossG_Style 1.5317 LossG_Content 1.9826\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[83](1/7): Loss_D: 0.6622 Loss_G: 6.5609 LossD_Fake: 0.6455 LossD_Real: 0.6789  LossG_Adv: 0.7129 LossG_L1: 1.7475 LossG_Style 1.8694 LossG_Content 2.2311\n",
            "===> Epoch[83](2/7): Loss_D: 0.6698 Loss_G: 6.3175 LossD_Fake: 0.6803 LossD_Real: 0.6593  LossG_Adv: 0.7083 LossG_L1: 1.7937 LossG_Style 1.6236 LossG_Content 2.1919\n",
            "===> Epoch[83](3/7): Loss_D: 0.6703 Loss_G: 5.3666 LossD_Fake: 0.6693 LossD_Real: 0.6714  LossG_Adv: 0.7193 LossG_L1: 1.4125 LossG_Style 1.4350 LossG_Content 1.7998\n",
            "===> Epoch[83](4/7): Loss_D: 0.6713 Loss_G: 5.6112 LossD_Fake: 0.6829 LossD_Real: 0.6597  LossG_Adv: 0.7056 LossG_L1: 1.5524 LossG_Style 1.3882 LossG_Content 1.9649\n",
            "===> Epoch[83](5/7): Loss_D: 0.6825 Loss_G: 5.7515 LossD_Fake: 0.6805 LossD_Real: 0.6845  LossG_Adv: 0.7082 LossG_L1: 1.6223 LossG_Style 1.5155 LossG_Content 1.9055\n",
            "===> Epoch[83](6/7): Loss_D: 0.6693 Loss_G: 5.7040 LossD_Fake: 0.6703 LossD_Real: 0.6682  LossG_Adv: 0.7187 LossG_L1: 1.5242 LossG_Style 1.4229 LossG_Content 2.0383\n",
            "\n",
            "saving sample dataset_83_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[83](7/7): Loss_D: 0.6829 Loss_G: 5.1640 LossD_Fake: 0.6824 LossD_Real: 0.6834  LossG_Adv: 0.7050 LossG_L1: 1.2581 LossG_Style 1.4002 LossG_Content 1.8007\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[84](1/7): Loss_D: 0.6711 Loss_G: 5.9887 LossD_Fake: 0.6823 LossD_Real: 0.6598  LossG_Adv: 0.7239 LossG_L1: 1.5287 LossG_Style 1.6456 LossG_Content 2.0906\n",
            "===> Epoch[84](2/7): Loss_D: 0.6769 Loss_G: 5.6309 LossD_Fake: 0.6645 LossD_Real: 0.6893  LossG_Adv: 0.7255 LossG_L1: 1.5574 LossG_Style 1.3881 LossG_Content 1.9599\n",
            "===> Epoch[84](3/7): Loss_D: 0.6651 Loss_G: 5.7544 LossD_Fake: 0.6637 LossD_Real: 0.6666  LossG_Adv: 0.7253 LossG_L1: 1.5893 LossG_Style 1.4860 LossG_Content 1.9538\n",
            "===> Epoch[84](4/7): Loss_D: 0.6763 Loss_G: 5.3375 LossD_Fake: 0.6573 LossD_Real: 0.6952  LossG_Adv: 0.7325 LossG_L1: 1.4214 LossG_Style 1.3135 LossG_Content 1.8701\n",
            "===> Epoch[84](5/7): Loss_D: 0.6717 Loss_G: 5.3611 LossD_Fake: 0.6544 LossD_Real: 0.6891  LossG_Adv: 0.7355 LossG_L1: 1.4289 LossG_Style 1.3637 LossG_Content 1.8330\n",
            "===> Epoch[84](6/7): Loss_D: 0.6569 Loss_G: 5.6183 LossD_Fake: 0.6582 LossD_Real: 0.6556  LossG_Adv: 0.7308 LossG_L1: 1.5379 LossG_Style 1.3752 LossG_Content 1.9744\n",
            "\n",
            "saving sample dataset_84_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[84](7/7): Loss_D: 0.6793 Loss_G: 6.6860 LossD_Fake: 0.6770 LossD_Real: 0.6816  LossG_Adv: 0.7115 LossG_L1: 1.6661 LossG_Style 2.0733 LossG_Content 2.2350\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[85](1/7): Loss_D: 0.6691 Loss_G: 6.5038 LossD_Fake: 0.6676 LossD_Real: 0.6705  LossG_Adv: 0.7163 LossG_L1: 1.7984 LossG_Style 1.7573 LossG_Content 2.2318\n",
            "===> Epoch[85](2/7): Loss_D: 0.6681 Loss_G: 6.3785 LossD_Fake: 0.6633 LossD_Real: 0.6729  LossG_Adv: 0.7263 LossG_L1: 1.6265 LossG_Style 2.0155 LossG_Content 2.0102\n",
            "===> Epoch[85](3/7): Loss_D: 0.6697 Loss_G: 5.7094 LossD_Fake: 0.6629 LossD_Real: 0.6764  LossG_Adv: 0.7262 LossG_L1: 1.6500 LossG_Style 1.3851 LossG_Content 1.9482\n",
            "===> Epoch[85](4/7): Loss_D: 0.6753 Loss_G: 5.3793 LossD_Fake: 0.6711 LossD_Real: 0.6795  LossG_Adv: 0.7181 LossG_L1: 1.3793 LossG_Style 1.4175 LossG_Content 1.8644\n",
            "===> Epoch[85](5/7): Loss_D: 0.6678 Loss_G: 5.7814 LossD_Fake: 0.6738 LossD_Real: 0.6618  LossG_Adv: 0.7165 LossG_L1: 1.5418 LossG_Style 1.4695 LossG_Content 2.0536\n",
            "===> Epoch[85](6/7): Loss_D: 0.6712 Loss_G: 5.7161 LossD_Fake: 0.6670 LossD_Real: 0.6755  LossG_Adv: 0.7220 LossG_L1: 1.4740 LossG_Style 1.5931 LossG_Content 1.9271\n",
            "\n",
            "saving sample dataset_85_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[85](7/7): Loss_D: 0.6606 Loss_G: 5.3973 LossD_Fake: 0.6760 LossD_Real: 0.6451  LossG_Adv: 0.7146 LossG_L1: 1.5272 LossG_Style 1.2918 LossG_Content 1.8638\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[86](1/7): Loss_D: 0.6690 Loss_G: 5.4621 LossD_Fake: 0.6705 LossD_Real: 0.6674  LossG_Adv: 0.7339 LossG_L1: 1.4979 LossG_Style 1.3083 LossG_Content 1.9219\n",
            "===> Epoch[86](2/7): Loss_D: 0.6759 Loss_G: 5.3604 LossD_Fake: 0.6667 LossD_Real: 0.6850  LossG_Adv: 0.7225 LossG_L1: 1.4090 LossG_Style 1.3790 LossG_Content 1.8500\n",
            "===> Epoch[86](3/7): Loss_D: 0.6705 Loss_G: 5.4988 LossD_Fake: 0.6696 LossD_Real: 0.6714  LossG_Adv: 0.7207 LossG_L1: 1.4170 LossG_Style 1.3801 LossG_Content 1.9809\n",
            "===> Epoch[86](4/7): Loss_D: 0.6688 Loss_G: 5.4714 LossD_Fake: 0.6690 LossD_Real: 0.6686  LossG_Adv: 0.7200 LossG_L1: 1.4490 LossG_Style 1.4127 LossG_Content 1.8898\n",
            "===> Epoch[86](5/7): Loss_D: 0.6817 Loss_G: 5.9340 LossD_Fake: 0.6749 LossD_Real: 0.6884  LossG_Adv: 0.7152 LossG_L1: 1.6051 LossG_Style 1.5162 LossG_Content 2.0975\n",
            "===> Epoch[86](6/7): Loss_D: 0.6747 Loss_G: 5.8000 LossD_Fake: 0.6573 LossD_Real: 0.6920  LossG_Adv: 0.7324 LossG_L1: 1.5009 LossG_Style 1.6148 LossG_Content 1.9518\n",
            "\n",
            "saving sample dataset_86_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[86](7/7): Loss_D: 0.6437 Loss_G: 5.1561 LossD_Fake: 0.6389 LossD_Real: 0.6485  LossG_Adv: 0.7524 LossG_L1: 1.4356 LossG_Style 1.2862 LossG_Content 1.6820\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[87](1/7): Loss_D: 0.6707 Loss_G: 5.4765 LossD_Fake: 0.6679 LossD_Real: 0.6736  LossG_Adv: 0.7323 LossG_L1: 1.4301 LossG_Style 1.4232 LossG_Content 1.8910\n",
            "===> Epoch[87](2/7): Loss_D: 0.6787 Loss_G: 5.3119 LossD_Fake: 0.6566 LossD_Real: 0.7008  LossG_Adv: 0.7330 LossG_L1: 1.4850 LossG_Style 1.2272 LossG_Content 1.8667\n",
            "===> Epoch[87](3/7): Loss_D: 0.6538 Loss_G: 5.8986 LossD_Fake: 0.6456 LossD_Real: 0.6620  LossG_Adv: 0.7448 LossG_L1: 1.6311 LossG_Style 1.5234 LossG_Content 1.9992\n",
            "===> Epoch[87](4/7): Loss_D: 0.6748 Loss_G: 5.5410 LossD_Fake: 0.6595 LossD_Real: 0.6901  LossG_Adv: 0.7298 LossG_L1: 1.4748 LossG_Style 1.3523 LossG_Content 1.9841\n",
            "===> Epoch[87](5/7): Loss_D: 0.6701 Loss_G: 5.1949 LossD_Fake: 0.6554 LossD_Real: 0.6848  LossG_Adv: 0.7345 LossG_L1: 1.3618 LossG_Style 1.3247 LossG_Content 1.7739\n",
            "===> Epoch[87](6/7): Loss_D: 0.6664 Loss_G: 5.8085 LossD_Fake: 0.6602 LossD_Real: 0.6727  LossG_Adv: 0.7302 LossG_L1: 1.5384 LossG_Style 1.5160 LossG_Content 2.0238\n",
            "\n",
            "saving sample dataset_87_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[87](7/7): Loss_D: 0.6778 Loss_G: 5.5159 LossD_Fake: 0.6689 LossD_Real: 0.6866  LossG_Adv: 0.7192 LossG_L1: 1.3258 LossG_Style 1.5611 LossG_Content 1.9097\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[88](1/7): Loss_D: 0.6756 Loss_G: 5.2285 LossD_Fake: 0.6568 LossD_Real: 0.6945  LossG_Adv: 0.6954 LossG_L1: 1.3686 LossG_Style 1.3276 LossG_Content 1.8369\n",
            "===> Epoch[88](2/7): Loss_D: 0.6712 Loss_G: 5.6636 LossD_Fake: 0.7011 LossD_Real: 0.6413  LossG_Adv: 0.6871 LossG_L1: 1.4662 LossG_Style 1.5349 LossG_Content 1.9753\n",
            "===> Epoch[88](3/7): Loss_D: 0.6648 Loss_G: 5.9918 LossD_Fake: 0.6993 LossD_Real: 0.6303  LossG_Adv: 0.6896 LossG_L1: 1.5745 LossG_Style 1.6239 LossG_Content 2.1038\n",
            "===> Epoch[88](4/7): Loss_D: 0.6709 Loss_G: 5.6275 LossD_Fake: 0.7061 LossD_Real: 0.6356  LossG_Adv: 0.6820 LossG_L1: 1.4985 LossG_Style 1.4906 LossG_Content 1.9564\n",
            "===> Epoch[88](5/7): Loss_D: 0.6688 Loss_G: 5.1911 LossD_Fake: 0.6919 LossD_Real: 0.6456  LossG_Adv: 0.6962 LossG_L1: 1.3789 LossG_Style 1.2688 LossG_Content 1.8471\n",
            "===> Epoch[88](6/7): Loss_D: 0.6685 Loss_G: 5.4905 LossD_Fake: 0.6896 LossD_Real: 0.6475  LossG_Adv: 0.6989 LossG_L1: 1.5511 LossG_Style 1.3785 LossG_Content 1.8620\n",
            "\n",
            "saving sample dataset_88_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[88](7/7): Loss_D: 0.6586 Loss_G: 6.0279 LossD_Fake: 0.6817 LossD_Real: 0.6356  LossG_Adv: 0.7063 LossG_L1: 1.8101 LossG_Style 1.3711 LossG_Content 2.1404\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[89](1/7): Loss_D: 0.6722 Loss_G: 5.6001 LossD_Fake: 0.6865 LossD_Real: 0.6579  LossG_Adv: 0.7163 LossG_L1: 1.4931 LossG_Style 1.4580 LossG_Content 1.9326\n",
            "===> Epoch[89](2/7): Loss_D: 0.6699 Loss_G: 5.3448 LossD_Fake: 0.6851 LossD_Real: 0.6546  LossG_Adv: 0.7027 LossG_L1: 1.3973 LossG_Style 1.3605 LossG_Content 1.8844\n",
            "===> Epoch[89](3/7): Loss_D: 0.6585 Loss_G: 5.5577 LossD_Fake: 0.6747 LossD_Real: 0.6422  LossG_Adv: 0.7136 LossG_L1: 1.4932 LossG_Style 1.4789 LossG_Content 1.8720\n",
            "===> Epoch[89](4/7): Loss_D: 0.6681 Loss_G: 5.6627 LossD_Fake: 0.6956 LossD_Real: 0.6407  LossG_Adv: 0.6935 LossG_L1: 1.4474 LossG_Style 1.4951 LossG_Content 2.0266\n",
            "===> Epoch[89](5/7): Loss_D: 0.6660 Loss_G: 5.5258 LossD_Fake: 0.6867 LossD_Real: 0.6453  LossG_Adv: 0.7013 LossG_L1: 1.4535 LossG_Style 1.4172 LossG_Content 1.9538\n",
            "===> Epoch[89](6/7): Loss_D: 0.6693 Loss_G: 5.2286 LossD_Fake: 0.6790 LossD_Real: 0.6596  LossG_Adv: 0.7102 LossG_L1: 1.3667 LossG_Style 1.2813 LossG_Content 1.8703\n",
            "\n",
            "saving sample dataset_89_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[89](7/7): Loss_D: 0.6742 Loss_G: 4.8735 LossD_Fake: 0.6791 LossD_Real: 0.6693  LossG_Adv: 0.7090 LossG_L1: 1.3303 LossG_Style 1.1675 LossG_Content 1.6666\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[90](1/7): Loss_D: 0.6715 Loss_G: 5.1816 LossD_Fake: 0.6869 LossD_Real: 0.6561  LossG_Adv: 0.7167 LossG_L1: 1.3821 LossG_Style 1.2439 LossG_Content 1.8389\n",
            "===> Epoch[90](2/7): Loss_D: 0.6647 Loss_G: 5.5995 LossD_Fake: 0.6754 LossD_Real: 0.6541  LossG_Adv: 0.7124 LossG_L1: 1.4249 LossG_Style 1.5484 LossG_Content 1.9139\n",
            "===> Epoch[90](3/7): Loss_D: 0.6617 Loss_G: 5.8527 LossD_Fake: 0.6737 LossD_Real: 0.6498  LossG_Adv: 0.7148 LossG_L1: 1.5698 LossG_Style 1.4773 LossG_Content 2.0908\n",
            "===> Epoch[90](4/7): Loss_D: 0.6636 Loss_G: 5.9692 LossD_Fake: 0.6629 LossD_Real: 0.6643  LossG_Adv: 0.7270 LossG_L1: 1.5362 LossG_Style 1.7153 LossG_Content 1.9907\n",
            "===> Epoch[90](5/7): Loss_D: 0.6821 Loss_G: 5.4816 LossD_Fake: 0.6840 LossD_Real: 0.6801  LossG_Adv: 0.7049 LossG_L1: 1.4968 LossG_Style 1.3660 LossG_Content 1.9139\n",
            "===> Epoch[90](6/7): Loss_D: 0.6708 Loss_G: 5.5171 LossD_Fake: 0.6656 LossD_Real: 0.6760  LossG_Adv: 0.7247 LossG_L1: 1.4519 LossG_Style 1.5007 LossG_Content 1.8397\n",
            "\n",
            "saving sample dataset_90_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[90](7/7): Loss_D: 0.6618 Loss_G: 5.4371 LossD_Fake: 0.6616 LossD_Real: 0.6619  LossG_Adv: 0.7272 LossG_L1: 1.5545 LossG_Style 1.3140 LossG_Content 1.8414\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[91](1/7): Loss_D: 0.6640 Loss_G: 5.6610 LossD_Fake: 0.6707 LossD_Real: 0.6572  LossG_Adv: 0.7103 LossG_L1: 1.5047 LossG_Style 1.5145 LossG_Content 1.9315\n",
            "===> Epoch[91](2/7): Loss_D: 0.6698 Loss_G: 5.8908 LossD_Fake: 0.6934 LossD_Real: 0.6463  LossG_Adv: 0.6964 LossG_L1: 1.6063 LossG_Style 1.5039 LossG_Content 2.0841\n",
            "===> Epoch[91](3/7): Loss_D: 0.6703 Loss_G: 5.7498 LossD_Fake: 0.6763 LossD_Real: 0.6643  LossG_Adv: 0.7130 LossG_L1: 1.4217 LossG_Style 1.6733 LossG_Content 1.9417\n",
            "===> Epoch[91](4/7): Loss_D: 0.6834 Loss_G: 5.2127 LossD_Fake: 0.6919 LossD_Real: 0.6749  LossG_Adv: 0.6969 LossG_L1: 1.3707 LossG_Style 1.3239 LossG_Content 1.8211\n",
            "===> Epoch[91](5/7): Loss_D: 0.6554 Loss_G: 5.8230 LossD_Fake: 0.6636 LossD_Real: 0.6471  LossG_Adv: 0.7261 LossG_L1: 1.5626 LossG_Style 1.5688 LossG_Content 1.9655\n",
            "===> Epoch[91](6/7): Loss_D: 0.6721 Loss_G: 5.2648 LossD_Fake: 0.6852 LossD_Real: 0.6589  LossG_Adv: 0.7055 LossG_L1: 1.4280 LossG_Style 1.2639 LossG_Content 1.8673\n",
            "\n",
            "saving sample dataset_91_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[91](7/7): Loss_D: 0.6596 Loss_G: 5.2853 LossD_Fake: 0.6807 LossD_Real: 0.6385  LossG_Adv: 0.7078 LossG_L1: 1.4742 LossG_Style 1.3002 LossG_Content 1.8031\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[92](1/7): Loss_D: 0.6684 Loss_G: 5.2904 LossD_Fake: 0.6893 LossD_Real: 0.6474  LossG_Adv: 0.7407 LossG_L1: 1.3763 LossG_Style 1.3045 LossG_Content 1.8690\n",
            "===> Epoch[92](2/7): Loss_D: 0.6622 Loss_G: 5.7335 LossD_Fake: 0.6485 LossD_Real: 0.6758  LossG_Adv: 0.7431 LossG_L1: 1.4954 LossG_Style 1.5174 LossG_Content 1.9776\n",
            "===> Epoch[92](3/7): Loss_D: 0.6651 Loss_G: 5.4155 LossD_Fake: 0.6455 LossD_Real: 0.6846  LossG_Adv: 0.7463 LossG_L1: 1.4393 LossG_Style 1.3143 LossG_Content 1.9157\n",
            "===> Epoch[92](4/7): Loss_D: 0.6751 Loss_G: 5.5314 LossD_Fake: 0.6487 LossD_Real: 0.7016  LossG_Adv: 0.7429 LossG_L1: 1.3764 LossG_Style 1.5051 LossG_Content 1.9069\n",
            "===> Epoch[92](5/7): Loss_D: 0.6745 Loss_G: 5.2400 LossD_Fake: 0.6387 LossD_Real: 0.7104  LossG_Adv: 0.7546 LossG_L1: 1.3428 LossG_Style 1.2816 LossG_Content 1.8609\n",
            "===> Epoch[92](6/7): Loss_D: 0.6727 Loss_G: 5.1827 LossD_Fake: 0.6353 LossD_Real: 0.7101  LossG_Adv: 0.7570 LossG_L1: 1.3494 LossG_Style 1.3348 LossG_Content 1.7414\n",
            "\n",
            "saving sample dataset_92_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[92](7/7): Loss_D: 0.6658 Loss_G: 5.5602 LossD_Fake: 0.6516 LossD_Real: 0.6800  LossG_Adv: 0.7408 LossG_L1: 1.3312 LossG_Style 1.4849 LossG_Content 2.0033\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[93](1/7): Loss_D: 0.6611 Loss_G: 5.6878 LossD_Fake: 0.6498 LossD_Real: 0.6723  LossG_Adv: 0.7356 LossG_L1: 1.5575 LossG_Style 1.4409 LossG_Content 1.9538\n",
            "===> Epoch[93](2/7): Loss_D: 0.6784 Loss_G: 4.8680 LossD_Fake: 0.6410 LossD_Real: 0.7158  LossG_Adv: 0.7518 LossG_L1: 1.2814 LossG_Style 1.1390 LossG_Content 1.6958\n",
            "===> Epoch[93](3/7): Loss_D: 0.6660 Loss_G: 5.6007 LossD_Fake: 0.6376 LossD_Real: 0.6943  LossG_Adv: 0.7545 LossG_L1: 1.4913 LossG_Style 1.4622 LossG_Content 1.8927\n",
            "===> Epoch[93](4/7): Loss_D: 0.6686 Loss_G: 5.2952 LossD_Fake: 0.6404 LossD_Real: 0.6968  LossG_Adv: 0.7514 LossG_L1: 1.2856 LossG_Style 1.3528 LossG_Content 1.9054\n",
            "===> Epoch[93](5/7): Loss_D: 0.6766 Loss_G: 5.0440 LossD_Fake: 0.6629 LossD_Real: 0.6903  LossG_Adv: 0.7279 LossG_L1: 1.1871 LossG_Style 1.3557 LossG_Content 1.7734\n",
            "===> Epoch[93](6/7): Loss_D: 0.6547 Loss_G: 5.8072 LossD_Fake: 0.6488 LossD_Real: 0.6606  LossG_Adv: 0.7422 LossG_L1: 1.5047 LossG_Style 1.5365 LossG_Content 2.0237\n",
            "\n",
            "saving sample dataset_93_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[93](7/7): Loss_D: 0.6774 Loss_G: 5.7459 LossD_Fake: 0.6836 LossD_Real: 0.6712  LossG_Adv: 0.7104 LossG_L1: 1.2773 LossG_Style 1.7333 LossG_Content 2.0248\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[94](1/7): Loss_D: 0.6622 Loss_G: 5.9903 LossD_Fake: 0.6540 LossD_Real: 0.6705  LossG_Adv: 0.7147 LossG_L1: 1.5940 LossG_Style 1.5961 LossG_Content 2.0854\n",
            "===> Epoch[94](2/7): Loss_D: 0.6669 Loss_G: 5.6029 LossD_Fake: 0.6773 LossD_Real: 0.6565  LossG_Adv: 0.7131 LossG_L1: 1.4484 LossG_Style 1.5193 LossG_Content 1.9221\n",
            "===> Epoch[94](3/7): Loss_D: 0.6717 Loss_G: 5.2657 LossD_Fake: 0.6582 LossD_Real: 0.6853  LossG_Adv: 0.7361 LossG_L1: 1.4482 LossG_Style 1.2258 LossG_Content 1.8556\n",
            "===> Epoch[94](4/7): Loss_D: 0.6691 Loss_G: 5.2613 LossD_Fake: 0.6706 LossD_Real: 0.6677  LossG_Adv: 0.7194 LossG_L1: 1.3263 LossG_Style 1.3967 LossG_Content 1.8189\n",
            "===> Epoch[94](5/7): Loss_D: 0.6575 Loss_G: 5.3441 LossD_Fake: 0.6660 LossD_Real: 0.6491  LossG_Adv: 0.7248 LossG_L1: 1.3831 LossG_Style 1.3252 LossG_Content 1.9110\n",
            "===> Epoch[94](6/7): Loss_D: 0.6724 Loss_G: 5.4251 LossD_Fake: 0.6739 LossD_Real: 0.6708  LossG_Adv: 0.7161 LossG_L1: 1.3479 LossG_Style 1.5357 LossG_Content 1.8254\n",
            "\n",
            "saving sample dataset_94_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[94](7/7): Loss_D: 0.6716 Loss_G: 5.1678 LossD_Fake: 0.6660 LossD_Real: 0.6772  LossG_Adv: 0.7231 LossG_L1: 1.2069 LossG_Style 1.3648 LossG_Content 1.8730\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[95](1/7): Loss_D: 0.6672 Loss_G: 5.7128 LossD_Fake: 0.6848 LossD_Real: 0.6497  LossG_Adv: 0.7165 LossG_L1: 1.4365 LossG_Style 1.6456 LossG_Content 1.9142\n",
            "===> Epoch[95](2/7): Loss_D: 0.6670 Loss_G: 5.6787 LossD_Fake: 0.6662 LossD_Real: 0.6678  LossG_Adv: 0.7239 LossG_L1: 1.3891 LossG_Style 1.5172 LossG_Content 2.0484\n",
            "===> Epoch[95](3/7): Loss_D: 0.6626 Loss_G: 5.8358 LossD_Fake: 0.6670 LossD_Real: 0.6581  LossG_Adv: 0.7239 LossG_L1: 1.5932 LossG_Style 1.5214 LossG_Content 1.9972\n",
            "===> Epoch[95](4/7): Loss_D: 0.6587 Loss_G: 5.5845 LossD_Fake: 0.6590 LossD_Real: 0.6583  LossG_Adv: 0.7313 LossG_L1: 1.4764 LossG_Style 1.3834 LossG_Content 1.9934\n",
            "===> Epoch[95](5/7): Loss_D: 0.6703 Loss_G: 5.0856 LossD_Fake: 0.6614 LossD_Real: 0.6792  LossG_Adv: 0.7302 LossG_L1: 1.3915 LossG_Style 1.2323 LossG_Content 1.7316\n",
            "===> Epoch[95](6/7): Loss_D: 0.6721 Loss_G: 4.8028 LossD_Fake: 0.6602 LossD_Real: 0.6839  LossG_Adv: 0.7323 LossG_L1: 1.2567 LossG_Style 1.1299 LossG_Content 1.6839\n",
            "\n",
            "saving sample dataset_95_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[95](7/7): Loss_D: 0.6855 Loss_G: 5.0316 LossD_Fake: 0.6782 LossD_Real: 0.6929  LossG_Adv: 0.7119 LossG_L1: 1.3551 LossG_Style 1.2977 LossG_Content 1.6670\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[96](1/7): Loss_D: 0.6632 Loss_G: 5.8887 LossD_Fake: 0.6675 LossD_Real: 0.6590  LossG_Adv: 0.6939 LossG_L1: 1.6287 LossG_Style 1.6271 LossG_Content 1.9389\n",
            "===> Epoch[96](2/7): Loss_D: 0.6666 Loss_G: 5.5636 LossD_Fake: 0.6979 LossD_Real: 0.6353  LossG_Adv: 0.6940 LossG_L1: 1.6828 LossG_Style 1.3337 LossG_Content 1.8531\n",
            "===> Epoch[96](3/7): Loss_D: 0.6672 Loss_G: 5.8082 LossD_Fake: 0.6883 LossD_Real: 0.6460  LossG_Adv: 0.7043 LossG_L1: 1.7712 LossG_Style 1.3789 LossG_Content 1.9538\n",
            "===> Epoch[96](4/7): Loss_D: 0.6589 Loss_G: 5.9509 LossD_Fake: 0.6831 LossD_Real: 0.6346  LossG_Adv: 0.7071 LossG_L1: 1.6408 LossG_Style 1.5505 LossG_Content 2.0526\n",
            "===> Epoch[96](5/7): Loss_D: 0.6663 Loss_G: 6.2962 LossD_Fake: 0.6986 LossD_Real: 0.6340  LossG_Adv: 0.6929 LossG_L1: 1.8383 LossG_Style 1.6650 LossG_Content 2.1000\n",
            "===> Epoch[96](6/7): Loss_D: 0.6550 Loss_G: 5.7306 LossD_Fake: 0.6739 LossD_Real: 0.6362  LossG_Adv: 0.7191 LossG_L1: 1.5688 LossG_Style 1.4507 LossG_Content 1.9920\n",
            "\n",
            "saving sample dataset_96_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[96](7/7): Loss_D: 0.6848 Loss_G: 5.8983 LossD_Fake: 0.6885 LossD_Real: 0.6811  LossG_Adv: 0.7031 LossG_L1: 1.7575 LossG_Style 1.4823 LossG_Content 1.9555\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[97](1/7): Loss_D: 0.6552 Loss_G: 6.5882 LossD_Fake: 0.6742 LossD_Real: 0.6361  LossG_Adv: 0.7608 LossG_L1: 2.1211 LossG_Style 1.6059 LossG_Content 2.1004\n",
            "===> Epoch[97](2/7): Loss_D: 0.6478 Loss_G: 6.6961 LossD_Fake: 0.6315 LossD_Real: 0.6641  LossG_Adv: 0.7621 LossG_L1: 1.7827 LossG_Style 1.9566 LossG_Content 2.1948\n",
            "===> Epoch[97](3/7): Loss_D: 0.6710 Loss_G: 6.3732 LossD_Fake: 0.6719 LossD_Real: 0.6701  LossG_Adv: 0.7205 LossG_L1: 1.7060 LossG_Style 1.7396 LossG_Content 2.2070\n",
            "===> Epoch[97](4/7): Loss_D: 0.6575 Loss_G: 6.8459 LossD_Fake: 0.6358 LossD_Real: 0.6791  LossG_Adv: 0.7586 LossG_L1: 2.1800 LossG_Style 1.7796 LossG_Content 2.1276\n",
            "===> Epoch[97](5/7): Loss_D: 0.6768 Loss_G: 6.4056 LossD_Fake: 0.6543 LossD_Real: 0.6994  LossG_Adv: 0.7396 LossG_L1: 1.9199 LossG_Style 1.6269 LossG_Content 2.1192\n",
            "===> Epoch[97](6/7): Loss_D: 0.6282 Loss_G: 6.8219 LossD_Fake: 0.6176 LossD_Real: 0.6388  LossG_Adv: 0.7803 LossG_L1: 2.1160 LossG_Style 1.8165 LossG_Content 2.1091\n",
            "\n",
            "saving sample dataset_97_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[97](7/7): Loss_D: 0.6845 Loss_G: 6.1925 LossD_Fake: 0.6680 LossD_Real: 0.7010  LossG_Adv: 0.7252 LossG_L1: 1.8812 LossG_Style 1.5197 LossG_Content 2.0663\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[98](1/7): Loss_D: 0.6523 Loss_G: 6.4946 LossD_Fake: 0.6222 LossD_Real: 0.6823  LossG_Adv: 0.6861 LossG_L1: 2.0515 LossG_Style 1.7421 LossG_Content 2.0148\n",
            "===> Epoch[98](2/7): Loss_D: 0.6667 Loss_G: 5.5735 LossD_Fake: 0.7382 LossD_Real: 0.5951  LossG_Adv: 0.6565 LossG_L1: 1.5936 LossG_Style 1.4026 LossG_Content 1.9208\n",
            "===> Epoch[98](3/7): Loss_D: 0.6643 Loss_G: 5.7351 LossD_Fake: 0.7423 LossD_Real: 0.5864  LossG_Adv: 0.6545 LossG_L1: 1.5033 LossG_Style 1.5664 LossG_Content 2.0109\n",
            "===> Epoch[98](4/7): Loss_D: 0.6612 Loss_G: 5.5470 LossD_Fake: 0.7509 LossD_Real: 0.5716  LossG_Adv: 0.6460 LossG_L1: 1.5206 LossG_Style 1.4059 LossG_Content 1.9746\n",
            "===> Epoch[98](5/7): Loss_D: 0.6632 Loss_G: 5.3810 LossD_Fake: 0.7683 LossD_Real: 0.5582  LossG_Adv: 0.6307 LossG_L1: 1.4291 LossG_Style 1.4664 LossG_Content 1.8548\n",
            "===> Epoch[98](6/7): Loss_D: 0.6713 Loss_G: 5.4320 LossD_Fake: 0.7604 LossD_Real: 0.5821  LossG_Adv: 0.6379 LossG_L1: 1.5314 LossG_Style 1.3321 LossG_Content 1.9306\n",
            "\n",
            "saving sample dataset_98_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[98](7/7): Loss_D: 0.6540 Loss_G: 7.3761 LossD_Fake: 0.7735 LossD_Real: 0.5346  LossG_Adv: 0.6256 LossG_L1: 1.7540 LossG_Style 2.5783 LossG_Content 2.4182\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[99](1/7): Loss_D: 0.6710 Loss_G: 6.4124 LossD_Fake: 0.7709 LossD_Real: 0.5712  LossG_Adv: 0.7825 LossG_L1: 1.9377 LossG_Style 1.6287 LossG_Content 2.0635\n",
            "===> Epoch[99](2/7): Loss_D: 0.6654 Loss_G: 5.9429 LossD_Fake: 0.6133 LossD_Real: 0.7176  LossG_Adv: 0.7858 LossG_L1: 1.6083 LossG_Style 1.5742 LossG_Content 1.9746\n",
            "===> Epoch[99](3/7): Loss_D: 0.6720 Loss_G: 5.9941 LossD_Fake: 0.6113 LossD_Real: 0.7328  LossG_Adv: 0.7874 LossG_L1: 1.7298 LossG_Style 1.4248 LossG_Content 2.0521\n",
            "===> Epoch[99](4/7): Loss_D: 0.6584 Loss_G: 6.0413 LossD_Fake: 0.6162 LossD_Real: 0.7007  LossG_Adv: 0.7852 LossG_L1: 1.5516 LossG_Style 1.6900 LossG_Content 2.0145\n",
            "===> Epoch[99](5/7): Loss_D: 0.6756 Loss_G: 5.7469 LossD_Fake: 0.6202 LossD_Real: 0.7310  LossG_Adv: 0.7760 LossG_L1: 1.5850 LossG_Style 1.3706 LossG_Content 2.0152\n",
            "===> Epoch[99](6/7): Loss_D: 0.6603 Loss_G: 5.2845 LossD_Fake: 0.6032 LossD_Real: 0.7174  LossG_Adv: 0.7955 LossG_L1: 1.3426 LossG_Style 1.3839 LossG_Content 1.7625\n",
            "\n",
            "saving sample dataset_99_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[99](7/7): Loss_D: 0.6854 Loss_G: 5.7855 LossD_Fake: 0.5935 LossD_Real: 0.7773  LossG_Adv: 0.8093 LossG_L1: 1.6520 LossG_Style 1.3119 LossG_Content 2.0122\n",
            "Checkpoint saved to checkpointdataset\n",
            "===> Epoch[100](1/7): Loss_D: 0.6544 Loss_G: 6.0158 LossD_Fake: 0.5974 LossD_Real: 0.7113  LossG_Adv: 0.7438 LossG_L1: 1.6184 LossG_Style 1.6067 LossG_Content 2.0469\n",
            "===> Epoch[100](2/7): Loss_D: 0.6653 Loss_G: 5.7254 LossD_Fake: 0.6727 LossD_Real: 0.6580  LossG_Adv: 0.7231 LossG_L1: 1.6200 LossG_Style 1.3821 LossG_Content 2.0002\n",
            "===> Epoch[100](3/7): Loss_D: 0.6663 Loss_G: 5.5523 LossD_Fake: 0.6716 LossD_Real: 0.6609  LossG_Adv: 0.7221 LossG_L1: 1.4895 LossG_Style 1.4466 LossG_Content 1.8941\n",
            "===> Epoch[100](4/7): Loss_D: 0.6646 Loss_G: 5.2641 LossD_Fake: 0.6527 LossD_Real: 0.6765  LossG_Adv: 0.7409 LossG_L1: 1.4145 LossG_Style 1.2389 LossG_Content 1.8699\n",
            "===> Epoch[100](5/7): Loss_D: 0.6515 Loss_G: 5.2748 LossD_Fake: 0.6649 LossD_Real: 0.6381  LossG_Adv: 0.7271 LossG_L1: 1.3503 LossG_Style 1.4257 LossG_Content 1.7717\n",
            "===> Epoch[100](6/7): Loss_D: 0.6767 Loss_G: 5.0961 LossD_Fake: 0.6766 LossD_Real: 0.6769  LossG_Adv: 0.7166 LossG_L1: 1.3460 LossG_Style 1.2091 LossG_Content 1.8244\n",
            "\n",
            "saving sample dataset_100_07.jpg - learning rate: 0.0001\n",
            "===> Epoch[100](7/7): Loss_D: 0.6617 Loss_G: 5.5878 LossD_Fake: 0.6897 LossD_Real: 0.6337  LossG_Adv: 0.7013 LossG_L1: 1.4257 LossG_Style 1.5542 LossG_Content 1.9066\n",
            "Checkpoint saved to checkpointdataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Zj66z8QbE8"
      },
      "source": [
        "def run():\r\n",
        "    torch.multiprocessing.freeze_support()\r\n",
        "    print('loop')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsvBwy22Qc_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad6cbac-2784-40ff-a0ee-1ca8f3e01206"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loop\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}